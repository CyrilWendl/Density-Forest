{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset: Density Forests\n",
    "Trains a simple CNN on _N-1_ classes of the MNIST dataset, predicts unseen classes using baseline methods and Density Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9159977444182164214\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils as np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import decomposition, svm, metrics\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "\n",
    "#custom libraries\n",
    "base_dir = '/Users/cyrilwendl/Documents/EPFL'\n",
    "#base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "import sys\n",
    "sys.path.append(base_dir + '/SIE-Master/Zurich')  # Path to density Tree package\n",
    "sys.path.append(base_dir + '/SIE-Master/Code')  # Path to density Tree package\n",
    "from density_forest.density_forest import *\n",
    "from density_forest.plots import *\n",
    "from density_forest.helpers import *\n",
    "from baselines.helpers import *\n",
    "from helpers.helpers import *\n",
    "from helpers.plots import *\n",
    "from helpers.cv_scorers import *\n",
    "from helpers.cross_validator import ParameterSearch\n",
    "from parametric_tSNE.utils import *\n",
    "\n",
    "# print available devices\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import \n",
    "Import the data, delete all data in the training set of class 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 5851, 5949]))\n",
      "x_train shape: (53735, 28, 28, 1)\n",
      "53735 train samples\n",
      "8972 test samples\n"
     ]
    }
   ],
   "source": [
    "label_to_remove = 7\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "def load_data(label_to_remove):\n",
    "    (x_train_all, y_train_all), (x_test_all, y_test_all) = mnist.load_data()\n",
    "    print(np.unique(y_train_all, return_counts=True))\n",
    "\n",
    "    # remove all trainig samples containing a label label_to_remove\n",
    "    x_train = x_train_all[y_train_all != label_to_remove]\n",
    "    y_train = y_train_all[y_train_all != label_to_remove]\n",
    "\n",
    "    x_test = x_test_all[y_test_all != label_to_remove]\n",
    "    y_test = y_test_all[y_test_all != label_to_remove]\n",
    "\n",
    "    # decrease all labels that are higher by -1 to avoid gaps\n",
    "    for i in range(label_to_remove + 1, 11):\n",
    "        y_train[y_train == i] = (i-1)\n",
    "        y_test[y_test == i] = (i-1)\n",
    "    print(np.unique(y_train, return_counts=True))    \n",
    "    \n",
    "    batch_size = 128\n",
    "    num_classes = 9\n",
    "    epochs = 5\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    # Reshape for Tensorflow\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    x_test_all = x_test_all.reshape(x_test_all.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_test_all = x_test_all.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    x_test_all /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = np_utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "    return x_train_all, y_train_all, x_test_all, y_test_all, x_train, y_train, x_test, y_test, batch_size, num_classes, epochs, img_rows, img_cols, input_shape\n",
    "\n",
    "x_train_all, y_train_all, x_test_all, y_test_all, x_train, y_train, x_test, y_test, batch_size, num_classes, epochs, img_ros, img_cols, input_shape = load_data(label_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 1,199,753\n",
      "Trainable params: 1,199,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model_train = False\n",
    "if model_train:\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "    model.save('mnist_models/mnist-weights-' + str(label_to_remove) + '.h5')\n",
    "else:\n",
    "    model = load_model('mnist_models/mnist-weights-' + str(label_to_remove) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OA(y_true, y_pred):\n",
    "        \"\"\"get overall accuracy\"\"\"\n",
    "        return np.sum(y_true == y_pred)/len(y_true)\n",
    "\n",
    "def AA(y_true, y_pred):\n",
    "    \"\"\"get average (macro) accuracy\"\"\"\n",
    "    acc_cl = []\n",
    "    for label in np.unique(y_true):\n",
    "        acc_cl.append(np.sum(y_true[y_pred==label] == y_pred[y_pred==label])/len(y_pred[y_pred==label]))\n",
    "    return np.mean(acc_cl), acc_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 5851, 5949]))\n",
      "x_train shape: (53735, 28, 28, 1)\n",
      "53735 train samples\n",
      "8972 test samples\n",
      "60000/60000 [==============================] - 34s 570us/step\n",
      "10000/10000 [==============================] - 6s 554us/step\n",
      "OA training set: 99.39\n",
      "AA training set: 99.38\n",
      "OA test set: 99.20\n",
      "AA test set: 99.19\n"
     ]
    }
   ],
   "source": [
    "# get all predictions in training and test set\n",
    "oa_trs = []\n",
    "aa_trs = []\n",
    "oa_tes = []\n",
    "aa_tes = []\n",
    "\n",
    "# for label_to_remove in range(10):\n",
    "\"\"\"\n",
    "get mean oa, aa for tr and te for all labels\n",
    "\"\"\"\n",
    "print(label_to_remove)\n",
    "x_train_all, y_train_all, x_test_all, y_test_all, x_train, y_train, x_test, y_test, batch_size, num_classes, epochs, img_ros, img_cols, input_shape = load_data(label_to_remove)\n",
    "model = load_model('mnist_models/mnist-weights-' + str(label_to_remove) + '.h5')\n",
    "y_pred_tr = model.predict(x_train_all[..., np.newaxis], verbose=True)\n",
    "y_pred_label_tr = get_y_pred_labels(y_pred_tr, class_to_remove=label_to_remove, background=False)\n",
    "\n",
    "y_pred_te = model.predict(x_test_all, verbose=True)\n",
    "y_pred_label_te = get_y_pred_labels(y_pred_te, class_to_remove=label_to_remove, background=False)\n",
    "\n",
    "# get indices of correctly / incorrectly predicted images\n",
    "pred_t_tr = y_train_all != label_to_remove\n",
    "pred_f_tr = y_train_all == label_to_remove\n",
    "\n",
    "pred_t_te = y_test_all != label_to_remove\n",
    "pred_f_te = y_test_all == label_to_remove\n",
    "\n",
    "# get overall and average accuracy for training and test set\n",
    "\n",
    "\n",
    "oa_tr = OA(y_train_all[y_train_all!=label_to_remove], y_pred_label_tr[y_train_all!=label_to_remove])\n",
    "aa_tr, aa_tr_cl = AA(y_train_all[y_train_all!=label_to_remove], y_pred_label_tr[y_train_all!=label_to_remove])\n",
    "\n",
    "oa_te = OA(y_test_all[y_test_all!=label_to_remove], y_pred_label_te[y_test_all!=label_to_remove])\n",
    "aa_te, aa_te_cl = AA(y_test_all[y_test_all!=label_to_remove], y_pred_label_te[y_test_all!=label_to_remove])\n",
    "oa_trs.append(oa_tr)\n",
    "aa_trs.append(aa_tr)\n",
    "\n",
    "oa_tes.append(oa_te)\n",
    "aa_tes.append(aa_te)\n",
    "\n",
    "print(\"OA training set: %.2f\" % (oa_tr*100))\n",
    "print(\"AA training set: %.2f\" % (aa_tr*100))\n",
    "\n",
    "print(\"OA test set: %.2f\" % (oa_te*100))\n",
    "print(\"AA test set: %.2f\" % (aa_te*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.39]\n",
      "[99.38]\n",
      "[99.2]\n",
      "[99.19]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.multiply(oa_trs,100),2))\n",
    "print(np.round(np.multiply(aa_trs,100),2))\n",
    "print(np.round(np.multiply(oa_tes,100),2))\n",
    "print(np.round(np.multiply(aa_tes,100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some predictions for the unseen class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LatexError",
     "evalue": "LaTeX returned an error, probably missing font or error in preamble:\nb'This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2018) (preloaded format=xelatex)\\n restricted \\\\write18 enabled.\\n**entering extended mode\\nLaTeX2e <2018-04-01> patch level 2\\nBabel <3.18> and hyphenation patterns for 84 language(s) loaded.\\n\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/base/minimal.cls\\nDocument Class: minimal 2001/05/25 Standard LaTeX minimal class\\n)\\n(Please type a command or say `\\\\end\\')\\n*\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/fontenc.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/tuenc.def))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\\n*\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n!\\n! fontspec error: \"font-not-found\"\\n! \\n! The font \"Bitstream Vera Serif\" cannot be found.\\n! \\n! See the fontspec documentation for further information.\\n! \\n! For immediate help type H <return>.\\n!...............................................  \\n                                                  \\n<*> \\\\setsansfont\\n                {Bitstream Vera Sans}\\nNo pages of output.\\nTranscript written on texput.log.\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLatexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6f42f1e8d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Misclassified labels (mean MSR=%.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_acc_net_msr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#plt.savefig(\"../Figures/MNIST/Pred_count/pred-count_wo_cl\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Figures/MNIST/Pred_count/pred-count_wo_cl\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_to_remove\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pgf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2261\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2264\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pgf.py\u001b[0m in \u001b[0;36mprint_pgf\u001b[0;34m(self, fname_or_fh, *args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_fh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_fh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pgf_to_fh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_writable_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pgf.py\u001b[0m in \u001b[0;36m_print_pgf_to_fh\u001b[0;34m(self, fh, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0m_bbox_inches_restore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_inches_restore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         renderer = MixedModeRenderer(self.figure, w, h, dpi,\n\u001b[0;32m--> 842\u001b[0;31m                                      \u001b[0mRendererPgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                                      bbox_inches_restore=_bbox_inches_restore)\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pgf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, figure, fh, dummy)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# get LatexManager instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatexManager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatexManagerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_latex_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pgf.py\u001b[0m in \u001b[0;36mget_latex_manager\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pgf.debug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"creating LatexManager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mnew_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatexManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mLatexManagerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_pgf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlatex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             raise LatexError(\"LaTeX returned an error, probably missing font \"\n\u001b[0;32m--> 315\u001b[0;31m                              \"or error in preamble:\\n%s\" % stdout)\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# open LaTeX process for real work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLatexError\u001b[0m: LaTeX returned an error, probably missing font or error in preamble:\nb'This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2018) (preloaded format=xelatex)\\n restricted \\\\write18 enabled.\\n**entering extended mode\\nLaTeX2e <2018-04-01> patch level 2\\nBabel <3.18> and hyphenation patterns for 84 language(s) loaded.\\n\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/base/minimal.cls\\nDocument Class: minimal 2001/05/25 Standard LaTeX minimal class\\n)\\n(Please type a command or say `\\\\end\\')\\n*\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/fontenc.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/tuenc.def))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\\n*\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n!\\n! fontspec error: \"font-not-found\"\\n! \\n! The font \"Bitstream Vera Serif\" cannot be found.\\n! \\n! See the fontspec documentation for further information.\\n! \\n! For immediate help type H <return>.\\n!...............................................  \\n                                                  \\n<*> \\\\setsansfont\\n                {Bitstream Vera Sans}\\nNo pages of output.\\nTranscript written on texput.log.\\n'"
     ]
    }
   ],
   "source": [
    "# all images in the test set containing a label label_to_remove\n",
    "x_unseen_class = x_test_all[np.where(y_test_all == label_to_remove)[0]] \n",
    "\n",
    "# make prodictions for class unseen during training\n",
    "y_pred = model.predict(x_unseen_class)\n",
    "y_pred_label = get_y_pred_labels(y_pred, label_to_remove, background=False)\n",
    "\n",
    "# distribution of predicted label\n",
    "pred_labels, pred_counts = np.unique(y_pred_label, return_counts=True)\n",
    "\n",
    "# visualization\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.bar(pred_labels, pred_counts)\n",
    "plt.xticks(np.arange(0, 10))\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.title(\"Misclassified labels (mean MSR=%.2f)\" % np.mean(get_acc_net_msr(y_pred)))\n",
    "#plt.savefig(\"../Figures/MNIST/Pred_count/pred-count_wo_cl\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.savefig(\"../Figures/MNIST/Pred_count/pred-count_wo_cl\" + str(label_to_remove) + \".pgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2018) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "**entering extended mode\n",
      "LaTeX2e <2018-04-01> patch level 2\n",
      "Babel <3.18> and hyphenation patterns for 84 language(s) loaded.\n",
      "\n",
      "*(/usr/local/texlive/2018/texmf-dist/tex/latex/base/minimal.cls\n",
      "Document Class: minimal 2001/05/25 Standard LaTeX minimal class\n",
      ")\n",
      "(Please type a command or say `\\end')\n",
      "*\n",
      "*(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.sty\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3.sty\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/base/fontenc.sty\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/base/tuenc.def))\n",
      "(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n",
      "*\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!\n",
      "! fontspec error: \"font-not-found\"\n",
      "! \n",
      "! The font \"Bitstream Vera Serif\" cannot be found.\n",
      "! \n",
      "! See the fontspec documentation for further information.\n",
      "! \n",
      "! For immediate help type H <return>.\n",
      "!...............................................  \n",
      "                                                  \n",
      "<*> \\setsansfont\n",
      "                {Bitstream Vera Sans}\n",
      "No pages of output.\n",
      "Transcript written on texput.log.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2018) (preloaded format=xelatex)\\n restricted \\\\write18 enabled.\\n**entering extended mode\\nLaTeX2e <2018-04-01> patch level 2\\nBabel <3.18> and hyphenation patterns for 84 language(s) loaded.\\n\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/base/minimal.cls\\nDocument Class: minimal 2001/05/25 Standard LaTeX minimal class\\n)\\n(Please type a command or say `\\\\end\\')\\n*\\n*(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/fontenc.sty\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/base/tuenc.def))\\n(/usr/local/texlive/2018/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\\n*\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n!\\n! fontspec error: \"font-not-found\"\\n! \\n! The font \"Bitstream Vera Serif\" cannot be found.\\n! \\n! See the fontspec documentation for further information.\\n! \\n! For immediate help type H <return>.\\n!...............................................  \\n                                                  \\n<*> \\\\setsansfont\\n                {Bitstream Vera Sans}\\nNo pages of output.\\nTranscript written on texput.log.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 68.64 %\n",
      "Std accuracy: 31.61 %\n",
      "30.45% of all predictions made with an accuracy higher than 0.95%\n"
     ]
    }
   ],
   "source": [
    "# Avarage certitude for unseen class: 1-max_margin\n",
    "c = get_acc_net_max_margin(y_pred)\n",
    "    \n",
    "pred_acc_mean = np.mean(c)\n",
    "pred_acc_std = np.std(c)\n",
    "    \n",
    "print(\"Mean accuracy: %.2f %%\" % (pred_acc_mean * 100))\n",
    "print(\"Std accuracy: %.2f %%\" % (pred_acc_std * 100))\n",
    "\n",
    "pred_acc_high = .95\n",
    "\n",
    "pct = np.round(len(c[c > pred_acc_high]) / len(c), 4) * 100\n",
    "print(\"%.2f%% of all predictions made with an accuracy higher than %.2f%%\" % (pct, pred_acc_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avarage certitude for seen class: 1-max_margin\n",
    "y_pred_seen = model.predict(x_test)\n",
    "y_pred_label_seen = get_y_pred_labels(y_pred_seen, label_to_remove, background=False)\n",
    "\n",
    "c = get_acc_net_max_margin(y_pred_seen)\n",
    "    \n",
    "pred_acc_mean = np.mean(c)\n",
    "pred_acc_std = np.std(c)\n",
    "    \n",
    "print(\"Mean accuracy: %.2f %%\" % (pred_acc_mean * 100))\n",
    "print(\"Std accuracy: %.2f %%\" % (pred_acc_std * 100))\n",
    "\n",
    "pred_acc_high = .95\n",
    "\n",
    "pct = np.round(len(c[c > pred_acc_high])/len(c), 4) * 100\n",
    "print(\"%.2f %% of all predictions made with an accuracy higher than %.2f%%\" % (pct, pred_acc_high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curves\n",
    "\n",
    "# msr\n",
    "y_scores = 1-get_acc_net_msr(y_pred_te)\n",
    "y_true = pred_f_te\n",
    "precision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_msr = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_msr = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# margin\n",
    "y_scores = 1-get_acc_net_max_margin(y_pred_te)\n",
    "precision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_margin = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_margin = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# entropy\n",
    "y_scores = 1-get_acc_net_entropy(y_pred_te)\n",
    "precision_entropy, recall_entropy, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_entropy = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_entropy = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# plot\n",
    "plt.step(recall_msr, precision_msr, where='post')\n",
    "plt.step(recall_margin, precision_margin, where='post')\n",
    "plt.step(recall_entropy, precision_entropy, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('MSR (AUC=%.2f)' % pr_auc_msr),\n",
    "            str.format('Margin (AUC=%.2f)' % pr_auc_margin),\n",
    "            str.format('Entropy (AUC=%.2f)' % pr_auc_entropy)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = predict_with_dropouts_batch(model, x_test_all, \n",
    "                                      batch_size=100, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean(y_preds, axis=0)\n",
    "probas = -get_acc_net_entropy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# PR\n",
    "precision_dropout, recall_dropout, _ = metrics.precision_recall_curve(y_true, probas)\n",
    "pr_auc_dropout = metrics.auc(recall_dropout, precision_dropout)\n",
    "# ROC\n",
    "fpr_dropout, tpr_dropout, _ = metrics.roc_curve(y_true, probas)\n",
    "auroc_dropout = metrics.roc_auc_score(y_true, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Density Forest\n",
    "## Get Activations, PCA, t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get activation weights of last layer\n",
    "act_unseen = get_activations_batch(model, 6, x_unseen_class, verbose=True)\n",
    "act_train_all = get_activations_batch(model, 6, x_train_all[..., np.newaxis], verbose=True)\n",
    "act_train = act_train_all[y_train_all != label_to_remove]\n",
    "act_test = get_activations_batch(model, 6, x_test_all, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pts_per_class = 300\n",
    "n_classes = 10\n",
    "dataset_subset_indices = get_balanced_subset_indices(y_test_all, np.arange(n_classes), pts_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300)\n",
    "# t-SNE visualization before PCA\n",
    "tsne_all = tsne.fit_transform(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# color scale and legend for t-sne plots\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, n_classes))[:, :3]\n",
    "names = ['Class ' + str(i) for i in range(10)]\n",
    "classes_to_keep = np.asarray([x for x in range(n_classes) if x != label_to_remove])\n",
    "\n",
    "# plot\n",
    "tsne_y = y_test_all[np.concatenate(dataset_subset_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plot_pts_2d(tsne_all, y_test_all, ax, classes_to_keep,\n",
    "            colors, class_to_remove=label_to_remove)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(\"../Figures/MNIST/tSNE/MNIST_t-SNE_wo_cl_\" + str(label_to_remove) + \"_before.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(act_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(act_train)\n",
    "\n",
    "\n",
    "# plot\n",
    "print(\"Variance explained by first %i components: %.2f\" % (len(pca.components_), \n",
    "                                                           np.sum(pca.explained_variance_ratio_[:len(pca.components_)])))\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.scatter(np.arange(len(pca.components_)), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative sum of explained variance\")\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.savefig(\"../Figures/MNIST/PCA/pca_components_wo_cl_\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit PCA\n",
    "X_train_all = pca.transform(act_train_all)\n",
    "X_train = pca.transform(act_train)\n",
    "X_test = pca.transform(act_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test sample (with unseen class)\n",
    "plot_pts_3d(X_train_all, y_train_all, classes_to_keep, colors, class_to_remove=label_to_remove, \n",
    "            subsample_pct=.05, s_name=\"../Figures/MNIST/PCA/MNIST_PCA_3D_wo_cl_\" + str(label_to_remove) + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sample (with unseen class)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plot_pts_2d(X_train_all, y_train_all, ax, classes_to_keep, colors, class_to_remove=label_to_remove, \n",
    "            subsample_pct=.05)\n",
    "ax.set_axis_off()\n",
    "plt.savefig(\"../Figures/MNIST/PCA/MNIST_PCA_2D_wo_cl_\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization after PCA\n",
    "tsne_all = tsne.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plot_pts_2d(tsne_all, y_test_all, ax, classes_to_keep,\n",
    "            colors, class_to_remove=label_to_remove)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(\"../Figures/MNIST/tSNE/MNIST_t-SNE_wo_cl_\" + str(label_to_remove) + \"_after.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_train = tsne_all[y_test_all != label_to_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM\n",
    "GMM, calculate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_components': np.arange(4, 10), \n",
    "                     'max_iter': [10000]}]\n",
    "\n",
    "# do parameter search\n",
    "ps_gmm = ParameterSearch(GaussianMixture, tuned_parameters, X_train, X_train_all, \n",
    "                         pred_f_tr[y_train_all < np.infty], scorer_roc_probas_gmm, \n",
    "                         n_iter=3, verbosity=11, n_jobs=1, subsample_train=.05, subsample_test=.05)\n",
    "ps_gmm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps_gmm.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "gmm = GaussianMixture(**ps_gmm.best_params)\n",
    "gmm.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "probas = gmm.predict_proba(X_test)\n",
    "probas = get_acc_net_entropy(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0], tsne_all[:, 1], c=probas)  # certainty for each point\n",
    "axes[1].scatter(tsne_all[:, 0], tsne_all[:, 1], c=probas < np.sort(probas)[300])  # 300 least certain points in yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# PR\n",
    "precision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, -probas)\n",
    "pr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\n",
    "# ROC\n",
    "fpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, -probas)\n",
    "auroc_gmm = metrics.roc_auc_score(y_true, -probas)\n",
    "\n",
    "print(\"PR AUC: %.2f, AUROC: %.2f\" % (pr_auc_gmm, auroc_gmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm = preprocessing.scale(X_train)\n",
    "X_train_all_svm = preprocessing.scale(X_train_all)\n",
    "X_test_svm = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_tr = (y_train_all != y_pred_label_tr) * 1\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'nu': [1e-2, .1, .3, .5]\n",
    "                     },\n",
    "                    {'kernel': ['poly'],\n",
    "                     'degree': np.arange(1, 16),\n",
    "                     'nu': [1e-2, .1, .3, .5],\n",
    "                     'max_iter': [10000]\n",
    "                     }]\n",
    "\n",
    "# do parameter search\n",
    "ps_svm = ParameterSearch(svm.OneClassSVM, tuned_parameters, X_train_svm, X_train_all_svm, \n",
    "                         pred_f_tr[y_train_all < np.infty], scorer_roc_probas_svm, n_iter=5, \n",
    "                         verbosity=10, n_jobs=-1, subsample_train=.1, subsample_test=.1)\n",
    "\n",
    "ps_svm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps_svm.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.OneClassSVM(**ps_svm.best_params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.fit(X_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf_svm.decision_function(X_test_svm)[:, 0]\n",
    "probas -= np.min(probas)\n",
    "probas /= np.max(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correctly / incorrectly predicted points (x/o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t_te], tsne_all[:, 1][pred_t_te], c=probas[pred_t_te], alpha=.02)\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t_te], tsne_all[:, 1][pred_t_te], \n",
    "                c=(probas < np.sort(probas)[1000])[pred_t_te], alpha=.02)\n",
    "\n",
    "# plot correctly / incorrectly predicted points (x/o marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f_te], tsne_all[:, 1][pred_f_te], c=probas[pred_f_te], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f_te], tsne_all[:, 1][pred_f_te], \n",
    "                c=(probas < np.sort(probas)[1000])[pred_f_te], marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# PR\n",
    "precision_svm, recall_svm, _ = metrics.precision_recall_curve(y_true, -probas)\n",
    "pr_auc_svm = metrics.auc(recall_svm, precision_svm)\n",
    "# ROC\n",
    "fpr_svm, tpr_svm, _ = metrics.roc_curve(y_true, -probas)\n",
    "auroc_svm = metrics.roc_auc_score(y_true, -probas)\n",
    "\n",
    "print(\"PR AUC: %.2f, AUROC: %.2f\" % (pr_auc_svm, auroc_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [{'max_depth': 2, 'ig_improvement': .7},\n",
    "               {'max_depth': 2, 'ig_improvement': .7},\n",
    "               {'max_depth': 4, 'ig_improvement': .3},\n",
    "               {'max_depth': 4, 'ig_improvement': .7},\n",
    "               {'max_depth': 4, 'ig_improvement': .7},\n",
    "               {'max_depth': 5, 'ig_improvement': 0},\n",
    "               {'max_depth': 5, 'ig_improvement': 0},\n",
    "               {'max_depth': 2, 'ig_improvement': .5},\n",
    "               {'max_depth': 2, 'ig_improvement': 0},\n",
    "               {'max_depth': 4, 'ig_improvement': .3},\n",
    "              ]\n",
    "\n",
    "\n",
    "\n",
    "default_params = {'min_subset': .05, 'n_trees': 30, 'n_max_dim': 1, 'n_jobs': -1, 'subsample_pct': .02, 'verbose': 0}\n",
    "paramsearch = False\n",
    "if paramsearch:\n",
    "    tuned_params = [{'max_depth': [2, 4, 5],\n",
    "                     'ig_improvement': [0, .3, .5, .7, .9]}]\n",
    "\n",
    "    ps_df = ParameterSearch(DensityForest, tuned_params, X_train, X_train_all,\n",
    "                            pred_f_tr[y_train_all < np.infty], scorer_roc_probas_df, n_iter=3,\n",
    "                            verbosity=11, n_jobs=1, subsample_train=1, subsample_test=1, default_params=default_params)\n",
    "\n",
    "    ps_df.fit()\n",
    "    \n",
    "    # show results\n",
    "    display(ps_df.results_df.groupby('max_depth').mean())\n",
    "    display(ps_df.results_df.groupby('ig_improvement').mean())\n",
    "    \n",
    "    best_params = ps_df.best_params\n",
    "else:\n",
    "    best_params = best_params[label_to_remove]\n",
    "\n",
    "default_params['verbose'] = 1\n",
    "#default_params['n_trees'] = 30\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DensityForest instance\n",
    "clf_df = DensityForest(**best_params, **default_params)\n",
    "clf_df.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf_df.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs, means = get_clusters(clf_df.root_nodes[1], [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "y_scores = -probas\n",
    "# PR\n",
    "precision_df, recall_df, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_df = metrics.auc(recall_df, precision_df)\n",
    "# ROC\n",
    "fpr_df, tpr_df, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_df = metrics.roc_auc_score(y_true, y_scores)\n",
    "plt.step(recall_df, precision_df)\n",
    "metrics.auc(recall_df, precision_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "# order according to increasing score\n",
    "scores_pr = np.multiply([pr_auc_msr, pr_auc_margin, pr_auc_entropy, \n",
    "                         pr_auc_dropout, pr_auc_gmm, pr_auc_svm, pr_auc_df], 100)\n",
    "\n",
    "recalls = [recall_msr, recall_margin, recall_entropy, recall_dropout, recall_gmm, recall_svm, recall_df]\n",
    "precisions = [precision_msr, precision_margin, precision_entropy, \n",
    "              precision_dropout, precision_gmm, precision_svm, precision_df]\n",
    "\n",
    "names_methods = np.array(['MSR', 'Margin', 'Entropy', 'Dropout', 'GMM', 'OC SVM', 'DF'])\n",
    "scores_order = np.argsort(scores_pr)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_pr)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(recalls[i], precisions[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_pr[i]) for i in scores_order], title=\"PR AUC [%]\")\n",
    "plt.savefig(\"../Figures/MNIST/Metrics/PR_ED_wo_cl_\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "# order according to increasing score\n",
    "scores_auc = np.multiply([auroc_msr, auroc_margin, auroc_entropy, auroc_dropout, auroc_gmm, auroc_svm, auroc_df], 100)\n",
    "fprs = [fpr_msr, fpr_margin, fpr_entropy, fpr_dropout, fpr_gmm, fpr_svm, fpr_df]\n",
    "tprs = [tpr_msr, tpr_margin, tpr_entropy, tpr_dropout, tpr_gmm, tpr_svm, tpr_df]\n",
    "scores_order = np.argsort(scores_auc)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_auc)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(fprs[i], tprs[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', c='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_auc[i]) for i in scores_order], title=\"AUROC [%]\")\n",
    "plt.savefig(\"../Figures/MNIST/Metrics/ROC_ED_wo_cl_\" + str(label_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
