\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\@newglossary[4]{}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{main.ist}
\@glsorder{word}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{List of Figures}{ii}{section*.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{List of Tables}{v}{section*.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Acronyms}{vi}{section*.6}}
\abx@aux@cite{leibig2017}
\abx@aux@segm{0}{0}{leibig2017}
\abx@aux@cite{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@cite{Levinson2011TowardsFA}
\abx@aux@segm{0}{0}{Levinson2011TowardsFA}
\abx@aux@cite{Volpi2017DenseSL}
\abx@aux@segm{0}{0}{Volpi2017DenseSL}
\abx@aux@cite{kampffmeyer}
\abx@aux@segm{0}{0}{kampffmeyer}
\abx@aux@cite{Zhu2017DeepLI}
\abx@aux@segm{0}{0}{Zhu2017DeepLI}
\abx@aux@cite{Shelhamer2015FullyCN}
\abx@aux@segm{0}{0}{Shelhamer2015FullyCN}
\abx@aux@cite{NguyenYC14}
\abx@aux@segm{0}{0}{NguyenYC14}
\abx@aux@cite{Goodfellow2014}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@cite{KendallG17}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@cite{Gal2016Uncertainty}
\abx@aux@segm{0}{0}{Gal2016Uncertainty}
\abx@aux@cite{Rupprecht2017LearningIA}
\abx@aux@segm{0}{0}{Rupprecht2017LearningIA}
\abx@aux@segm{0}{0}{leibig2017}
\abx@aux@segm{0}{0}{leibig2017}
\abx@aux@cite{menderes_automatic_2015}
\abx@aux@segm{0}{0}{menderes_automatic_2015}
\abx@aux@cite{womble_automated_2007}
\abx@aux@segm{0}{0}{womble_automated_2007}
\abx@aux@cite{postadjian_investigating_2017}
\abx@aux@segm{0}{0}{postadjian_investigating_2017}
\abx@aux@cite{tuiaAL2011}
\abx@aux@segm{0}{0}{tuiaAL2011}
\abx@aux@cite{Tuia2011ASO}
\abx@aux@segm{0}{0}{Tuia2011ASO}
\abx@aux@segm{0}{0}{Gal2016Uncertainty}
\abx@aux@cite{Choi2017UncertaintyAwareLF}
\abx@aux@segm{0}{0}{Choi2017UncertaintyAwareLF}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@cite{subramanya}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{leibig2017}
\abx@aux@cite{Sun2018KSconfA}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@cite{Hammer2007HowTP}
\abx@aux@segm{0}{0}{Hammer2007HowTP}
\abx@aux@segm{0}{0}{Gal2016Uncertainty}
\abx@aux@segm{0}{0}{Gal2016Uncertainty}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@cite{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@cite{Bahat_2018}
\abx@aux@segm{0}{0}{Bahat_2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@cite{deMorsier2014thesis}
\abx@aux@segm{0}{0}{deMorsier2014thesis}
\abx@aux@cite{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@cite{mnist}
\abx@aux@segm{0}{0}{mnist}
\abx@aux@cite{Volpi2015SemanticSO}
\abx@aux@segm{0}{0}{Volpi2015SemanticSO}
\abx@aux@cite{ghahramani}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{NguyenYC14}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{NguyenYC14}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@cite{Bishop1994NoveltyDA}
\abx@aux@segm{0}{0}{Bishop1994NoveltyDA}
\abx@aux@cite{Markou2003NoveltyDApt1}
\abx@aux@segm{0}{0}{Markou2003NoveltyDApt1}
\abx@aux@cite{Markou2003NoveltyDApt2}
\abx@aux@segm{0}{0}{Markou2003NoveltyDApt2}
\abx@aux@cite{Pimentel2014ARO}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@segm{0}{0}{deMorsier2014thesis}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@segm{0}{0}{deMorsier2014thesis}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@cite{Schmidhuber2015DeepLI}
\abx@aux@segm{0}{0}{Schmidhuber2015DeepLI}
\abx@aux@segm{0}{0}{Zhu2017DeepLI}
\abx@aux@cite{Kampffmeyer2016SemanticSO}
\abx@aux@segm{0}{0}{Kampffmeyer2016SemanticSO}
\abx@aux@cite{HendrycksG16c}
\abx@aux@segm{0}{0}{HendrycksG16c}
\abx@aux@cite{zaragoza}
\abx@aux@segm{0}{0}{zaragoza}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{4}{section.2}}
\newlabel{sec:lit}{{2}{4}{Literature Review}{section.2}{}}
\abx@aux@cite{ouerghemmi_two-step_2017}
\abx@aux@segm{0}{0}{ouerghemmi_two-step_2017}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{zaragoza}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{Bahat_2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Methods Based on Network Output}{5}{subsection.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Single-Pass Methods}{5}{subsubsection.2.1.1}}
\newlabel{eq:net_msr}{{3}{5}{Single-Pass Methods}{equation.2.3}{}}
\newlabel{eq:net_margin}{{4}{5}{Single-Pass Methods}{equation.2.4}{}}
\newlabel{eq:net_entropy}{{5}{5}{Single-Pass Methods}{equation.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Invariance to Image Transformations}{5}{subsubsection.2.1.2}}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{leibig2017}
\abx@aux@cite{Lakshminarayanan16}
\abx@aux@segm{0}{0}{Lakshminarayanan16}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{Kampffmeyer2016SemanticSO}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{NguyenYC14}
\abx@aux@segm{0}{0}{NguyenYC14}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Bishop1994NoveltyDA}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Invariance To Image Transformation: Schema for \gls {MNIST} digit example \cite {Bahat_2018}.\relax }}{6}{figure.caption.8}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:schema-baseline1}{{1}{6}{Invariance To Image Transformation: Schema for \gls {MNIST} digit example \cite {Bahat_2018}.\relax }{figure.caption.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}MC-Dropout}{6}{subsubsection.2.1.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Methods Based on Network Activations}{6}{subsection.2.2}}
\newlabel{subsec:pre-softmax}{{2.2}{6}{Methods Based on Network Activations}{subsection.2.2}{}}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@cite{Gal2015Dropout}
\abx@aux@segm{0}{0}{Gal2015Dropout}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@segm{0}{0}{Gal2015Dropout}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{Gal2015Dropout}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Lakshminarayanan16}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Lakshminarayanan16}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@segm{0}{0}{Markou2003NoveltyDApt1}
\abx@aux@segm{0}{0}{Markou2003NoveltyDApt2}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Network Architectures for Confidence Estimation}{7}{subsection.2.3}}
\abx@aux@cite{Reynolds2009GaussianMM}
\abx@aux@segm{0}{0}{Reynolds2009GaussianMM}
\abx@aux@cite{Dempster1977MaximumLF}
\abx@aux@segm{0}{0}{Dempster1977MaximumLF}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@cite{Wang2004AnomalyID}
\abx@aux@segm{0}{0}{Wang2004AnomalyID}
\abx@aux@cite{Beghi2014AOS}
\abx@aux@segm{0}{0}{Beghi2014AOS}
\abx@aux@cite{Szymanski2011VisualisingKS}
\abx@aux@segm{0}{0}{Szymanski2011VisualisingKS}
\abx@aux@segm{0}{0}{deMorsier2014thesis}
\abx@aux@segm{0}{0}{Pimentel2014ARO}
\abx@aux@cite{Breunig2000LOFID}
\abx@aux@segm{0}{0}{Breunig2000LOFID}
\abx@aux@cite{Liu2008IsolationF}
\abx@aux@segm{0}{0}{Liu2008IsolationF}
\abx@aux@segm{0}{0}{HendrycksG16c}
\abx@aux@segm{0}{0}{HendrycksG16c}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{Bahat_2018}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{ghahramani}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{Sun2018KSconfA}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{subramanya}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{Goodfellow2014}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@segm{0}{0}{KendallG17}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Comparison to Novelty Detection Methods}{8}{subsection.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Summary}{8}{subsection.2.5}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of reviewed confidence measures for neural networks. Implemented baselines are indicated in bold.\relax }}{8}{table.caption.9}}
\newlabel{table:summary_literature}{{1}{8}{Summary of reviewed confidence measures for neural networks. Implemented baselines are indicated in bold.\relax }{table.caption.9}{}}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{9}{section.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview: Density Forests}{9}{subsection.3.1}}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Workflow Diagram\relax }}{10}{figure.caption.10}}
\newlabel{fig:schema}{{2}{10}{Workflow Diagram\relax }{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Decision Trees}{10}{subsection.3.2}}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@cite{Breiman2001}
\abx@aux@segm{0}{0}{Breiman2001}
\abx@aux@cite{Zoubir2007BootstrapMA}
\abx@aux@segm{0}{0}{Zoubir2007BootstrapMA}
\abx@aux@cite{Breiman1996BaggingP}
\abx@aux@segm{0}{0}{Breiman1996BaggingP}
\abx@aux@cite{CW2017}
\abx@aux@segm{0}{0}{CW2017}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\newlabel{eq:ig}{{6}{11}{Decision Trees}{equation.3.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Random Forests}{11}{subsection.3.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Density Forests}{11}{subsection.3.4}}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@segm{0}{0}{decisionForests-MSR}
\abx@aux@cite{scipy}
\abx@aux@segm{0}{0}{scipy}
\newlabel{eq:proba_density}{{10}{12}{Density Forests}{equation.3.10}{}}
\newlabel{eq:mv-gaussian}{{11}{12}{Density Forests}{equation.3.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of tree growth for a fictive dataset. Covariance ellipses are indicated in red lines and splitting lines in red dotted lines, indicating the dimension and value along which a node is split. $D_i$ and $V_i$ denote the split dimension and value of the $i$-th split. Nodes are considered leaf nodes when no further split is necessary or possible, either because the Information Gain of a new split would lower than a defined threshold or because the maximum tree depth is reached. In a \acrlong {DF}, every tree would see a subset of all points and fit slightly different leaf nodes each time.\relax }}{13}{figure.caption.11}}
\newlabel{fig:DF-split-visu}{{3}{13}{Illustration of tree growth for a fictive dataset. Covariance ellipses are indicated in red lines and splitting lines in red dotted lines, indicating the dimension and value along which a node is split. $D_i$ and $V_i$ denote the split dimension and value of the $i$-th split. Nodes are considered leaf nodes when no further split is necessary or possible, either because the Information Gain of a new split would lower than a defined threshold or because the maximum tree depth is reached. In a \acrlong {DF}, every tree would see a subset of all points and fit slightly different leaf nodes each time.\relax }{figure.caption.11}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \acrlong {DF} parameters and suggested parameter ranges.\relax }}{14}{table.caption.12}}
\newlabel{table:df-parameters}{{2}{14}{\acrlong {DF} parameters and suggested parameter ranges.\relax }{table.caption.12}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Datasets}{14}{section.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Synthetic Datasets}{14}{subsection.4.1}}
\newlabel{subsec:data-synthetic}{{4.1}{14}{Synthetic Datasets}{subsection.4.1}{}}
\abx@aux@segm{0}{0}{mnist}
\abx@aux@segm{0}{0}{mnist}
\abx@aux@segm{0}{0}{mnist}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Synthetic datasets\relax }}{15}{figure.caption.13}}
\newlabel{fig:synthetic-datasets}{{4}{15}{Synthetic datasets\relax }{figure.caption.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}MNIST Dataset}{15}{subsection.4.2}}
\abx@aux@segm{0}{0}{Volpi2017DenseSL}
\abx@aux@segm{0}{0}{Volpi2015SemanticSO}
\abx@aux@segm{0}{0}{Volpi2015SemanticSO}
\abx@aux@segm{0}{0}{Volpi2015SemanticSO}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sample images of the \gls {MNIST} dataset for true y labels 0 to 9 \cite {mnist}\relax }}{16}{figure.caption.14}}
\newlabel{fig:MNIST-Im}{{5}{16}{Sample images of the \gls {MNIST} dataset for true y labels 0 to 9 \cite {mnist}\relax }{figure.caption.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Zurich Dataset}{16}{subsection.4.3}}
\newlabel{subsec:data-zurich}{{4.3}{16}{Zurich Dataset}{subsection.4.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sample pair of images and ground truth for the Zurich dataset \cite {Volpi2015SemanticSO}\relax }}{16}{figure.caption.15}}
\newlabel{fig:zh-im-gt-pair}{{6}{16}{Sample pair of images and ground truth for the Zurich dataset \cite {Volpi2015SemanticSO}\relax }{figure.caption.15}{}}
\abx@aux@segm{0}{0}{mnist}
\abx@aux@cite{Srivastava2014DropoutAS}
\abx@aux@segm{0}{0}{Srivastava2014DropoutAS}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Label distribution in the Zurich dataset\relax }}{17}{figure.caption.16}}
\newlabel{fig:zurich-label-dist}{{7}{17}{Label distribution in the Zurich dataset\relax }{figure.caption.16}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{17}{section.5}}
\newlabel{sec:experimental-setup}{{5}{17}{Experimental Setup}{section.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Network Architectures}{17}{subsection.5.1}}
\newlabel{sec:network-architectures}{{5.1}{17}{Network Architectures}{subsection.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}MNIST dataset}{17}{subsubsection.5.1.1}}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@cite{Alom2018RecurrentRC}
\abx@aux@segm{0}{0}{Alom2018RecurrentRC}
\abx@aux@cite{Dong2017AutomaticBT}
\abx@aux@segm{0}{0}{Dong2017AutomaticBT}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Architecture of the \gls {CNN} used for \gls {MNIST} digit classification. $|b|$ = batch size, $p$ = dropout probability.\relax }}{18}{table.caption.17}}
\newlabel{table:CNN_MNIST}{{3}{18}{Architecture of the \gls {CNN} used for \gls {MNIST} digit classification. $|b|$ = batch size, $p$ = dropout probability.\relax }{table.caption.17}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Zurich dataset}{18}{subsubsection.5.1.2}}
\abx@aux@cite{Marmanis2016SemanticSO}
\abx@aux@segm{0}{0}{Marmanis2016SemanticSO}
\abx@aux@segm{0}{0}{Volpi2017DenseSL}
\abx@aux@segm{0}{0}{Volpi2017DenseSL}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces U-Net architecture, according to \textcite {ronneberger2015u}. Numbers on top of each blue block indicate the number of filters, numbers on the bottom left of the blocks indicate the resolution of each filter. \relax }}{19}{figure.caption.18}}
\newlabel{fig:u-net}{{8}{19}{U-Net architecture, according to \textcite {ronneberger2015u}. Numbers on top of each blue block indicate the number of filters, numbers on the bottom left of the blocks indicate the resolution of each filter. \relax }{figure.caption.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Image Tiling}{19}{section*.19}}
\abx@aux@cite{scikit-learn}
\abx@aux@segm{0}{0}{scikit-learn}
\abx@aux@cite{Hinneburg2000WhatIT}
\abx@aux@segm{0}{0}{Hinneburg2000WhatIT}
\abx@aux@cite{Hinneburg1999OptimalGT}
\abx@aux@segm{0}{0}{Hinneburg1999OptimalGT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Data Augmentation}{20}{section*.20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Novelty Detection Baselines}{20}{subsection.5.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}MSR, Margin, Entropy}{20}{subsubsection.5.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}MC-Dropout}{20}{subsubsection.5.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Pre-softmax methods}{20}{subsubsection.5.2.3}}
\abx@aux@cite{Maaten2008VisualizingDU}
\abx@aux@segm{0}{0}{Maaten2008VisualizingDU}
\abx@aux@segm{0}{0}{Maaten2008VisualizingDU}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Dimensionality Reduction and Data Separability}{21}{subsection.5.3}}
\newlabel{subsec:methodology-dim-reduction}{{5.3}{21}{Dimensionality Reduction and Data Separability}{subsection.5.3}{}}
\newlabel{fig:pca_components_mnist}{{9a}{21}{\gls {MNIST} dataset, left-out class 8\relax }{figure.caption.21}{}}
\newlabel{sub@fig:pca_components_mnist}{{a}{21}{\gls {MNIST} dataset, left-out class 8\relax }{figure.caption.21}{}}
\newlabel{fig:pca_components_zurich}{{9b}{21}{Zurich dataset, left-out class roads\relax }{figure.caption.21}{}}
\newlabel{sub@fig:pca_components_zurich}{{b}{21}{Zurich dataset, left-out class roads\relax }{figure.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Explained variance as a function of the number of components\relax }}{21}{figure.caption.21}}
\newlabel{fig:pca_components}{{9}{21}{Explained variance as a function of the number of components\relax }{figure.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \gls {t-SNE} schema with toy data. \gls {t-SNE} finds a mapping between the original, high-dimensional data (left) and the data in a lower dimensionality (right). Classes of data points are shown in blue, red and green. If data points within the same class are more similar to each other in high-dimensional space, they will be closer to each other in the \gls {t-SNE} visualization.\relax }}{22}{figure.caption.22}}
\newlabel{fig:t-SNE-schema}{{10}{22}{\gls {t-SNE} schema with toy data. \gls {t-SNE} finds a mapping between the original, high-dimensional data (left) and the data in a lower dimensionality (right). Classes of data points are shown in blue, red and green. If data points within the same class are more similar to each other in high-dimensional space, they will be closer to each other in the \gls {t-SNE} visualization.\relax }{figure.caption.22}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Evaluation}{22}{subsection.5.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \acrlong {CM} for classification problem with $r$ classes. UA = User's Accuracy = Precision, PA = Producer's Accuracy = Recall, OA = Overall Accuracy, $1,2,\mathinner {\ldotp \ldotp \ldotp },r$=classes. $n_{ij}$ counts the number of labels predicted as class $i$ and belonging to the true class $j$. Bullet indexes signify either the sum of the row (e.g., $n_{O\bullet }$), the sum of the column (e.g., $n_{\bullet O}$) or the sum of all elements of the \acrlong {CM} ($n_{\bullet \bullet }$).\relax }}{23}{table.caption.23}}
\newlabel{table:cm}{{4}{23}{\acrlong {CM} for classification problem with $r$ classes. UA = User's Accuracy = Precision, PA = Producer's Accuracy = Recall, OA = Overall Accuracy, $1,2,\hdots ,r$=classes. $n_{ij}$ counts the number of labels predicted as class $i$ and belonging to the true class $j$. Bullet indexes signify either the sum of the row (e.g., $n_{O\bullet }$), the sum of the column (e.g., $n_{\bullet O}$) or the sum of all elements of the \acrlong {CM} ($n_{\bullet \bullet }$).\relax }{table.caption.23}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Hyperparameter Search}{23}{subsection.5.5}}
\newlabel{subsec:hyperparameter-search}{{5.5}{23}{Hyperparameter Search}{subsection.5.5}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \acrlong {DF} parameters for each dataset\relax }}{23}{table.caption.24}}
\newlabel{table:synthetic-parameters}{{5}{23}{\acrlong {DF} parameters for each dataset\relax }{table.caption.24}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{24}{section.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Experiments}{24}{subsection.6.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Synthetic Data}{24}{subsection.6.2}}
\newlabel{subsec:results-synthetic}{{6.2}{24}{Synthetic Data}{subsection.6.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Covariance ellipses of individual Density Tree (subset of all points shown)\relax }}{24}{figure.caption.25}}
\newlabel{fig:gen-data}{{11}{24}{Covariance ellipses of individual Density Tree (subset of all points shown)\relax }{figure.caption.25}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Splitting steps of a single node, showing the data, covariance ellipses and information gain of the parent node for dataset 2\relax }}{25}{figure.caption.26}}
\newlabel{fig:D2-covs-steps}{{12}{25}{Splitting steps of a single node, showing the data, covariance ellipses and information gain of the parent node for dataset 2\relax }{figure.caption.26}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Gaussian \gls {PDF} distribution according to single tree, and according to a \acrlong {DF} consisting of 20 trees\relax }}{26}{figure.caption.27}}
\newlabel{fig:gen-data-heatmap}{{13}{26}{Gaussian \gls {PDF} distribution according to single tree, and according to a \acrlong {DF} consisting of 20 trees\relax }{figure.caption.27}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}MNIST}{26}{subsection.6.3}}
\newlabel{subsec:results-MNIST}{{6.3}{26}{MNIST}{subsection.6.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Mean Overall Accuracy in \% for the \gls {CNN} models trained on $N-1$ classes\relax }}{27}{table.caption.28}}
\newlabel{table:mnist-nd-accuracy-mean}{{6}{27}{Mean Overall Accuracy in \% for the \gls {CNN} models trained on $N-1$ classes\relax }{table.caption.28}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Predicted labels for networks with left-out classes 4 and 8 (top) and 1 and 7 (bottom). While digits showing a 4 are mostly mislabeled as a 9, the digit 8 is mislabeled less homogeneously. While one could suppose that digits 1 and 7 look similar and might be confused, digits 7 are mostly classified as digit 9, and digit 1 mostly as digits 4 and 8.\relax }}{27}{figure.caption.29}}
\newlabel{fig:pred-count-mnist}{{14}{27}{Predicted labels for networks with left-out classes 4 and 8 (top) and 1 and 7 (bottom). While digits showing a 4 are mostly mislabeled as a 9, the digit 8 is mislabeled less homogeneously. While one could suppose that digits 1 and 7 look similar and might be confused, digits 7 are mostly classified as digit 9, and digit 1 mostly as digits 4 and 8.\relax }{figure.caption.29}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \gls {t-SNE} of \gls {MNIST} activations, model with left-out class 7. Both before and after \gls {PCA}, activations of different classes seem well separable, including the unseen class. \relax }}{28}{figure.caption.30}}
\newlabel{fig:tsne-mnist}{{15}{28}{\gls {t-SNE} of \gls {MNIST} activations, model with left-out class 7. Both before and after \gls {PCA}, activations of different classes seem well separable, including the unseen class. \relax }{figure.caption.30}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces t-SNE of \gls {MNIST} activations, after \gls {PCA} transformations.\relax }}{29}{figure.caption.31}}
\newlabel{fig:tsne-mnist-miscl}{{16}{29}{t-SNE of \gls {MNIST} activations, after \gls {PCA} transformations.\relax }{figure.caption.31}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Mean \gls {AUROC} for each left-out class in the \gls {MNIST} dataset\relax }}{29}{table.caption.32}}
\newlabel{table:mnist-auroc-nd-mean}{{7}{29}{Mean \gls {AUROC} for each left-out class in the \gls {MNIST} dataset\relax }{table.caption.32}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Zurich Dataset}{30}{subsection.6.4}}
\newlabel{subsec:results-zurich}{{6.4}{30}{Zurich Dataset}{subsection.6.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Overall Results}{30}{subsubsection.6.4.1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Test set accuracy for the UNET \gls {CNN} trained on all classes (Overall Accuracy: 77.59 \%)\relax }}{30}{table.caption.33}}
\newlabel{table:zurich-cnn-acc-all}{{8}{30}{Test set accuracy for the UNET \gls {CNN} trained on all classes (Overall Accuracy: 77.59 \%)\relax }{table.caption.33}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Accuracy measures for the UNET \gls {CNN} trained on $N-1$ classes.\relax }}{30}{table.caption.34}}
\newlabel{table:zurich-cnn-acc-nd}{{9}{30}{Accuracy measures for the UNET \gls {CNN} trained on $N-1$ classes.\relax }{table.caption.34}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Prediction and ground truth for the model trained without the roads class\relax }}{31}{figure.caption.35}}
\newlabel{fig:pred-gt-road}{{17}{31}{Prediction and ground truth for the model trained without the roads class\relax }{figure.caption.35}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Predictions for network with left-out class ``roads'' and ``trees''. While roads are mostly mislabelled as buildings, trees are mislabelled less homogeneously.\relax }}{31}{figure.caption.36}}
\newlabel{fig:pred-count-zurich}{{18}{31}{Predictions for network with left-out class ``roads'' and ``trees''. While roads are mostly mislabelled as buildings, trees are mislabelled less homogeneously.\relax }{figure.caption.36}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces \gls {t-SNE} of Zurich dataset activations, model with left-out class buildings. The same number of points are shown by class, although the real class distribution is imbalanced (cf. figure \ref  {fig:zurich-label-dist}).\relax }}{32}{figure.caption.37}}
\newlabel{fig:tsne-zurich}{{19}{32}{\gls {t-SNE} of Zurich dataset activations, model with left-out class buildings. The same number of points are shown by class, although the real class distribution is imbalanced (cf. figure \ref {fig:zurich-label-dist}).\relax }{figure.caption.37}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces \gls {t-SNE} of Zurich dataset activations after \gls {PCA} for left-out classes ``Roads'' and ``Trees''.\relax }}{33}{figure.caption.38}}
\newlabel{fig:tsne-zurich-miscl}{{20}{33}{\gls {t-SNE} of Zurich dataset activations after \gls {PCA} for left-out classes ``Roads'' and ``Trees''.\relax }{figure.caption.38}{}}
\abx@aux@cite{Gonzlez2012DigitalIP}
\abx@aux@segm{0}{0}{Gonzlez2012DigitalIP}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces \gls {AUROC} for each left-out class\relax }}{34}{table.caption.39}}
\newlabel{table:zurich-auroc-nd}{{10}{34}{\gls {AUROC} for each left-out class\relax }{table.caption.39}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Visual Interpretation}{34}{subsubsection.6.4.2}}
\newlabel{subfig:original-im}{{21c}{35}{Original confidence image\relax }{figure.caption.40}{}}
\newlabel{sub@subfig:original-im}{{c}{35}{Original confidence image\relax }{figure.caption.40}{}}
\newlabel{subfig:equalized-im}{{21d}{35}{Equalized confidence image\relax }{figure.caption.40}{}}
\newlabel{sub@subfig:equalized-im}{{d}{35}{Equalized confidence image\relax }{figure.caption.40}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Original and equalized confidence distributions for \gls {DF}, using the left-out class ``Roads''. While outliers are visible in the original figure, smaller confidence differences between classes are better visible after histogram equalization.\relax }}{35}{figure.caption.40}}
\newlabel{fig:hist-eq}{{21}{35}{Original and equalized confidence distributions for \gls {DF}, using the left-out class ``Roads''. While outliers are visible in the original figure, smaller confidence differences between classes are better visible after histogram equalization.\relax }{figure.caption.40}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Visual uncertainty results for selected methods on left-out class ``roads'' and corresponding ground truth. Contrast stretching and histogram equalization have been applied to \gls {OC-SVM} and \gls {DF} images for better visibility. Variance per \gls {PCA} component and \gls {ROC} curves are shown below the confidence images.\relax }}{36}{figure.caption.41}}
\newlabel{fig:im_cert_1}{{22}{36}{Visual uncertainty results for selected methods on left-out class ``roads'' and corresponding ground truth. Contrast stretching and histogram equalization have been applied to \gls {OC-SVM} and \gls {DF} images for better visibility. Variance per \gls {PCA} component and \gls {ROC} curves are shown below the confidence images.\relax }{figure.caption.41}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Visual uncertainty results for selected methods on left-out class ``trees'' and corresponding ground truth. Contrast stretching and histogram equalization have been applied to \gls {OC-SVM} and \gls {DF} images for better visibility. Variance per \gls {PCA} component and \gls {ROC} curves are shown below the confidence images.\relax }}{38}{figure.caption.42}}
\newlabel{fig:im_cert_3}{{23}{38}{Visual uncertainty results for selected methods on left-out class ``trees'' and corresponding ground truth. Contrast stretching and histogram equalization have been applied to \gls {OC-SVM} and \gls {DF} images for better visibility. Variance per \gls {PCA} component and \gls {ROC} curves are shown below the confidence images.\relax }{figure.caption.42}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Confidence for the left-out class ``Trees'' according to different methods plotted onto \gls {t-SNE}, showing the $n$ points with the lowest confidence where $n$ is the number of points per class shown in the \gls {t-SNE} plot. Points of the unseen classes are indicated with a solid-edge circle. Ideally, all solid-edge circles should be red, and all other points green. The original \gls {t-SNE} plot and the \gls {ROC} curves for each method are shown for comparison.\relax }}{39}{figure.caption.43}}
\newlabel{fig:t-SNE-probas_3}{{24}{39}{Confidence for the left-out class ``Trees'' according to different methods plotted onto \gls {t-SNE}, showing the $n$ points with the lowest confidence where $n$ is the number of points per class shown in the \gls {t-SNE} plot. Points of the unseen classes are indicated with a solid-edge circle. Ideally, all solid-edge circles should be red, and all other points green. The original \gls {t-SNE} plot and the \gls {ROC} curves for each method are shown for comparison.\relax }{figure.caption.43}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Particular Objects}{40}{subsubsection.6.4.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Swimming pool object with MSR and \gls {DF} confidence images\relax }}{41}{figure.caption.44}}
\newlabel{fig:obj-im1}{{25}{41}{Swimming pool object with MSR and \gls {DF} confidence images\relax }{figure.caption.44}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Soccer pitch object with \gls {MSR} and \gls {DF} confidence scores\relax }}{42}{figure.caption.45}}
\newlabel{fig:obj-im4}{{26}{42}{Soccer pitch object with \gls {MSR} and \gls {DF} confidence scores\relax }{figure.caption.45}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{43}{section.7}}
\newlabel{sec:discussion}{{7}{43}{Discussion}{section.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Softmax-based Methods}{43}{subsection.7.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Pre-softmax-based Methods}{43}{subsection.7.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Dimensionality Reduction}{43}{section*.46}}
\abx@aux@segm{0}{0}{Hinneburg2000WhatIT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Gaussianity in high dimensions}{44}{section*.47}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Class confusion}{44}{section*.48}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Method Aspects}{44}{section*.49}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{45}{section.8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Main Contributions}{45}{subsection.8.1}}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@cite{Berkeley2015HypercolumnsFO}
\abx@aux@segm{0}{0}{Berkeley2015HypercolumnsFO}
\abx@aux@segm{0}{0}{mandelbaum17}
\abx@aux@segm{0}{0}{mandelbaum17}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Future Research}{46}{subsection.8.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Datasets and Architectures}{46}{section*.50}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Dimensionality Reduction}{46}{section*.51}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Meta-Loss to Increase Class Separability}{46}{section*.52}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Parameter sensitivity}{46}{section*.53}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Further research ideas}{47}{section*.54}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Alternative confidence measure scheme: red parts are to be retrieved and their entropy calculated to measure the degree of agreement of the input to the softmax activation function.\relax }}{47}{figure.caption.55}}
\newlabel{fig:nn_scheme}{{27}{47}{Alternative confidence measure scheme: red parts are to be retrieved and their entropy calculated to measure the degree of agreement of the input to the softmax activation function.\relax }{figure.caption.55}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Evaluation}{47}{section*.56}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Conclusion}{47}{section*.57}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {9}Appendices}{53}{section.9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {A}Code Documentation}{53}{subsection.9.1}}
\newlabel{subsec:implementation}{{A}{53}{Code Documentation}{subsection.9.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {B}Random Forest}{53}{subsection.9.2}}
\newlabel{app:rf}{{B}{53}{Random Forest}{subsection.9.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Decision boundaries of a single Decision Tree on 2-dimensional synthetic data, splitting the data until every leaf node only contains data of one cluster. Left: decision boundaries with Data, right: decision boundaries only. The Decision Tree clearly overfits the data.\relax }}{53}{figure.caption.59}}
\newlabel{fig:decision-boundaries}{{B.1}{53}{Decision boundaries of a single Decision Tree on 2-dimensional synthetic data, splitting the data until every leaf node only contains data of one cluster. Left: decision boundaries with Data, right: decision boundaries only. The Decision Tree clearly overfits the data.\relax }{figure.caption.59}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Decision tree with unlimited depth on the training data for shown for illustrative purposes, with the split dimension and value at every non-leaf node and the class label at every leaf node. The tree clearly overfits the data and produces edgy decision boundaries\relax }}{54}{figure.caption.60}}
\newlabel{fig:decision_tree}{{B.2}{54}{Decision tree with unlimited depth on the training data for shown for illustrative purposes, with the split dimension and value at every non-leaf node and the class label at every leaf node. The tree clearly overfits the data and produces edgy decision boundaries\relax }{figure.caption.60}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Decision boundaries of a Random Forest on 2-dimensional synthetic data. 1000 Decision Trees have been trained on a 30\% bootstrap sample of the original data. Left: decision boundaries with Data, right: decision boundaries only. The Random Forest manages to smooth out the class decision boundaries.\relax }}{54}{figure.caption.61}}
\newlabel{fig:rf}{{B.3}{54}{Decision boundaries of a Random Forest on 2-dimensional synthetic data. 1000 Decision Trees have been trained on a 30\% bootstrap sample of the original data. Left: decision boundaries with Data, right: decision boundaries only. The Random Forest manages to smooth out the class decision boundaries.\relax }{figure.caption.61}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {C}Data Structure}{55}{subsection.9.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {C.1}{\ignorespaces Implemented data structure for Decision Tree nodes. Every node saves a pointer to its parent, the unique labels contained at its split level, the split dimension and value, methods for tree descending and formatting as well information about its child nodes.\relax }}{55}{figure.caption.62}}
\newlabel{fig:decision-node}{{C.1}{55}{Implemented data structure for Decision Tree nodes. Every node saves a pointer to its parent, the unique labels contained at its split level, the split dimension and value, methods for tree descending and formatting as well information about its child nodes.\relax }{figure.caption.62}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {C.2}{\ignorespaces Implemented data structure for Density Tree nodes. Every node saves a pointer to its parent, the unique labels contained at its split level, the split dimension and value, methods for tree descending and formatting as well information about its child nodes. In addition, every root node pre-stores the inverse and determinant of the covariance matrix of both clusters situated to the right and left of the node for faster calculation of the Gaussian \gls {PDF}.\relax }}{55}{figure.caption.63}}
\newlabel{fig:density-node}{{C.2}{55}{Implemented data structure for Density Tree nodes. Every node saves a pointer to its parent, the unique labels contained at its split level, the split dimension and value, methods for tree descending and formatting as well information about its child nodes. In addition, every root node pre-stores the inverse and determinant of the covariance matrix of both clusters situated to the right and left of the node for faster calculation of the Gaussian \gls {PDF}.\relax }{figure.caption.63}{}}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\abx@aux@segm{0}{0}{ronneberger2015u}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {D}MNIST Evaluation Metrics}{56}{subsection.9.4}}
\newlabel{subsec:app-eval-mnist}{{D}{56}{MNIST Evaluation Metrics}{subsection.9.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {D.1}{\ignorespaces Accuracy metrics in \% for the \gls {CNN} trained on $N-1$ classes for the \gls {MNIST} dataset\relax }}{56}{table.caption.64}}
\newlabel{table:mnist-nd-accuracy}{{D.1}{56}{Accuracy metrics in \% for the \gls {CNN} trained on $N-1$ classes for the \gls {MNIST} dataset\relax }{table.caption.64}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {D.2}{\ignorespaces \gls {AUROC} for each left-out class in the \gls {MNIST} dataset\relax }}{56}{table.caption.65}}
\newlabel{table:mnist-auroc-nd}{{D.2}{56}{\gls {AUROC} for each left-out class in the \gls {MNIST} dataset\relax }{table.caption.65}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {E}Zurich Network Architecture}{57}{subsection.9.5}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {E.1}{\ignorespaces U-Net Architecture of the \gls {CNN} used for Zurich Dataset, according to \textcite {ronneberger2015u}. Conv. = convolution, filt = filters, str = stride, $p$ = dropout probability, dim = dimensions, Input dimensions $|b|, w, h, n_c$ = batch size, width, height, number of channels. A convolution or transpose convolution always takes the previous layer in the network as input.\relax }}{57}{table.caption.66}}
\newlabel{table:CNN_Zurich}{{E.1}{57}{U-Net Architecture of the \gls {CNN} used for Zurich Dataset, according to \textcite {ronneberger2015u}. Conv. = convolution, filt = filters, str = stride, $p$ = dropout probability, dim = dimensions, Input dimensions $|b|, w, h, n_c$ = batch size, width, height, number of channels. A convolution or transpose convolution always takes the previous layer in the network as input.\relax }{table.caption.66}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {F}MNIST Dataset Figures}{58}{subsection.9.6}}
\newlabel{app:mnist-figures}{{F}{58}{MNIST Dataset Figures}{subsection.9.6}{}}
\newlabel{subfig:MNIST-pred_count-0}{{F.1a}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-0}{{a}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-1}{{F.1b}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-1}{{b}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-2}{{F.1c}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-2}{{c}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-3}{{F.1d}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-3}{{d}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-4}{{F.1e}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-4}{{e}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-5}{{F.1f}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-5}{{f}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-6}{{F.1g}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-6}{{g}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-7}{{F.1h}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-7}{{h}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-8}{{F.1i}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-8}{{i}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-pred_count-9}{{F.1j}{58}{Class \class \relax }{figure.caption.67}{}}
\newlabel{sub@subfig:MNIST-pred_count-9}{{j}{58}{Class \class \relax }{figure.caption.67}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {F.1}{\ignorespaces Count of predictions for each left-out class\relax }}{58}{figure.caption.67}}
\newlabel{fig:MNIST_pred_count_all}{{F.1}{58}{Count of predictions for each left-out class\relax }{figure.caption.67}{}}
\newlabel{subfig:MNIST-tsne-0}{{F.2a}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-0}{{a}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-1}{{F.2b}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-1}{{b}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-2}{{F.2c}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-2}{{c}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-3}{{F.2d}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-3}{{d}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-4}{{F.2e}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-4}{{e}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-5}{{F.2f}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-5}{{f}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-6}{{F.2g}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-6}{{g}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-7}{{F.2h}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-7}{{h}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-8}{{F.2i}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-8}{{i}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{subfig:MNIST-tsne-9}{{F.2j}{59}{Class \class \relax }{figure.caption.68}{}}
\newlabel{sub@subfig:MNIST-tsne-9}{{j}{59}{Class \class \relax }{figure.caption.68}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {F.2}{\ignorespaces \gls {t-SNE} of \gls {MNIST} dataset activations after \gls {PCA} transformations for each left-out class\relax }}{59}{figure.caption.68}}
\newlabel{fig:tsne-mnist-all-cl}{{F.2}{59}{\gls {t-SNE} of \gls {MNIST} dataset activations after \gls {PCA} transformations for each left-out class\relax }{figure.caption.68}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {G}Zurich Dataset Figures}{60}{subsection.9.7}}
\newlabel{app:zurich-figures}{{G}{60}{Zurich Dataset Figures}{subsection.9.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.1}{\ignorespaces Count of label predictions for each left-out class and for the \gls {CNN} trained on all classes\relax }}{60}{figure.caption.69}}
\newlabel{fig:pred-count-zurich-all-cl}{{G.1}{60}{Count of label predictions for each left-out class and for the \gls {CNN} trained on all classes\relax }{figure.caption.69}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.2}{\ignorespaces Explained variance by first \gls {PCA} components, for activations of each left-out class and for activations of the model trained on all classes. The number of \gls {PCA} components was chosen such as to explain more than 95\% of the variance.\relax }}{61}{figure.caption.70}}
\newlabel{fig:pca-zurich-all-cl}{{G.2}{61}{Explained variance by first \gls {PCA} components, for activations of each left-out class and for activations of the model trained on all classes. The number of \gls {PCA} components was chosen such as to explain more than 95\% of the variance.\relax }{figure.caption.70}{}}
\newlabel{subfig:tsne-1}{{G.3a}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-1}{{a}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-2}{{G.3b}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-2}{{b}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-3}{{G.3c}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-3}{{c}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-4}{{G.3d}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-4}{{d}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-5}{{G.3e}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-5}{{e}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-6}{{G.3f}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-6}{{f}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-7}{{G.3g}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-7}{{g}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{subfig:tsne-8}{{G.3h}{62}{\classname {}\relax }{figure.caption.71}{}}
\newlabel{sub@subfig:tsne-8}{{h}{62}{\classname {}\relax }{figure.caption.71}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.3}{\ignorespaces \gls {t-SNE} of Zurich dataset activations after \gls {PCA} transformations for each left-out class and for the activations of the network trained on all classes. The same number of points are shown by class to show class separability, although the real class distribution is imbalanced (cf. table \ref  {table:zurich-cnn-acc-all}).\relax }}{62}{figure.caption.71}}
\newlabel{fig:tsne-zurich-all-cl}{{G.3}{62}{\gls {t-SNE} of Zurich dataset activations after \gls {PCA} transformations for each left-out class and for the activations of the network trained on all classes. The same number of points are shown by class to show class separability, although the real class distribution is imbalanced (cf. table \ref {table:zurich-cnn-acc-all}).\relax }{figure.caption.71}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.4}{\ignorespaces Image and ground truth for visualized novelty detection methods\relax }}{63}{figure.caption.72}}
\newlabel{fig:app-im-gt-methods}{{G.4}{63}{Image and ground truth for visualized novelty detection methods\relax }{figure.caption.72}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.5}{\ignorespaces Ground truth and visual results for left-out class ``roads''.\relax }}{64}{figure.caption.73}}
\newlabel{fig:zurich-im-uncert-1}{{G.5}{64}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.73}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.6}{\ignorespaces Ground truth and visual results for left-out class ``buildings''.\relax }}{65}{figure.caption.74}}
\newlabel{fig:zurich-im-uncert-2}{{G.6}{65}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.74}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.7}{\ignorespaces Ground truth and visual results for left-out class ``trees''.\relax }}{66}{figure.caption.75}}
\newlabel{fig:zurich-im-uncert-3}{{G.7}{66}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.75}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.8}{\ignorespaces Ground truth and visual results for left-out class ``grass''.\relax }}{67}{figure.caption.76}}
\newlabel{fig:zurich-im-uncert-4}{{G.8}{67}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.76}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.9}{\ignorespaces Ground truth and visual results for left-out class ``bare soil''.\relax }}{68}{figure.caption.77}}
\newlabel{fig:zurich-im-uncert-5}{{G.9}{68}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.77}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.10}{\ignorespaces Ground truth and visual results for left-out class ``water''.\relax }}{69}{figure.caption.78}}
\newlabel{fig:zurich-im-uncert-6}{{G.10}{69}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.78}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.11}{\ignorespaces Ground truth and visual results for left-out class ``railways''.\relax }}{70}{figure.caption.79}}
\newlabel{fig:zurich-im-uncert-7}{{G.11}{70}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.79}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.12}{\ignorespaces Ground truth and visual results for left-out class ``swimming pools''.\relax }}{71}{figure.caption.80}}
\newlabel{fig:zurich-im-uncert-8}{{G.12}{71}{Ground truth and visual results for left-out class ``\classname ''.\relax }{figure.caption.80}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {G.13}{\ignorespaces \gls {ROC} curves of confidence measures for novelty detection and for error detection\relax }}{72}{figure.caption.81}}
\newlabel{fig:zurich-nd-roc}{{G.13}{72}{\gls {ROC} curves of confidence measures for novelty detection and for error detection\relax }{figure.caption.81}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {H}Hyperparameter Search Results}{73}{subsection.9.8}}
\newlabel{app:hyperparameters}{{H}{73}{Hyperparameter Search Results}{subsection.9.8}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {H.1}{\ignorespaces Best hyperparameters for the \gls {MNIST} Dataset\relax }}{73}{table.caption.82}}
\newlabel{table:hyperparameters-results-mnist}{{H.1}{73}{Best hyperparameters for the \gls {MNIST} Dataset\relax }{table.caption.82}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {H.2}{\ignorespaces Best hyperparameters for the Zurich Dataset\relax }}{74}{table.caption.83}}
\newlabel{table:hyperparameters-results-zurich}{{H.2}{74}{Best hyperparameters for the Zurich Dataset\relax }{table.caption.83}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {H.1}{\ignorespaces \gls {RBF} Kernel visualizations for \acrlong {OC-SVM} in Zurich dataset. Kernels were applied to a class-balanced subsample of training activations belonging to the seen classes. Best kernels found using hyperparameter search are labelled in bold.\relax }}{74}{figure.caption.84}}
\newlabel{fig:oc-svm-vis-rbf}{{H.1}{74}{\gls {RBF} Kernel visualizations for \acrlong {OC-SVM} in Zurich dataset. Kernels were applied to a class-balanced subsample of training activations belonging to the seen classes. Best kernels found using hyperparameter search are labelled in bold.\relax }{figure.caption.84}{}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{Alom2018RecurrentRC}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Bahat_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Beghi2014AOS}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Bishop1994NoveltyDA}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Breiman1996BaggingP}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Breiman2001}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Breunig2000LOFID}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Berkeley2015HypercolumnsFO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Choi2017UncertaintyAwareLF}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{decisionForests-MSR}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Dempster1977MaximumLF}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gonzlez2012DigitalIP}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Dong2017AutomaticBT}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gal2016Uncertainty}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gal2015Dropout}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ghahramani}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Goodfellow2014}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hammer2007HowTP}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{HendrycksG16c}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hinneburg2000WhatIT}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hinneburg1999OptimalGT}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kampffmeyer}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Kampffmeyer2016SemanticSO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{KendallG17}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Lakshminarayanan16}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnist}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{leibig2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Levinson2011TowardsFA}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Liu2008IsolationF}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Maaten2008VisualizingDU}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mandelbaum17}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Markou2003NoveltyDApt1}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Markou2003NoveltyDApt2}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Marmanis2016SemanticSO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{menderes_automatic_2015}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{deMorsier2014thesis}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{NguyenYC14}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ouerghemmi_two-step_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{scikit-learn}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Pimentel2014ARO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{postadjian_investigating_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Reynolds2009GaussianMM}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ronneberger2015u}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Rupprecht2017LearningIA}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Schmidhuber2015DeepLI}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{scipy}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Shelhamer2015FullyCN}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Srivastava2014DropoutAS}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{subramanya}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Sun2018KSconfA}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Szymanski2011VisualisingKS}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{tuiaAL2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Tuia2011ASO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Volpi2015SemanticSO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Volpi2017DenseSL}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Wang2004AnomalyID}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{CW2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{womble_automated_2007}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{zaragoza}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Zhu2017DeepLI}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Zoubir2007BootstrapMA}{nyt/global//global/global}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {H.2}{\ignorespaces Polynomial kernel visualizations for \acrlong {OC-SVM} in Zurich dataset with best degree $r$. Kernels were applied to a class-balanced subsample of training activations belonging to the seen classes. Contrast stretching has been applied to the images of the polynomial kernels to highlight more local variation. Best kernels found using hyperparameter search are labelled in bold.\relax }}{75}{figure.caption.85}}
\newlabel{fig:oc-svm-vis-poly}{{H.2}{75}{Polynomial kernel visualizations for \acrlong {OC-SVM} in Zurich dataset with best degree $r$. Kernels were applied to a class-balanced subsample of training activations belonging to the seen classes. Contrast stretching has been applied to the images of the polynomial kernels to highlight more local variation. Best kernels found using hyperparameter search are labelled in bold.\relax }{figure.caption.85}{}}
