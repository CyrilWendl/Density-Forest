{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zurich Land Cover Classification\n",
    "\n",
    "This script presents a visualization of training a U-Net classifier on 7 out of 8 available land cover classes of the Zurich dataset, and detecting the unseen class using the following Baseline Method:\n",
    "## Dropout as a Bayesian Approximation\n",
    "https://arxiv.org/abs/1506.02142\n",
    "\n",
    "Data Visualizations are contained in the notebook `Zurich Land Cover Density Forest.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14608742313003633077\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 30015488\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6609931628623192634\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraries\n",
    "from matplotlib.patches import Rectangle\n",
    "import natsort as ns\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "\n",
    "# custom libraries\n",
    "from helpers.helpers import *\n",
    "from helpers.data_augment import *\n",
    "from keras_helpers.unet import *\n",
    "from keras_helpers.helpers import *\n",
    "from keras_helpers.callbacks import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Meta-Parameters\n",
    "#base_dir = '/Users/cyrilwendl/Documents/EPFL'  # for local machine\n",
    "base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "sys.path.append(base_dir + '/SIE-Master/Code') # Path to density Tree package Tree package\n",
    "\n",
    "# custom libraries\n",
    "from density_tree.density_forest import *\n",
    "from density_tree.helpers import print_density_tree_latex\n",
    "from helpers.helpers import imgs_stretch_eq\n",
    "from baselines.helpers import *\n",
    "from baselines.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_remove = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 20 \n",
      "ground truth images: 20 \n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "im_dir = r'' + path + '/Zurich_dataset/images_tif/'\n",
    "gt_dir = r'' + path + '/Zurich_dataset/groundtruth/'\n",
    "\n",
    "im_names = ns.natsorted(os.listdir(im_dir))\n",
    "gt_names = ns.natsorted(os.listdir(gt_dir))\n",
    "print(\"images: %i \" % len(im_names))\n",
    "print(\"ground truth images: %i \" % len(gt_names))\n",
    "\n",
    "imgs = np.asarray([im_load(im_dir + im_name) for im_name in im_names])\n",
    "gt = np.asarray([im_load(gt_dir + gt_name) for gt_name in gt_names])\n",
    "\n",
    "# histogram stretching\n",
    "imgs_eq = imgs_stretch_eq(imgs)\n",
    "imgs = imgs_eq  # continue using stretched image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. GT to labels\n",
    "Next, we need to convert the ground truth (colors) to labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = OrderedDict((('Background', [255, 255, 255]),\n",
    "                      ('Roads', [0, 0, 0]),\n",
    "                      ('Buildings', [100, 100, 100]),\n",
    "                      ('Trees', [0, 125, 0]),\n",
    "                      ('Grass', [0, 255, 0]),\n",
    "                      ('Bare Soil', [150, 80, 0]),\n",
    "                      ('Water', [0, 0, 150]),\n",
    "                      ('Railways', [255, 255, 0]),\n",
    "                      ('Swimming Pools', [150, 150, 255])))\n",
    "\n",
    "# get class names by increasing value (as done above)\n",
    "names, colors = [], []\n",
    "for name, color in legend.items():\n",
    "    names.append(name)\n",
    "    colors.append(color)\n",
    "\n",
    "gt_maj_label = gt_color_to_label(gt, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels in GT:  [0. 1. 2. 3. 4. 5. 6. 7. 8.]\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Load Images\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "flat_labels = flatten(flatten(gt_maj_label))\n",
    "print(\"Unique Labels in GT: \", np.unique(flat_labels))\n",
    "print(np.shape(gt_maj_label))\n",
    "gt = gt_maj_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Get patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3902, 64, 64, 4)\n",
      "(964, 64, 64, 4)\n",
      "(964, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Get patches\n",
    "patch_size = 64\n",
    "stride_train = 64  # has to be <= patch_size\n",
    "stride_test = 32  # has to be <= patch_size\n",
    "\n",
    "# ids for training, validation and test sets (0-19)\n",
    "ids_train = np.arange(0, 12)\n",
    "ids_val = np.arange(12, 16)\n",
    "ids_test = np.arange(16, 20)\n",
    "\n",
    "# get training, test and validation sets\n",
    "x_train = get_padded_patches(imgs[ids_train], patch_size=patch_size, stride=stride_train)\n",
    "x_val = get_padded_patches(imgs[ids_val], patch_size=patch_size, stride=stride_train)\n",
    "x_test = get_padded_patches(imgs[ids_test], patch_size=patch_size, stride=stride_test)\n",
    "x_test_nostride = get_padded_patches(imgs[ids_test], patch_size=patch_size, stride=patch_size)\n",
    "\n",
    "y_train = get_gt_patches(gt[ids_train], patch_size=patch_size, stride=stride_train)\n",
    "y_val = get_gt_patches(gt[ids_val], patch_size=patch_size, stride=stride_train)\n",
    "y_test = get_gt_patches(gt[ids_test], patch_size=patch_size, stride=stride_test)\n",
    "y_test_nostride = get_gt_patches(gt[ids_test], patch_size=patch_size, stride=patch_size)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test_nostride.shape)\n",
    "print(y_test_nostride.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras CNN\n",
    "\n",
    "Data Split: \n",
    "- Training: 12 images\n",
    "- Validation: 4 images\n",
    "- Test: 4 images\n",
    "\n",
    "Tested Architectures: \n",
    "\n",
    "| Model | Patch Size | Data Augmentations | Number of Parameters | Testing Precision (avg) | Testing Recall (avg) | Testing f1 score (avg) | Validation / Test accuracy |\n",
    "| ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| U-Net | 64 | Rot 90°, Flipping  | 7,828,200 | 0.87 | 0.858 | 0.86 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.69 | 0.61 | 0.64 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.90 | 0.89 | 0.89 | v |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copies of original data\n",
    "y_train_label = y_train.copy()\n",
    "y_val_label = y_val.copy()\n",
    "y_test_label = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n",
      "Class weights:\n",
      "     Background: 0.000\n",
      "          Roads: 0.757\n",
      "      Buildings: 0.480\n",
      "          Trees: 1.508\n",
      "          Grass: 2.105\n",
      "      Bare Soil: 7.000\n",
      "          Water: 2.006\n",
      "       Railways: 6.211\n",
      " Swimming Pools: 7.000\n"
     ]
    }
   ],
   "source": [
    "# get class weights\n",
    "labels_unique = np.unique(y_train.flatten())\n",
    "print(labels_unique)\n",
    "class_weights = class_weight.compute_class_weight('balanced', labels_unique, y_train.flatten())\n",
    "class_weights[0] = 0  # give less weight to background label class\n",
    "class_weights[5] = 7  # give less weight to bare soil class\n",
    "class_weights[8] = 7  # give less weight to swimming pool class\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(class_weights):\n",
    "    print(\"%15s: %3.3f\" % (names[i], w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes to keep: ['Roads', 'Buildings', 'Trees', 'Grass', 'Bare Soil', 'Water', 'Swimming Pools']\n",
      "(3897, 64, 64, 4)\n",
      "(3897, 64, 64, 7)\n",
      "(1117, 64, 64, 4)\n",
      "(1117, 64, 64, 7)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 9\n",
    "\n",
    "# convert to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "x_val = np.asarray(x_val)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "# make y data categorical\n",
    "y_train = to_categorical(y_train_label, n_classes)\n",
    "y_val = to_categorical(y_val_label, n_classes)\n",
    "\n",
    "# remove class\n",
    "classes_to_keep = np.asarray([x for x in range(1, n_classes) if x != class_to_remove])\n",
    "\n",
    "names_keep = np.asarray(names)[classes_to_keep]\n",
    "names_keep = names_keep.tolist()\n",
    "print(\"classes to keep: \" + str(names_keep))\n",
    "\n",
    "y_train = y_train[..., classes_to_keep]\n",
    "y_val = y_val[..., classes_to_keep]\n",
    "n_classes = len(classes_to_keep)\n",
    "class_weights = class_weights[classes_to_keep]\n",
    "\n",
    "# print shapes of variables\n",
    "for var in x_train, y_train, x_val, y_val:\n",
    "    print(np.shape(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# callbacks (evaluated every epoch)\n",
    "# show loss and accuracy figures after each epoch\n",
    "callback_plot = PlotLosses()\n",
    "\n",
    "# stop early if after several epochs the accuracy doesn't improve\n",
    "callback_earlystop = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=24, verbose=1, mode='auto')\n",
    "\n",
    "# decrease learning rate when accuracy stops improving\n",
    "callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, verbose=1, mode='auto',\n",
    "                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "# checkpoint to save weights at every epoch (in case of interruption)\n",
    "file_path = \"weights-improvement.hdf5\"\n",
    "callback_checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# model setup\n",
    "batch_size = 20\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "def model_train(model, data_augmentation):\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(batch_generator(x_train, y_train,\n",
    "                                        batch_size=batch_size, data_augmentation=data_augmentation),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        class_weight=class_weights,  # weights for loss function\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback_earlystop,\n",
    "                                   callback_lr,\n",
    "                                   #callback_checkpoint,\n",
    "                                   callback_plot,\n",
    "                                   callback_tensorboard],\n",
    "                        workers=cpu_count(),\n",
    "                        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or load model\n",
    "# train the model\n",
    "#model_unet = get_unet(n_classes, x_train.shape[1:])\n",
    "#model_train(model_unet, data_augmentation=True)\n",
    "#model_unet.save('models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')  # save model, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512]\n\t [[Node: conv2d_10/bias/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d_10/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/bias, conv2d_9/Const)]]\n\nCaused by op 'conv2d_10/bias/Assign', defined at:\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-6375b842b9c9>\", line 3, in <module>\n    model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2524, in from_config\n    process_node(layer, node_data)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2481, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 592, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 144, in build\n    constraint=self.bias_constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 416, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 395, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512]\n\t [[Node: conv2d_10/bias/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d_10/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/bias, conv2d_9/Const)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512]\n\t [[Node: conv2d_10/bias/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d_10/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/bias, conv2d_9/Const)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6375b842b9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mname_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/models_out/model_unet_64_flip_rot90_wo_cl_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_to_remove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mignore_background_class_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Early return if compilation is not required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3380\u001b[0m                              ' elements.')\n\u001b[1;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3382\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2371\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2373\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512]\n\t [[Node: conv2d_10/bias/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d_10/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/bias, conv2d_9/Const)]]\n\nCaused by op 'conv2d_10/bias/Assign', defined at:\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-6375b842b9c9>\", line 3, in <module>\n    model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2524, in from_config\n    process_node(layer, node_data)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2481, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 592, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 144, in build\n    constraint=self.bias_constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/topology.py\", line 416, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 395, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512]\n\t [[Node: conv2d_10/bias/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@conv2d_10/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/bias, conv2d_9/Const)]]\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "name_model = path + '/models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '.h5'    \n",
    "model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2. Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "y_pred = model_unet.predict(x_test, batch_size=20, verbose=1)\n",
    "\n",
    "# prediction patches without overlapping patches\n",
    "y_pred = np.concatenate(remove_overlap(imgs, y_pred, ids_test, 64, 32))\n",
    "\n",
    "# get label\n",
    "y_pred_label = get_y_pred_labels(y_pred, class_to_remove=class_to_remove)\n",
    "\n",
    "# Get accuracy as margin between highest and second highest class\n",
    "y_pred_acc = get_accuracy_probas(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction image\n",
    "y_pred_acc_imgs = [convert_patches_to_image(imgs, y_pred_acc[...,np.newaxis],\n",
    "                                       img_idx=idx_im, img_start=ids_test[0], patch_size=64,\n",
    "                                       stride=64) for idx_im in ids_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Accuracy Metrics (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metrics\n",
    "y_pred_flattened= np.asarray(flatten(flatten(y_pred_label))).astype('int')\n",
    "y_test_flattened= np.asarray(flatten(flatten(y_test_nostride))).astype('int')\n",
    "\n",
    "# mask background and removed classes for evaluation metrics\n",
    "filter_items = (y_test_flattened != 0) & (y_test_flattened != class_to_remove)\n",
    "\n",
    "# Class accuracy, average accuracy\n",
    "print(metrics.classification_report(\n",
    "    y_test_flattened[filter_items],\n",
    "    y_pred_flattened[filter_items],\n",
    "    target_names=names_keep,\n",
    "    digits=3))\n",
    "\n",
    "\n",
    "# Overall accuracy\n",
    "OA = metrics.accuracy_score(y_test_flattened[filter_items], y_pred_flattened[filter_items])\n",
    "print(\"Overall accuracy: %.3f %%\" % (OA*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to log file\n",
    "import pandas as pd\n",
    "precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test_flattened[filter_items], y_pred_flattened[filter_items])\n",
    "df = pd.DataFrame(data={'Precision':precision,\n",
    "                        'Recall':recall,\n",
    "                       'f1-score':fscore,\n",
    "                       'support':support}, index=names_keep)\n",
    "\n",
    "df.index.name = 'Class'\n",
    "with open(\"models_out/acc_class_\" + str(class_to_remove) + \".csv\", 'w') as f:\n",
    "    print(df.to_latex(float_format='%.3f'), file=f)  # Python 3.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN accuracies\n",
    "```python\n",
    "AA_CNN=[87.098, 81.905, 87.839, 81.076,\n",
    "        81.236, 83.891, 81.091, 81.451] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout as a Bayesian Approximation\n",
    "https://arxiv.org/abs/1506.02142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_preds = predict_with_dropout_imgs(model_unet, x_test,\n",
    "                                    imgs, ids_test, batch_size=100,\n",
    "                                    n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.mean(y_preds, axis=0)\n",
    "uncertainty = np.var(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(uncertainty), np.shape(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncertainty = variance where class prediction is maximum\n",
    "ind = np.argmax(prediction, axis=-1) # indicator where maximum element lies\n",
    "uncertainty_new = np.max(prediction, axis=-1) # initialize with same dimensions as label prediction\n",
    "for patch in range(np.shape(prediction)[0]):\n",
    "    for w in range(np.shape(prediction)[1]):\n",
    "        for h in range(np.shape(prediction)[2]):\n",
    "            uncertainty_new[patch, w, h] = uncertainty[patch, w, h, ind[patch, w, h]]\n",
    "        \n",
    "uncertainty = uncertainty_new\n",
    "# standardize between (0,1)\n",
    "uncertainty -= np.min(uncertainty)\n",
    "uncertainty /= np.max(uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(prediction), np.shape(uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = get_y_pred_labels(prediction, class_to_remove=class_to_remove)\n",
    "pred_labels_im = [convert_patches_to_image(imgs, pred_labels[...,np.newaxis],\n",
    "                                          i, patch_size=64, stride=64, img_start=16) for i in ids_test]\n",
    "pred_labels_im = [gt_label_to_color(pred_labels_im[i][...,0], colors) for i in range(len(ids_test))]\n",
    "\n",
    "plt.imshow(pred_labels_im[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cert_im = [convert_patches_to_image(imgs, uncertainty[..., np.newaxis]\n",
    "                                         , i, patch_size=64, stride=64, img_start=16) for i in ids_test]\n",
    "\n",
    "img = imgs_stretch_eq(pred_cert_im[0])\n",
    "plt.imshow(img[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change shape of y\n",
    "print(np.shape(y_preds))\n",
    "y_preds = np.transpose(y_preds, (1,2,3,4,0))\n",
    "print(np.shape(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y (label)\n",
    "# get prediction\n",
    "y_pred = model_unet.predict(x_test, batch_size=20, verbose=1)\n",
    "y_pred = np.concatenate(remove_overlap(imgs, y_pred, ids_test, 64, 32))\n",
    "\n",
    "# prediction patches without overlapping patches\n",
    "# y_pred = np.concatenate(remove_overlap(imgs, y_pred, ids_test, 64, 32))\n",
    "\n",
    "# get label\n",
    "y_pred_label = get_y_pred_labels(y_pred, class_to_remove=class_to_remove)\n",
    "\n",
    "y_mlp = np.equal(y_pred_label, y_test_nostride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X (training data)\n",
    "idx_tr_mlp = np.arange(get_offset(imgs,64,64,16,18))\n",
    "idx_te_mlp = np.arange(get_offset(imgs,64,64,16,18),get_offset(imgs,64,64,16,20))\n",
    "\n",
    "x_tr_mlp = y_preds[idx_tr_mlp]\n",
    "x_te_mlp = y_preds[idx_te_mlp]\n",
    "\n",
    "y_tr_mlp = y_mlp[idx_tr_mlp]\n",
    "y_te_mlp = y_mlp[idx_te_mlp]\n",
    "\n",
    "\n",
    "def cat(var):\n",
    "    return np.concatenate(np.concatenate(var))\n",
    "\n",
    "x_tr_mlp = np.transpose(cat(x_tr_mlp),(2,0,1))\n",
    "x_te_mlp = np.transpose(cat(x_te_mlp),(2,0,1))\n",
    "y_tr_mlp = cat(y_tr_mlp)\n",
    "y_te_mlp = cat(y_te_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP, similar to baseline 1\n",
    "# loop all data points\n",
    "\n",
    "# transformation seem to deteriorate performance\n",
    "_, x_train_mlp = reorder_truncate_concatenate(x_tr_mlp, n_components=20)\n",
    "_, x_test_mlp = reorder_truncate_concatenate(x_te_mlp, n_components=20)\n",
    "#x_train_mlp  = np.concatenate(x_tr_mlp, axis=-1)\n",
    "#x_test_mlp  = np.concatenate(x_te_mlp, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 2\n",
    "\n",
    "y_train_mlp = keras.utils.to_categorical(y_tr_mlp, num_classes)\n",
    "y_test_mlp = keras.utils.to_categorical(y_te_mlp, num_classes)\n",
    "\n",
    "print(np.shape(y_train_mlp),np.shape(y_test_mlp))\n",
    "np.shape(x_train_mlp),np.shape(x_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(300, activation='relu', input_shape=(x_train_mlp.shape[1:])))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(300, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_mlp.summary()\n",
    "\n",
    "model_mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 2000\n",
    "epochs = 20\n",
    "\n",
    "train = True\n",
    "if train:\n",
    "    history = model_mlp.fit(x_train_mlp, y_train_mlp,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test_mlp, y_test_mlp))\n",
    "    model_mlp.save('models_out/model_MLP_BL2_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')  # save model, weightsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = load_model('models_out/model_MLP_BL2_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model_mlp.predict(x_test_mlp, verbose = 1,\n",
    "                                 batch_size=batch_size)\n",
    "y_pred_proba_label = y_pred_proba[:,1]  # probability to have a good label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patches from pixels\n",
    "n_patches = get_offset(imgs, 64, 64, 18, 20)\n",
    "y_pred_proba_label_patches = np.reshape(y_pred_proba_label,(n_patches,64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image from patches\n",
    "img_idx = 18\n",
    "y_pred_proba_label_imgs = convert_patches_to_image(imgs, y_pred_proba_label_patches[..., np.newaxis], img_idx, 64, 64, 18)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(y_pred_proba_label_imgs[...,0])\n",
    "plt.savefig(\"../Figures/baseline/BL2_im_\" + str(img_idx+1) + \"_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average certainty by  MLP\n",
    "av_cert = np.asarray([np.nanmean(y_pred_proba_label_patches\n",
    "                      [y_test_nostride[idx_te_mlp]==label]) \n",
    "           for label in np.arange(1, 9)])\n",
    "av_cert[-1] = 0\n",
    "\n",
    "\n",
    "plot_probas(av_cert, class_to_remove, names[1:])\n",
    "plt.savefig(\"../Figures/baseline/BL2_probas_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "# ratio unseen class / seen classes\n",
    "cert_unseen = av_cert[class_to_remove - 1]\n",
    "cert_seen = np.nanmean(np.asarray(av_cert)[av_cert != cert_unseen])\n",
    "\n",
    "# weighted accuracies\n",
    "# get support (for weighting)\n",
    "_, support = np.unique(y_test_nostride, return_counts=True)\n",
    "support = support[1:]\n",
    "av_cert_w = (av_cert*support)/sum(support)\n",
    "cert_unseen_w = av_cert_w[class_to_remove - 1]\n",
    "cert_seen_w = np.nanmean(np.asarray(av_cert)[av_cert_w != cert_unseen])\n",
    "\n",
    "print(\"Average certainty unseen class:\\t%.5f\" % cert_unseen)\n",
    "print(\"Average certainty seen classes:\\t%.5f\" % cert_seen)\n",
    "print(\"Ratio between support-weighted cert. of seen classes / unseen class:\\t%.3f\" % (cert_seen_w / cert_unseen_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without transformations\n",
    "#ratios = [12.750, 11.152, 19.619]\n",
    "# with transformations (reorder, truncate (n=4))\n",
    "ratios = [6.266, _, _, _]\n",
    "\n",
    "# with transformations (reorder, truncate (n=20))\n",
    "ratios = [7.194, 7.815, 11.071, 4.007, 44.917, 169.341, 144.520, 0]\n",
    "np.dot(ratios, support)/sum(support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
