{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Land Use Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import torch\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from unet import UNet\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from skimage import exposure\n",
    "from skimage.io import imread\n",
    "from skimage.util import *\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort as ns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZurichLoader(data.Dataset):\n",
    "    \"\"\"\n",
    "    Data loader for Zurich dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, im_patches, gt_patches, split, data_augmentation = False):\n",
    "        \"\"\"\n",
    "        Load data.\n",
    "        :param split: 'train', 'val' or empty\n",
    "        :param transform_data: list of data transformations for images\n",
    "        :param transform_labels: list of data transformations for labels\n",
    "        :param im_size: size to which to crop labels and images\n",
    "        :param patch_size: size of image patches\n",
    "        \"\"\"\n",
    "        # data transformations\n",
    "        self.data_augmentation = data_augmentation\n",
    "\n",
    "        # Load image indexes, depending on set:\n",
    "        if split == 'train':\n",
    "            self.img_idx = np.arange(1, int(len(im_patches)*.6))\n",
    "        elif split == 'val':\n",
    "            self.img_idx = np.arange(int(len(im_patches)*.6)+1, int(len(im_patches)*.8))\n",
    "        else:\n",
    "            self.img_idx = np.arange(int(len(im_patches)*.8)+1, int(len(im_patches)))\n",
    "\n",
    "        self.im_patches = [im_patches[i] for i in self.img_idx]\n",
    "        self.gt_patches= [gt_patches[i] for i in self.img_idx]\n",
    "\n",
    "        # translate to data and label paths\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        function must be overridden: returns data-label pair of tensors for data point at index\n",
    "        Here we just return the entire images for demonstration reasons. In reality, you would crop\n",
    "        from each image at random here, or would have a pre-defined list of coordinates initialised\n",
    "        in the constructor and crop according to it.\n",
    "        \"\"\"\n",
    "\n",
    "        img = self.im_patches[idx]\n",
    "        gt = self.gt_patches[idx]\n",
    "\n",
    "        # convert image\n",
    "        #img = Image.fromarray((img*255).astype(np.uint8))\n",
    "        #gt = Image.fromarray(gt.astype(np.uint8)).convert('L')\n",
    "        # apply transformations\n",
    "\n",
    "\n",
    "        if self.data_augmentation:\n",
    "            img, gt = augment_images_and_gt(img, gt)\n",
    "\n",
    "\n",
    "        # If you want to do special transforms like rotation, do them here.\n",
    "        # Don't forget to apply the same transforms to both the data and label tensors.\n",
    "        # You can use Torchsample, or else convert the data to numpy (e.g.: img.numpy())\n",
    "        # and then load it again into a torch tensor (img = torch.from_numpy(img)).\n",
    "\n",
    "        # TODO transformations using torchsample\n",
    "        img = np.asarray(img).transpose((2,0,1)).astype(np.float64)\n",
    "        img = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "        gt[gt==0] = -1\n",
    "        gt = torch.from_numpy(gt).type(torch.LongTensor)  # .astype(np.double))\n",
    "\n",
    "        return img, gt\n",
    "\n",
    "    def __len__(self):\n",
    "        # function must be overridden: returns number of data points in data set\n",
    "        return len(self.gt_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 20 \n",
      "ground truth images: 20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 122.93it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 1185.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/767 (0%)]\tLoss: -0.026590\n",
      "Train Epoch: 1 [40/767 (5%)]\tLoss: -0.041622\n",
      "Train Epoch: 1 [80/767 (10%)]\tLoss: -0.084711\n",
      "Train Epoch: 1 [120/767 (16%)]\tLoss: -0.116668\n",
      "Train Epoch: 1 [160/767 (21%)]\tLoss: -0.210624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_gt_patches(images_gt, patch_size=64):\n",
    "    \"\"\"\n",
    "    get ground truth patches for all images\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for im in tqdm(images_gt):\n",
    "        patches_im_gt = view_as_blocks(im, block_shape=(patch_size, patch_size))\n",
    "        n_patches = int((im.shape[0] / patch_size) ** 2)  # 25*25 = 625 per image\n",
    "        patches_im_gt = np.reshape(patches_im_gt, (n_patches, patch_size, patch_size))\n",
    "\n",
    "        patches.append(patches_im_gt)\n",
    "    patches = np.array(patches)\n",
    "    patches = np.asarray([patches[i][j] for i in range(len(patches)) for j in range(len(patches[i]))])\n",
    "    # patches = np.concatenate(patches, axis = 0)\n",
    "    return np.asarray(patches)\n",
    "\n",
    "\n",
    "def get_padded_patches(images, patch_size=16, window_size=64):\n",
    "    \"\"\"\n",
    "    get padded (mirror) patches for all images\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for im in tqdm(images):\n",
    "        patches_im = np.zeros(\n",
    "            [int(im.shape[0] / patch_size), int(im.shape[0] / patch_size), window_size, window_size, im.shape[-1]])\n",
    "        for i in range(im.shape[-1]):\n",
    "            padded = np.lib.pad(im[:, :, i], int(np.floor((window_size - patch_size) / 2)), 'reflect')\n",
    "            patches_im[:, :, :, :, i] = view_as_windows(padded, window_size, step=patch_size)\n",
    "\n",
    "        n_patches = int((im.shape[0] / patch_size) ** 2)  # 25*25 = 625 per image\n",
    "        patches_im = np.reshape(patches_im, (n_patches, window_size, window_size, im.shape[2]))\n",
    "\n",
    "        patches.append(patches_im)\n",
    "    patches = np.array(patches)\n",
    "    patches = np.asarray([patches[i][j] for i in range(len(patches)) for j in range(len(patches[i]))])\n",
    "    # patches = np.concatenate(patches, axis = 0)\n",
    "    return patches\n",
    "\n",
    "\n",
    "# Training settings\n",
    "batch_size = 2\n",
    "test_batch_size = 2\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "no_cuda = True\n",
    "seed = 1\n",
    "log_interval = 20\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "\n",
    "# define transforms\n",
    "\n",
    "\n",
    "def im_load(path, max_size=512):  # for now, only return highest [max_size] pixels, multiple of patch_size\n",
    "    \"\"\"load a TIF image\"\"\"\n",
    "    image = np.asarray(imread(path)).astype('double')\n",
    "    image = image[:max_size, :max_size, :]\n",
    "    return image\n",
    "\n",
    "\n",
    "def imgs_stretch_eq(im):\n",
    "    \"\"\"\n",
    "    Do contrast stretching on image\n",
    "    :param im: input image\n",
    "    :return img_stretch: stretched image\n",
    "    :return img_eq: equalized image\n",
    "    \"\"\"\n",
    "    im = np.asarray(im)\n",
    "    img_stretch = im.copy()\n",
    "    img_eq = im.copy()\n",
    "    for band in range(im.shape[-1]):\n",
    "        p2, p98 = np.percentile(im[:, :, band], (2, 98))\n",
    "        img_stretch[:, :, band] = exposure.rescale_intensity(im[:, :, band], in_range=(p2, p98))\n",
    "        img_eq[:, :, band] = exposure.equalize_hist(img_stretch[:, :, band])\n",
    "    return img_stretch, img_eq\n",
    "\n",
    "\n",
    "legend = OrderedDict((('Background', [255, 255, 255]),\n",
    "                      ('Roads', [0, 0, 0]),\n",
    "                      ('Buildings', [100, 100, 100]),\n",
    "                      ('Trees', [0, 125, 0]),\n",
    "                      ('Grass', [0, 255, 0]),\n",
    "                      ('Bare Soil', [150, 80, 0]),\n",
    "                      ('Water', [0, 0, 150]),\n",
    "                      ('Railways', [255, 255, 0]),\n",
    "                      ('Swimming Pools', [150, 150, 255])))\n",
    "\n",
    "# get class names by increasing value (as done above)\n",
    "names, colors = [], []\n",
    "for name, color in legend.items():\n",
    "    names.append(name)\n",
    "    colors.append(color)\n",
    "\n",
    "\n",
    "def gt_color_to_label(gt, maj=False):\n",
    "    \"\"\"\n",
    "    Transform a set of GT image in value range [0, 255] of shape (n_images, width, height, 3)\n",
    "    to a set of GT labels of shape (n_images, width, height)\n",
    "    \"\"\"\n",
    "\n",
    "    # sum of distinct color values\n",
    "    gt_new = np.zeros(np.asarray(gt).shape[:-1])\n",
    "\n",
    "    # replace colors by new values\n",
    "    for i in range(len(colors)):\n",
    "        gt_new[np.all(gt == colors[i], axis=-1)] = i  # np.argsort(colors)[i]\n",
    "\n",
    "    if maj:\n",
    "        # return only majority label for each patch\n",
    "        gt_maj_label = []\n",
    "        for i in range(len(gt)):\n",
    "            counts = np.bincount(gt_new[i].flatten())\n",
    "            gt_maj_label.append(np.argmax(counts))\n",
    "\n",
    "        gt_new = np.asarray([gt_maj_label]).T\n",
    "\n",
    "    return gt_new\n",
    "\n",
    "\n",
    "def gt_label_to_color(gt):\n",
    "    \"\"\"\n",
    "    Transform a set of GT labels of shape (n_images, width, height)\n",
    "    to a set of GT images in value range [0,1] of shape (n_images, width, height, 3) \"\"\"\n",
    "    gt_new = np.zeros(gt.shape + (3,))\n",
    "    for i in range(len(colors)):  # loop colors\n",
    "        gt_new[gt == i, :] = np.divide(colors[i], 255)\n",
    "    return gt_new\n",
    "\n",
    "\n",
    "def load_data(max_size=512, patch_size=64):\n",
    "    \"\"\"\n",
    "    load image data and create patches to use with DataLoader\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    base_dir = \"/home/cyrilwendl/SIE-Master/Zurich/Zurich_dataset\"\n",
    "    im_dir = base_dir + '/images_tif/'\n",
    "    gt_dir = base_dir + '/groundtruth/'\n",
    "    im_names = ns.natsorted(os.listdir(im_dir))\n",
    "    gt_names = ns.natsorted(os.listdir(gt_dir))\n",
    "    print(\"images: %i \" % len(im_names))\n",
    "    print(\"ground truth images: %i \" % len(gt_names))\n",
    "\n",
    "    imgs = np.asarray([im_load(im_dir + im_name, max_size=max_size) for im_name in im_names])\n",
    "    gt = np.asarray([im_load(gt_dir + gt_name, max_size=max_size) for gt_name in gt_names])\n",
    "\n",
    "    # image stretching\n",
    "    imgs =[imgs_stretch_eq(img)[1] for img in imgs]\n",
    "\n",
    "\n",
    "\n",
    "    # convert gt colors to labels\n",
    "    gt_maj_label = gt_color_to_label(gt)\n",
    "    gt = gt_maj_label\n",
    "\n",
    "    # get patches\n",
    "    im_patches = get_padded_patches(imgs, patch_size=patch_size, window_size=patch_size)\n",
    "    gt_patches = get_gt_patches(gt, patch_size=patch_size)\n",
    "\n",
    "    return im_patches, gt_patches\n",
    "\n",
    "\n",
    "im_patches, gt_patches = load_data(max_size=512, patch_size=64)\n",
    "\n",
    "transform_data = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "transform_both = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# create datasets\n",
    "train_loader = data.DataLoader(\n",
    "    ZurichLoader(im_patches, gt_patches, 'train'),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    ZurichLoader(im_patches, gt_patches, 'val'),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    ZurichLoader(im_patches, gt_patches, 'test'),\n",
    "    batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "n_classes = 8  # TODO parse\n",
    "\n",
    "model = UNet(n_classes, in_channels=4)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "def train(epochs=epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (im_data, labels) in enumerate(train_loader):\n",
    "        # print(\"Shape batch:\"+str(np.shape(Variable(im_data).data.numpy())))\n",
    "        # print(\"Batch id: %i\"%batch_idx)\n",
    "        if cuda:\n",
    "            im_data, labels = im_data.cuda(), labels.cuda()\n",
    "        im_data, labels = Variable(im_data), Variable(labels)\n",
    "        # class_weights = class_weight.compute_class_weight('balanced', np.unique(labels.data.numpy().flatten()),\n",
    "        #                                                np.arange(10))\n",
    "        # class_weights=Variable(torch.from_numpy(class_weights).type(torch.FloatTensor))\n",
    "        optimizer.zero_grad()\n",
    "        output = model(im_data)\n",
    "        loss = functional.nll_loss(output, labels, ignore_index=-1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epochs, batch_idx * len(im_data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for im_data, target in test_loader:\n",
    "        if cuda:\n",
    "            im_data, target = im_data.cuda(), target.cuda()\n",
    "        im_data, target = Variable(im_data), Variable(target)\n",
    "        output = model(im_data)\n",
    "        test_loss += functional.nll_loss(output, target, size_average=False, ignore_index=-1).data[0]  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset) * 64 * 64 * 4,\n",
    "        100. * correct / (len(test_loader.dataset) * 64 * 64 * 4)))\n",
    "\n",
    "\n",
    "def test_show_some_images():\n",
    "    test_im = test_loader.dataset[11]\n",
    "    im_test = Variable(test_im[0]).data.numpy()\n",
    "    im_test_l = Variable(test_im[1]).data.numpy()\n",
    "\n",
    "    print(im_test.shape, im_test_l.shape)\n",
    "\n",
    "    im_test = im_test * 1.\n",
    "    im_test = np.transpose(im_test, (1, 2, 0))\n",
    "    im_test_l = im_test_l * 1.\n",
    "    #print(np.shape(im_test_l))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im_test[:, :, :3])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im_test_l)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "        #test_show_some_images()\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
