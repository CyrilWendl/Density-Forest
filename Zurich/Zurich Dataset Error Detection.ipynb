{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zurich Land Cover Classification\n",
    "\n",
    "This script presents a visualization of training a U-Net classifier on 7 out of 8 available land cover classes of the Zurich dataset, and detecting the unseen class using a Density Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13147679796899021588\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2039283712\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12130082984282225863\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraries\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.manifold import TSNE\n",
    "import sys\n",
    "\n",
    "from sklearn import decomposition, svm, preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# custom libraries\n",
    "base_dir = '/Users/cyrilwendl/Documents/EPFL'\n",
    "#base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "sys.path.append(base_dir + '/SIE-Master/Code')  # Path to density Tree package\n",
    "sys.path.append(base_dir + '/SIE-Master')  # Path to density Tree package\n",
    "sys.path.append(base_dir + '/SIE-Master/Code/density_tree')  # Path to density Tree package\n",
    "from helpers.helpers import *\n",
    "from helpers.data_augment import *\n",
    "from helpers.data_loader import ZurichLoader\n",
    "from helpers.cv_scorers import *\n",
    "from helpers.cross_validator import ParameterSearch\n",
    "from baselines.helpers import predict_with_dropout_imgs\n",
    "from density_forest.density_forest import *\n",
    "from density_forest.plots import *\n",
    "from density_forest.helpers import *\n",
    "from keras_helpers.unet import *\n",
    "from keras_helpers.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_train = ZurichLoader(path, 'train')\n",
    "data_val = ZurichLoader(path, 'val')\n",
    "data_test = ZurichLoader(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with overlap, for prediction\n",
    "data_train_overlap = ZurichLoader(path, 'train', stride=32)\n",
    "data_val_overlap = ZurichLoader(path, 'val', stride=32)\n",
    "data_test_overlap = ZurichLoader(path, 'test', stride=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data_train.names\n",
    "colors = data_train.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes to keep: ['Background', 'Roads', 'Buildings', 'Trees', 'Grass', 'Bare Soil', 'Water', 'Railways', 'Swimming Pools']\n"
     ]
    }
   ],
   "source": [
    "# remove class\n",
    "n_classes = 9\n",
    "classes_to_keep = np.asarray([x for x in range(1, n_classes)])\n",
    "\n",
    "names_keep = np.asarray(names)\n",
    "names_keep = names_keep.tolist()\n",
    "print(\"classes to keep: \" + str(names_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Data Split: \n",
    "- Training: 12 images\n",
    "- Validation: 4 images\n",
    "- Test: 4 images\n",
    "\n",
    "Tested Architectures: \n",
    "\n",
    "| Model | Patch Size | Data Augmentations | Number of Parameters | Testing Precision (avg) | Testing Recall (avg) | Testing f1 score (avg) | Validation / Test accuracy |\n",
    "| ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| U-Net | 64 | Rot 90°, Flipping  | 7,828,200 | 0.87 | 0.858 | 0.86 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.69 | 0.61 | 0.64 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.90 | 0.89 | 0.89 | v |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create copies of original data\\ny_train_label = y_train.copy()\\ny_val_label = y_val.copy()\\ny_test_label = y_test.copy()\\n\\n# get class weights\\nlabels_unique = np.unique(y_train.flatten())\\nprint(labels_unique)\\nclass_weights = class_weight.compute_class_weight(\\'balanced\\', labels_unique, y_train.flatten())\\nclass_weights[0] = 0  # give less weight to background label class\\nclass_weights[5] = 7  # give less weight to bare soil class\\nclass_weights[8] = 7  # give less weight to swimming pool class\\n\\nprint(\"Class weights:\")\\nfor i, w in enumerate(class_weights):\\n    print(\"%15s: %3.3f\" % (names[i], w))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# create copies of original data\n",
    "y_train_label = y_train.copy()\n",
    "y_val_label = y_val.copy()\n",
    "y_test_label = y_test.copy()\n",
    "\n",
    "# get class weights\n",
    "labels_unique = np.unique(y_train.flatten())\n",
    "print(labels_unique)\n",
    "class_weights = class_weight.compute_class_weight('balanced', labels_unique, y_train.flatten())\n",
    "class_weights[0] = 0  # give less weight to background label class\n",
    "class_weights[5] = 7  # give less weight to bare soil class\n",
    "class_weights[8] = 7  # give less weight to swimming pool class\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(class_weights):\n",
    "    print(\"%15s: %3.3f\" % (names[i], w))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# convert to numpy arrays\\nx_train = np.asarray(x_train)\\nx_val = np.asarray(x_val)\\nx_test = np.asarray(x_test)\\n\\n# make y data categorical\\ny_train = to_categorical(y_train_label, n_classes)\\ny_val = to_categorical(y_val_label, n_classes)\\n\\ny_train = y_train[..., classes_to_keep]\\ny_val = y_val[..., classes_to_keep]\\nn_classes = len(classes_to_keep)\\nclass_weights = class_weights[classes_to_keep]\\n\\n# print shapes of variables\\nfor var in x_train, y_train, x_val, y_val:\\n    print(np.shape(var))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# convert to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "x_val = np.asarray(x_val)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "# make y data categorical\n",
    "y_train = to_categorical(y_train_label, n_classes)\n",
    "y_val = to_categorical(y_val_label, n_classes)\n",
    "\n",
    "y_train = y_train[..., classes_to_keep]\n",
    "y_val = y_val[..., classes_to_keep]\n",
    "n_classes = len(classes_to_keep)\n",
    "class_weights = class_weights[classes_to_keep]\n",
    "\n",
    "# print shapes of variables\n",
    "for var in x_train, y_train, x_val, y_val:\n",
    "    print(np.shape(var))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# callbacks (evaluated every epoch)\\n# show loss and accuracy figures after each epoch\\ncallback_plot = PlotLosses()\\n\\n# stop early if after several epochs the accuracy doesn\\'t improve\\ncallback_earlystop = EarlyStopping(monitor=\\'val_loss\\', min_delta=1e-4, patience=24, verbose=1, mode=\\'auto\\')\\n\\n# decrease learning rate when accuracy stops improving\\ncallback_lr = ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.5, patience=12, verbose=1, mode=\\'auto\\',\\n                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\\n\\n# checkpoint to save weights at every epoch (in case of interruption)\\nfile_path = \"weights-improvement.hdf5\"\\ncallback_checkpoint = ModelCheckpoint(file_path, monitor=\\'val_acc\\', verbose=0, save_best_only=True, mode=\\'max\\')\\n\\ncallback_tensorboard = TensorBoard(log_dir=\\'./tensorboard\\', histogram_freq=0, write_graph=True, write_images=True)\\n\\n# model setup\\nbatch_size = 20\\nepochs = 300\\n\\n\\ndef model_train(model, data_augmentation):\\n    # Fit the model on the batches generated by datagen.flow().\\n    model.fit_generator(batch_generator(x_train, y_train,\\n                                        batch_size=batch_size, data_augmentation=data_augmentation),\\n                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\\n                        epochs=epochs,\\n                        verbose=1,\\n                        class_weight=class_weights,  # weights for loss function\\n                        validation_data=(x_val, y_val),\\n                        callbacks=[callback_earlystop,\\n                                   callback_lr,\\n                                   # callback_checkpoint,\\n                                   callback_plot,\\n                                   callback_tensorboard],\\n                        workers=cpu_count(),\\n                        use_multiprocessing=True)\\n                        \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# callbacks (evaluated every epoch)\n",
    "# show loss and accuracy figures after each epoch\n",
    "callback_plot = PlotLosses()\n",
    "\n",
    "# stop early if after several epochs the accuracy doesn't improve\n",
    "callback_earlystop = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=24, verbose=1, mode='auto')\n",
    "\n",
    "# decrease learning rate when accuracy stops improving\n",
    "callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, verbose=1, mode='auto',\n",
    "                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "# checkpoint to save weights at every epoch (in case of interruption)\n",
    "file_path = \"weights-improvement.hdf5\"\n",
    "callback_checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# model setup\n",
    "batch_size = 20\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "def model_train(model, data_augmentation):\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(batch_generator(x_train, y_train,\n",
    "                                        batch_size=batch_size, data_augmentation=data_augmentation),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        class_weight=class_weights,  # weights for loss function\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback_earlystop,\n",
    "                                   callback_lr,\n",
    "                                   # callback_checkpoint,\n",
    "                                   callback_plot,\n",
    "                                   callback_tensorboard],\n",
    "                        workers=cpu_count(),\n",
    "                        use_multiprocessing=True)\n",
    "                        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or load model\n",
    "# train the model\n",
    "#model_unet = get_unet(n_classes, x_train.shape[1:])\n",
    "#model_train(model_unet, data_augmentation=True)\n",
    "#model_unet.save('models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')  # save model, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [2,2,256,512] and type float\n\t [[Node: training/SGD/zeros_20 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2,2,256,512] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training/SGD/zeros_20', defined at:\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-a82d63f2b906>\", line 3, in <module>\n    model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/saving.py\", line 295, in load_model\n    model._make_train_function()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\", line 497, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in get_updates\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in <listcomp>\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 699, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [2,2,256,512] and type float\n\t [[Node: training/SGD/zeros_20 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2,2,256,512] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [2,2,256,512] and type float\n\t [[Node: training/SGD/zeros_20 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2,2,256,512] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a82d63f2b906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mname_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/models_out/model_unet_64_flip_rot90_all_cl.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mignore_background_class_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    301\u001b[0m                                            optimizer_weight_names]\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                     warnings.warn('Error in loading the saved optimizer '\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    113\u001b[0m                              'of the optimizer (' + str(len(params)) + ')')\n\u001b[1;32m    114\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \"\"\"\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [2,2,256,512] and type float\n\t [[Node: training/SGD/zeros_20 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2,2,256,512] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training/SGD/zeros_20', defined at:\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/python36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/python36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-a82d63f2b906>\", line 3, in <module>\n    model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/saving.py\", line 295, in load_model\n    model._make_train_function()\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\", line 497, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in get_updates\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/optimizers.py\", line 182, in <listcomp>\n    moments = [K.zeros(shape) for shape in shapes]\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 699, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [2,2,256,512] and type float\n\t [[Node: training/SGD/zeros_20 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2,2,256,512] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "name_model = path + '/models_out/model_unet_64_flip_rot90_all_cl.h5'    \n",
    "model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "y_pred_te = model_unet.predict(data_test_overlap.im_patches, batch_size=20, verbose=1)\n",
    "\n",
    "# prediction patches without overlapping patches\n",
    "y_pred_te = np.concatenate(remove_overlap(data_test.imgs, y_pred_te, np.arange(4), 64, 32))\n",
    "\n",
    "# get label\n",
    "y_pred_label_te = get_y_pred_labels(y_pred_te, background=True)\n",
    "\n",
    "# get accuracy as softmax pseudo-probability\n",
    "y_pred_acc = np.max(y_pred_te, axis=-1)\n",
    "\n",
    "# Get accuracy as margin between highest and second highest class\n",
    "y_pred_acc_margin = get_acc_net_max_margin(y_pred_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction image\n",
    "y_pred_acc_imgs = [convert_patches_to_image(data_test.imgs, y_pred_acc[..., np.newaxis], \n",
    "                                            img_idx=idx_im, img_start=0, patch_size=64, stride=64) \n",
    "                   for idx_im in np.arange(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_im = [convert_patches_to_image(data_test.imgs, gt_label_to_color(y_pred_label_te, colors), \n",
    "                                      img_idx=i, img_start=0, patch_size=64, stride=64) \n",
    "             for i in np.arange(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metrics\n",
    "y_pred_flattened = np.asarray(y_pred_label_te.flatten()).astype('int')\n",
    "y_test_flattened = np.asarray(data_test.gt_patches.flatten()).astype('int')\n",
    "\n",
    "# mask background and removed classes for evaluation metrics\n",
    "filter_items = (y_test_flattened != 0)\n",
    "\n",
    "# Class accuracy, average accuracy\n",
    "print(metrics.classification_report(\n",
    "    y_test_flattened[filter_items],\n",
    "    y_pred_flattened[filter_items],\n",
    "    target_names=names_keep[1:],\n",
    "    digits=3))\n",
    "\n",
    "\n",
    "# Overall accuracy\n",
    "OA = metrics.accuracy_score(y_test_flattened[filter_items], y_pred_flattened[filter_items])\n",
    "print(\"Overall accuracy: %.3f %%\" % (OA*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all predictions in training and test set\n",
    "# training set\n",
    "y_pred_tr = model_unet.predict(data_train_overlap.im_patches, verbose=1)\n",
    "y_pred_tr = np.concatenate(remove_overlap(data_train.imgs, y_pred_tr, np.arange(12), 64, 32))\n",
    "y_pred_label_tr = get_y_pred_labels(y_pred_tr, background=True)\n",
    "\n",
    "# validation set\n",
    "y_pred_val = model_unet.predict(data_val_overlap.im_patches, verbose=1)\n",
    "y_pred_val = np.concatenate(remove_overlap(data_val.imgs, y_pred_val, np.arange(4), 64, 32))\n",
    "y_pred_label_val = get_y_pred_labels(y_pred_val, background=True)\n",
    "\n",
    "# test set already done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of correctly / incorrectly predicted pixels\n",
    "# with error in known classes\n",
    "# only known classes (novely detection)\n",
    "# get indices of correctly / incorrectly predicted pixels\n",
    "# with error in known classes\n",
    "# only known classes (novely detection)\n",
    "\n",
    "pred_t_tr = (data_train.gt_patches != 0) & (data_train.gt_patches == y_pred_label_tr)\n",
    "pred_f_tr = (data_train.gt_patches != 0) & (data_train.gt_patches != y_pred_label_tr)\n",
    "\n",
    "pred_t_val = (data_val.gt_patches != 0) & (data_val.gt_patches == y_pred_label_val)\n",
    "pred_f_val = (data_val.gt_patches != 0) & (data_val.gt_patches != y_pred_label_val)\n",
    "\n",
    "pred_t_te = (data_test.gt_patches != 0) & (data_test.gt_patches == y_pred_label_te)\n",
    "pred_f_te = (data_test.gt_patches != 0) & (data_test.gt_patches != y_pred_label_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of predictions in wrongly predicted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of predicted label\n",
    "pred_labels, pred_counts = np.unique(y_pred_label_te[pred_f_te], return_counts=True)\n",
    "\n",
    "# visualization\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(pred_labels, pred_counts)\n",
    "plt.xticks(np.arange(0, 10))\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Misclassified labels (mean MSR=%.2f)\" % np.mean(get_acc_net_msr(y_pred_label_te[pred_f_te])))\n",
    "plt.xticks(pred_labels, names[pred_labels], rotation=20)\n",
    "plt.savefig(\"../Figures/Zurich/pred-count_ED.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curves\n",
    "\n",
    "# msr\n",
    "y_scores = (-get_acc_net_msr(y_pred_te)).flatten()\n",
    "y_true = pred_f_te.flatten()\n",
    "precision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_msr = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_msr = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# margin\n",
    "y_scores = (-get_acc_net_max_margin(y_pred_te)).flatten()\n",
    "precision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_margin = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_margin = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# entropy\n",
    "y_scores = (-get_acc_net_entropy(y_pred_te)).flatten()\n",
    "precision_entropy, recall_entropy, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_entropy = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_entropy = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "# MSR\n",
    "probas_patches_msr = np.reshape((get_acc_net_msr(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_msr -= np.min(probas_patches_msr)\n",
    "probas_patches_msr /= np.max(probas_patches_msr)\n",
    "\n",
    "# margin\n",
    "probas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_margin -= np.min(probas_patches_margin)\n",
    "probas_patches_margin /= np.max(probas_patches_margin)\n",
    "\n",
    "\n",
    "# entropy\n",
    "probas_patches_entropy = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_entropy -= np.min(probas_patches_entropy)\n",
    "probas_patches_entropy /= np.max(probas_patches_entropy)\n",
    "\n",
    "# visualization\n",
    "# MSR\n",
    "probas_patches_msr = np.reshape((get_acc_net_msr(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_msr -= np.min(probas_patches_msr)\n",
    "probas_patches_msr /= np.max(probas_patches_msr)\n",
    "\n",
    "# margin\n",
    "probas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_margin -= np.min(probas_patches_margin)\n",
    "probas_patches_margin /= np.max(probas_patches_margin)\n",
    "\n",
    "# entropy\n",
    "probas_patches_entropy = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_entropy -= np.min(probas_patches_entropy)\n",
    "probas_patches_entropy /= np.max(probas_patches_entropy)\n",
    "\n",
    "# show images\n",
    "for img_idx in range(4):\n",
    "    acc_im_msr = convert_patches_to_image(data_test.imgs, probas_patches_msr[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_msr = imgs_stretch_eq([acc_im_msr])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_msr[..., 0], cmap='gray')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/ED/net_msr_im_\" + str(img_idx) + \".pdf\", \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    acc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_margin = imgs_stretch_eq([acc_im_margin])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_margin[..., 0], cmap='gray')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/ED/net_margin_im_\" + str(img_idx) + \".pdf\", \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    acc_im_entropy = convert_patches_to_image(data_test.imgs, probas_patches_entropy[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_entropy = imgs_stretch_eq([acc_im_entropy])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_entropy[..., 0], cmap='gray')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/ED/net_entropy_im_\" + str(img_idx) + \".pdf\", \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_preds = predict_with_dropout_imgs(model_unet, data_test_overlap.im_patches,\n",
    "                                    data_test.imgs, np.arange(4), batch_size=500,\n",
    "                                    n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction and confidence\n",
    "prediction = np.mean(y_preds, 0)\n",
    "probas_dropout = -get_acc_net_entropy(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout metrics\n",
    "y_scores = probas_dropout.flatten()\n",
    "precision_dropout, recall_dropout, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_dropout = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_dropout = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_dropout, tpr_dropout, _ = metrics.roc_curve(y_true, y_scores)\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_dropout, pr_auc_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "probas_patches_margin = np.reshape(y_scores, np.shape(data_test.gt_patches))\n",
    "probas_patches_margin -= np.min(probas_patches_margin)\n",
    "probas_patches_margin /= np.max(probas_patches_margin)\n",
    "\n",
    "img_idx = 3\n",
    "acc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "acc_im_margin = imgs_stretch_eq([acc_im_margin])[0]\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(acc_im_margin[..., 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Activations, PCA, t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get activations for training Density Forest\n",
    "act_train_all = get_activations_batch(model_unet, -2, data_train_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_train_all = np.concatenate(remove_overlap(data_train.imgs, act_train_all, np.arange(12), patch_size=64, stride=32))\n",
    "act_train = act_train_all[pred_t_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get activations\n",
    "act_val_all = get_activations_batch(model_unet, -2, data_val_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_val_all = np.concatenate(remove_overlap(data_val.imgs, act_val_all, np.arange(4), patch_size=64, stride=32))\n",
    "act_val = act_val_all[pred_t_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get activations for testing Density Forest\n",
    "act_test = get_activations_batch(model_unet, -2, data_test_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# remove test activations overlap\n",
    "act_test = remove_overlap(data_test.imgs, act_test, np.arange(4), patch_size=64, stride=32)\n",
    "act_test = np.concatenate(np.concatenate(np.concatenate(act_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get balanced data subset to show in figure\n",
    "tsne_pts_per_class = 200\n",
    "dataset_subset_indices = get_balanced_subset_indices(data_test.gt_patches.flatten(), \n",
    "                                                     np.arange(1, 9), pts_per_class=tsne_pts_per_class)\n",
    "dataset_subset_indices = np.concatenate(dataset_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=500)\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])\n",
    "tsne_y = data_test.gt_patches.flatten()[dataset_subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, names, colors)\n",
    "plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create density tree for activation weights of training data\n",
    "# PCA\n",
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(act_test)  # fit on training set without background pixels\n",
    "n_components = np.alen(pca.explained_variance_ratio_)\n",
    "print(\"Variance explained by first %i components: %.2f\" % (\n",
    "    n_components, sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "# transform training activations\n",
    "act_train_all = pca.transform(np.concatenate(np.concatenate(act_train_all)))\n",
    "act_train = pca.transform(act_train)\n",
    "\n",
    "act_val_all = pca.transform(np.concatenate(np.concatenate(act_val_all)))\n",
    "act_val = pca.transform(act_val)\n",
    "\n",
    "\n",
    "# transform test set activations\n",
    "act_test = pca.transform(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization after PCA\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne without unseen class\n",
    "tsne_train = tsne_all[(tsne_y == y_pred_label_te.flatten()[dataset_subset_indices]) & tsne_y!=0]\n",
    "tsne_train_y = tsne_y[(tsne_y == y_pred_label_te.flatten()[dataset_subset_indices]) & tsne_y!=0]\n",
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_pts_2d(tsne_train, tsne_train_y, ax, np.unique(tsne_train_y), names, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne without unseen class\n",
    "tsne_train = tsne_all[(tsne_y == y_pred_label_te.flatten()[dataset_subset_indices]) & tsne_y!=0]\n",
    "tsne_train_y = tsne_y[(tsne_y == y_pred_label_te.flatten()[dataset_subset_indices]) & tsne_y!=0]\n",
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, names, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 3 PCA components\n",
    "plot_pts_3d(act_test[:, :3], data_test.gt_patches.flatten(), classes_to_keep, names, colors, subsample_pct=.0003)\n",
    "\n",
    "print(\"Variance explained by first 3 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 2 PCA components\n",
    "_, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plot_pts_2d(act_test[:, :2], data_test.gt_patches.flatten(), ax, classes_to_keep, names, colors, subsample_pct=.0005)\n",
    "\n",
    "print(\"Variance explained by first 2 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_components': np.arange(3, 12), \n",
    "                     'max_iter': [10000]}]\n",
    "\n",
    "# do parameter search\n",
    "ps_gmm = ParameterSearch(GaussianMixture, tuned_parameters, act_train, act_train_all,\n",
    "                         pred_f_tr.flatten(), scorer_roc_probas_gmm, \n",
    "                         n_iter=3, verbosity=10, n_jobs=-1, subsample_train=.01, subsample_test=.001)\n",
    "ps_gmm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_gmm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GMM\n",
    "gmm = GaussianMixture(**ps_gmm.best_params)\n",
    "gmm.fit(draw_subsamples(act_train, .01))\n",
    "\n",
    "# Predict\n",
    "probas_gmm = gmm.predict_proba(act_test)\n",
    "probas_gmm = get_acc_net_entropy(probas_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# dataset_subset_indicesices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_gmm_c = imgs_stretch_eq([probas_gmm[..., np.newaxis]])[0, ..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_gmm_c)[:, :3][dataset_subset_indices]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] <\n",
    "                            np.sort(probas_gmm_c[dataset_subset_indices])[200])*255)[:, :3]\n",
    "c_thresh_f = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] > \n",
    "                            np.sort(probas_gmm_c[dataset_subset_indices])[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t], alpha=.6)\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "y_scores = -probas_gmm\n",
    "precision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\n",
    "fpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_gmm = metrics.roc_auc_score(y_true, y_scores)\n",
    "plt.step(recall_gmm, precision_gmm)\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_gmm, pr_auc_gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_gmm = np.reshape(probas_gmm, np.shape(data_test.gt_patches))\n",
    "probas_patches_gmm -= np.min(probas_patches_gmm)\n",
    "probas_patches_gmm /= np.max(probas_patches_gmm)\n",
    "probas_patches_gmm = 1 - probas_patches_gmm\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(4):\n",
    "    acc_im_gmm = convert_patches_to_image(data_test.imgs, probas_patches_gmm[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_gmm = imgs_stretch_eq([acc_im_gmm])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_gmm[..., 0], cmap='gray')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/ED/GMM_im_\" + str(img_idx) + \".pdf\", \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train_svm = preprocessing.scale(act_train)\n",
    "act_val_all_svm = preprocessing.scale(act_val_all)\n",
    "act_test_svm = preprocessing.scale(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_f_tr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1],\n",
    "                     },\n",
    "                    {'kernel': ['poly'],\n",
    "                     'degree': np.arange(1, 17),\n",
    "                     'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1],\n",
    "                     'max_iter': [10000]}]\n",
    "\n",
    "# do parameter search\n",
    "ps_svm = ParameterSearch(svm.OneClassSVM, tuned_parameters, act_train_svm, act_train_all,\n",
    "                         pred_f_tr.flatten(), scorer_roc_probas_svm, n_iter=5,\n",
    "                         verbosity=11, n_jobs=-1, subsample_train=.01, subsample_test=.001)\n",
    "ps_svm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps_svm.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "clf_svm = svm.OneClassSVM(**ps_svm.best_params)\n",
    "clf_svm.fit(draw_subsamples(act_train_svm, .001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "probas_svm = clf_svm.decision_function(act_test_svm[dataset_subset_indices])\n",
    "probas_svm -= np.min(probas_svm)\n",
    "probas_svm /= np.max(probas_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_svm_c = probas_svm[..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_svm_c)[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_svm_c < np.sort(probas_svm_c)[200])*255)[:, :3]\n",
    "\n",
    "c_thresh_f = plt.cm.GnBu((probas_svm_c > np.sort(probas_svm_c)[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_svm = clf_svm.decision_function(act_test_svm)\n",
    "probas_svm -= np.min(probas_svm)\n",
    "probas_svm /= np.max(probas_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "y_scores = -probas_svm\n",
    "# PR\n",
    "precision_svm, recall_svm, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_svm = metrics.auc(recall_svm, precision_svm)\n",
    "\n",
    "# ROC\n",
    "fpr_svm, tpr_svm, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_svm = metrics.roc_auc_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_svm, pr_auc_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_svm = np.reshape(probas_svm, np.shape(data_test.gt_patches))\n",
    "probas_patches_svm -= np.min(probas_patches_svm)\n",
    "probas_patches_svm /= np.max(probas_patches_svm)\n",
    "probas_patches_svm = 1 - probas_patches_svm\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(4):\n",
    "    acc_im_svm = convert_patches_to_image(data_test.imgs, probas_patches_svm[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_svm = imgs_stretch_eq([acc_im_svm])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_svm[..., 0], cmap='gray')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/ED/svm_im_\" + str(img_idx) + \".pdf\", \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DensityForest instance\n",
    "clf_df = DensityForest(max_depth=2, min_subset=.1, n_trees=100,\n",
    "                       subsample_pct=.1, n_jobs=-1, verbose=10,\n",
    "                       ig_improvement=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to training data\n",
    "clf_df.fit(tsne_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ellipses on plot\n",
    "_, axes = plt.subplots(2, 2, figsize=(15, 15)) \n",
    "for i in range(4):\n",
    "    plot_pts_2d(tsne_all, tsne_y, axes[int(i/2)][np.mod(i, 2)], classes_to_keep, names, \n",
    "                colors)\n",
    "    covs, means = get_clusters(clf_df.root_nodes[i], [], [])\n",
    "    plot_ellipses(axes[int(i / 2)][np.mod(i, 2)], means, covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "# get probabilities for all images\n",
    "probas_df = np.log(clf_df.predict(tsne_all))\n",
    "\n",
    "# indices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_df_c = imgs_stretch_eq(probas_df[np.newaxis, ..., np.newaxis])[0, ..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_df_c)[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.GnBu((probas_df < np.sort(probas_df)[tsne_pts_per_class])*255)[:, :3]\n",
    "\n",
    "c_thresh_f = plt.cm.GnBu((probas_df > np.sort(probas_df)[tsne_pts_per_class])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "[axes[i].legend(['Seen points', 'Novel points']) for i in range(2)]\n",
    "[axes[i].set_axis_off() for i in range(2)]\n",
    "extent = axes[0].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_f_tr.flatten(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {'n_trees': 10, \n",
    "                   'n_max_dim': 0,\n",
    "                   'n_jobs': -1,\n",
    "                   'verbose': 1,\n",
    "                   'subsample_pct': .0002\n",
    "                  }\n",
    "\n",
    "tuned_params = [{'max_depth': [2, 3, 4],\n",
    "                 'min_subset': [1e-2, 1e-3, 1e-4],\n",
    "                 'ig_improvement': [0, .3, .5]}]\n",
    "                 \n",
    "\n",
    "# do parameter search\n",
    "ps_df = ParameterSearch(DensityForest, tuned_params, act_train[..., :3], act_train_all[..., :3],\n",
    "                         pred_f_tr.flatten(), scorer_roc_probas_df,\n",
    "                        n_iter=3, verbosity=11, n_jobs=1, subsample_train=.001, \n",
    "                        subsample_test=.0001, default_params=default_params)\n",
    "\n",
    "print(\"Testing %i combinations %i times\" % (len(ps_df.combinations), ps_df.n_iter))\n",
    "print(ps_df.combinations)\n",
    "ps_df.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_df.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params['verbose'] = 1\n",
    "default_params['batch_size'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DensityForest instance\n",
    "clf_df = DensityForest(**ps_df.best_params, **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df.fit(act_train[..., :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities for all images\n",
    "probas_df = clf_df.predict(act_test[..., :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# indices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "#probas_df_c = imgs_stretch_eq(probas_df[dataset_subset_indices, np.newaxis])[0, ..., 0]\n",
    "probas_df_c = probas_df[dataset_subset_indices]\n",
    "colors_plt = plt.cm.YlOrRd(1-np.log(probas_df_c))[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_df_c < np.sort(probas_df_c)[200])*255)[:, :3]\n",
    "c_thresh_f = plt.cm.YlOrRd((probas_df_c > np.sort(probas_df_c)[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "# axes[0].savefig(\"../Figures/Zurich/GIF/probas.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape probas to (n_patches, patch_size, patch_size)\n",
    "probas_patches_df = np.reshape(probas_df, np.shape(data_test.gt_patches))\n",
    "\n",
    "# transformations\n",
    "probas_patches_df -= np.nanmin(probas_patches_df)\n",
    "probas_patches_df /= np.nanmax(probas_patches_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "y_scores = -probas_df\n",
    "\n",
    "# PR\n",
    "precision_df, recall_df, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_df = metrics.auc(recall_df, precision_df)\n",
    "\n",
    "# ROC\n",
    "fpr_df, tpr_df, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_df = metrics.roc_auc_score(y_true, y_scores)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_df, pr_auc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "img_idx = 2\n",
    "acc_im_df = convert_patches_to_image(data_test.imgs, probas_patches_df[...,np.newaxis], img_idx, 64, 64, 0)\n",
    "acc_im_df = imgs_stretch_eq([acc_im_df])[0]\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(acc_im_df[..., 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "# order according to increasing score\n",
    "scores_pr = np.multiply([pr_auc_msr, pr_auc_margin, pr_auc_entropy, \n",
    "                         pr_auc_dropout, pr_auc_gmm, pr_auc_svm, pr_auc_df], 100)\n",
    "\n",
    "recalls = [recall_msr, recall_margin, recall_entropy, recall_dropout, recall_gmm, recall_svm, recall_df]\n",
    "precisions = [precision_msr, precision_margin, precision_entropy, precision_dropout, \n",
    "              precision_gmm, precision_svm, precision_df]\n",
    "\n",
    "names_methods = np.array(['MSR', 'Margin', 'Entropy', 'Dropout', 'GMM', 'OC SVM', 'DF'])\n",
    "scores_order = np.argsort(scores_pr)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_pr)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(recalls[i], precisions[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_pr[i]) for i in scores_order], title=\"PR AUC [%]\")\n",
    "plt.savefig(\"../Figures/Zurich/PR_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "# order according to increasing score\n",
    "scores_auc = np.multiply([auroc_msr, auroc_margin, auroc_entropy, \n",
    "                          auroc_dropout, auroc_gmm, auroc_svm, auroc_df], 100)\n",
    "fprs = [fpr_msr, fpr_margin, fpr_entropy, fpr_dropout, fpr_gmm, fpr_svm, fpr_df]\n",
    "tprs = [tpr_msr, tpr_margin, tpr_entropy, tpr_dropout, tpr_gmm, tpr_svm, tpr_df]\n",
    "scores_order = np.argsort(scores_auc)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_auc)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(fprs[i], tprs[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', c='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_auc[i]) for i in scores_order], title=\"AUROC [%]\")\n",
    "plt.savefig(\"../Figures/Zurich/ROC_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
