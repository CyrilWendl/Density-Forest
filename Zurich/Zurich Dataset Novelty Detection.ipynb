{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zurich Land Cover Classification\n",
    "\n",
    "This script presents a visualization of training a U-Net classifier on 7 out of 8 available land cover classes of the Zurich dataset, and detecting the unseen class using a Density Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16245994773464322485\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10919205274\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6869982681379639708\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# python libraries\n",
    "import os, sys\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from sklearn import decomposition, svm, preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.stats import skew\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# custom libraries\n",
    "# base_dir = '/Users/cyrilwendl/Documents/EPFL'\n",
    "base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "sys.path.append(base_dir + '/SIE-Master/Code')  # Path to density Tree package\n",
    "\n",
    "from helpers.helpers import *\n",
    "from helpers.plots import *\n",
    "from helpers.data_augment import *\n",
    "from helpers.data_loader import *\n",
    "from helpers.parameter_search import *\n",
    "from density_forest.density_forest import *\n",
    "from density_forest.helpers import *\n",
    "from baselines.helpers import *\n",
    "from keras_helpers.unet import *\n",
    "from keras_helpers.callbacks import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # sys.argv[2]\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "class_to_remove = 2  # int(sys.argv[1])\n",
    "paramsearch = False  # search for best hyperparameters\n",
    "\n",
    "my_dpi=255 # dpi of my screen, for image exporting\n",
    "\n",
    "# data frame with previously found optimal hyperparameters\n",
    "df_ps = pd.read_csv('models_out/hyperparams.csv', index_col=0) \n",
    "df_auroc = pd.read_csv('models_out/auroc_all.csv', index_col=0)\n",
    "df_aucpr = pd.read_csv('models_out/aucpr_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading data with overlap\n",
      "classes to keep: ['Roads' 'Trees' 'Grass' 'Bare Soil' 'Water' 'Railways' 'Swimming Pools']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "# data without overlap\n",
    "print(\"loading data\")\n",
    "data_train = ZurichLoader(path, 'train', class_to_remove=class_to_remove)\n",
    "data_val = ZurichLoader(path, 'val', class_to_remove=class_to_remove)\n",
    "data_test = ZurichLoader(path, 'test', class_to_remove=class_to_remove)\n",
    "\n",
    "print(\"loading data with overlap\")\n",
    "# data with overlap, for prediction\n",
    "data_train_overlap = ZurichLoader(path, 'train', stride=32, inherit_loader=data_train)\n",
    "data_val_overlap = ZurichLoader(path, 'val', stride=32, inherit_loader=data_val)\n",
    "data_test_overlap = ZurichLoader(path, 'test', stride=32, inherit_loader=data_test)\n",
    "\n",
    "# class names and colors\n",
    "names = data_train.names\n",
    "colors = data_train.colors\n",
    "n_classes = 8\n",
    "classes_to_keep = np.asarray([x for x in range(1, n_classes + 1) if x != class_to_remove])\n",
    "names_keep = np.asarray(names)[classes_to_keep]\n",
    "print(\"classes to keep: \" + str(names_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, offset in zip([data_train, data_val, data_test], [0, 10, 15]):\n",
    "    for im_idx, im in enumerate(dataset.imgs):\n",
    "        im = im[..., :3]\n",
    "        f_name = \"../Figures/Zurich/Im/Im_\" + str(im_idx + offset) + \".jpg\"\n",
    "        export_figure_matplotlib(im, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, offset in zip([data_train, data_val, data_test], [0, 10, 15]):\n",
    "    for gt_idx, gt in enumerate(dataset.gt):\n",
    "        gt_col = gt_label_to_color(gt, colors)*255\n",
    "        f_name = \"../Figures/Zurich/Im/GT_\" + str(gt_idx + offset) + \".jpg\"\n",
    "        export_figure_matplotlib(gt_col, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_labels_tr, cnt_tr = np.unique(data_train.gt_patches.astype('int'), return_counts=True)\n",
    "pred_labels_val, cnt_val = np.unique(data_val.gt_patches.astype('int'), return_counts=True)\n",
    "pred_labels_te, cnt_te = np.unique(data_test.gt_patches.astype('int'), return_counts=True)\n",
    "\n",
    "cnt_tr = cnt_tr / np.sum(cnt_tr) * 100\n",
    "cnt_val = np.concatenate((cnt_val / np.sum(cnt_val) * 100, [0]))\n",
    "cnt_te = cnt_te / np.sum(cnt_te) * 100\n",
    "\n",
    "df = pd.DataFrame({'Train': cnt_tr, 'Val': cnt_val, 'Test': cnt_te}, index=names[pred_labels_tr])\n",
    "\n",
    "axis = df[::-1].plot.barh(figsize=(7, 6), colormap='winter')\n",
    "plt.xlim([0, 100])\n",
    "plt.xlabel(\"Count [%]\")\n",
    "plt.grid(alpha=.3)\n",
    "axis.spines['right'].set_visible(False)\n",
    "axis.spines['top'].set_visible(False)\n",
    "plt.savefig(\"../Figures/Zurich/Pred_count/ZH_dist.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create copies of original data\\ny_train_label = y_train.copy()\\ny_val_label = y_val.copy()\\ny_test_label = y_test.copy()\\n\\n# get class weights\\nlabels_unique = np.unique(y_train.flatten())\\nprint(labels_unique)\\nclass_weights = class_weight.compute_class_weight(\\'balanced\\', labels_unique, y_train.flatten())\\nclass_weights[0] = 0  # give less weight to background label class\\nclass_weights[5] = 7  # give less weight to bare soil class\\nclass_weights[8] = 7  # give less weight to swimming pool class\\n\\nprint(\"Class weights:\")\\nfor i, w in enumerate(class_weights):\\n    print(\"%15s: %3.3f\" % (names[i], w))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# create copies of original data\n",
    "y_train_label = y_train.copy()\n",
    "y_val_label = y_val.copy()\n",
    "y_test_label = y_test.copy()\n",
    "\n",
    "# get class weights\n",
    "labels_unique = np.unique(y_train.flatten())\n",
    "print(labels_unique)\n",
    "class_weights = class_weight.compute_class_weight('balanced', labels_unique, y_train.flatten())\n",
    "class_weights[0] = 0  # give less weight to background label class\n",
    "class_weights[5] = 7  # give less weight to bare soil class\n",
    "class_weights[8] = 7  # give less weight to swimming pool class\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(class_weights):\n",
    "    print(\"%15s: %3.3f\" % (names[i], w))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# convert to numpy arrays\\nx_train = np.asarray(x_train)\\nx_val = np.asarray(x_val)\\nx_test = np.asarray(x_test)\\n\\n# make y data categorical\\ny_train = to_categorical(y_train_label, n_classes)\\ny_val = to_categorical(y_val_label, n_classes)\\n\\ny_train = y_train[..., classes_to_keep]\\ny_val = y_val[..., classes_to_keep]\\nn_classes = len(classes_to_keep)\\nclass_weights = class_weights[classes_to_keep]\\n\\n# print shapes of variables\\nfor var in x_train, y_train, x_val, y_val:\\n    print(np.shape(var))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# convert to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "x_val = np.asarray(x_val)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "# make y data categorical\n",
    "y_train = to_categorical(y_train_label, n_classes)\n",
    "y_val = to_categorical(y_val_label, n_classes)\n",
    "\n",
    "y_train = y_train[..., classes_to_keep]\n",
    "y_val = y_val[..., classes_to_keep]\n",
    "n_classes = len(classes_to_keep)\n",
    "class_weights = class_weights[classes_to_keep]\n",
    "\n",
    "# print shapes of variables\n",
    "for var in x_train, y_train, x_val, y_val:\n",
    "    print(np.shape(var))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# callbacks (evaluated every epoch)\\n# show loss and accuracy figures after each epoch\\ncallback_plot = PlotLosses()\\n\\n# stop early if after several epochs the accuracy doesn\\'t improve\\ncallback_earlystop = EarlyStopping(monitor=\\'val_loss\\', min_delta=1e-4, patience=24, verbose=1, mode=\\'auto\\')\\n\\n# decrease learning rate when accuracy stops improving\\ncallback_lr = ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.5, patience=12, verbose=1, mode=\\'auto\\',\\n                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\\n\\n# checkpoint to save weights at every epoch (in case of interruption)\\nfile_path = \"weights-improvement.hdf5\"\\ncallback_checkpoint = ModelCheckpoint(file_path, monitor=\\'val_acc\\', verbose=0, save_best_only=True, mode=\\'max\\')\\n\\ncallback_tensorboard = TensorBoard(log_dir=\\'./tensorboard\\', histogram_freq=0, write_graph=True, write_images=True)\\n\\n# model setup\\nbatch_size = 20\\nepochs = 300\\n\\n\\ndef model_train(model, data_augmentation):\\n    # Fit the model on the batches generated by datagen.flow().\\n    model.fit_generator(batch_generator(x_train, y_train,\\n                                        batch_size=batch_size, data_augmentation=data_augmentation),\\n                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\\n                        epochs=epochs,\\n                        verbose=1,\\n                        class_weight=class_weights,  # weights for loss function\\n                        validation_data=(x_val, y_val),\\n                        callbacks=[callback_earlystop,\\n                                   callback_lr,\\n                                   # callback_checkpoint,\\n                                   callback_plot,\\n                                   callback_tensorboard],\\n                        workers=cpu_count(),\\n                        use_multiprocessing=True)\\n                        \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# callbacks (evaluated every epoch)\n",
    "# show loss and accuracy figures after each epoch\n",
    "callback_plot = PlotLosses()\n",
    "\n",
    "# stop early if after several epochs the accuracy doesn't improve\n",
    "callback_earlystop = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=24, verbose=1, mode='auto')\n",
    "\n",
    "# decrease learning rate when accuracy stops improving\n",
    "callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, verbose=1, mode='auto',\n",
    "                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "# checkpoint to save weights at every epoch (in case of interruption)\n",
    "file_path = \"weights-improvement.hdf5\"\n",
    "callback_checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# model setup\n",
    "batch_size = 20\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "def model_train(model, data_augmentation):\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(batch_generator(x_train, y_train,\n",
    "                                        batch_size=batch_size, data_augmentation=data_augmentation),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        class_weight=class_weights,  # weights for loss function\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback_earlystop,\n",
    "                                   callback_lr,\n",
    "                                   # callback_checkpoint,\n",
    "                                   callback_plot,\n",
    "                                   callback_tensorboard],\n",
    "                        workers=cpu_count(),\n",
    "                        use_multiprocessing=True)\n",
    "                        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or load model\n",
    "# train the model\n",
    "# model_unet = get_unet(n_classes, x_train.shape[1:])\n",
    "# model_train(model_unet, data_augmentation=True)\n",
    "# model_unet.save('models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')  # save model, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "name_model = path + '/models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower().replace(\" \", \"\") + '.h5'    \n",
    "model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15640/15640 [==============================] - 16s 1ms/step\n",
      "5165/5165 [==============================] - 5s 926us/step\n",
      "5223/5223 [==============================] - 4s 746us/step\n"
     ]
    }
   ],
   "source": [
    "# get all predictions in training and test set\n",
    "# training set\n",
    "y_pred_tr = model_unet.predict(data_train_overlap.im_patches, verbose=1)\n",
    "y_pred_tr = remove_overlap(data_train.imgs, y_pred_tr, 64, 32)\n",
    "y_pred_label_tr = get_y_pred_labels(y_pred_tr, class_to_remove=class_to_remove, background=True)\n",
    "\n",
    "# validation set\n",
    "y_pred_val = model_unet.predict(data_val_overlap.im_patches, verbose=1)\n",
    "y_pred_val = remove_overlap(data_val.imgs, y_pred_val, 64, 32)\n",
    "y_pred_label_val = get_y_pred_labels(y_pred_val, class_to_remove=class_to_remove, background=True)\n",
    "\n",
    "# test set\n",
    "y_pred_te = model_unet.predict(data_test_overlap.im_patches, verbose=1)\n",
    "y_pred_te = remove_overlap(data_test.imgs, y_pred_te, 64, 32)\n",
    "y_pred_label_te = get_y_pred_labels(y_pred_te, class_to_remove=class_to_remove, background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of correctly / incorrectly predicted pixels\n",
    "# train\n",
    "pred_t_tr = y_pred_label_tr == data_train.gt_patches\n",
    "pred_f_tr = data_train.gt_patches == class_to_remove\n",
    "\n",
    "# val\n",
    "pred_t_val = y_pred_label_val == data_val.gt_patches\n",
    "pred_f_val = data_val.gt_patches == class_to_remove\n",
    "\n",
    "# test\n",
    "pred_t_te = y_pred_label_te == data_test.gt_patches\n",
    "pred_f_te = data_test.gt_patches == class_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export predicted images\n",
    "offset = 0\n",
    "for dataset, preds in zip([data_train, data_val, data_test], [y_pred_label_tr, y_pred_label_val, y_pred_label_te]):\n",
    "    imgs = convert_patches_to_image(dataset.imgs, preds[..., np.newaxis], 64, 64)\n",
    "    for im_idx, im in enumerate(imgs):\n",
    "        im_color = gt_label_to_color(im, colors) * 255\n",
    "        f_name = \"../Figures/Zurich/Im_pred/cl_\" + str(class_to_remove)\n",
    "        f_name = f_name + \"/Im_\" + str(im_idx + offset) + \"_wo_cl_\" + str(class_to_remove) + \".jpg\"\n",
    "        export_figure_matplotlib(im_color, f_name, dpi=my_dpi)\n",
    "        \n",
    "    offset += len(dataset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90.82 90.21]\n",
      "[89.45 77.84]\n",
      "[84.2  70.37]\n"
     ]
    }
   ],
   "source": [
    "# Get oa, aa for train, val, test\n",
    "# train\n",
    "y_pred_tr_flattened = np.asarray(y_pred_label_tr.flatten()).astype('int')\n",
    "y_tr_flattened = np.asarray(data_train.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_tr_flattened != 0) & (y_tr_flattened != class_to_remove)\n",
    "oa_tr = oa(y_tr_flattened[filter_items], y_pred_tr_flattened[filter_items])\n",
    "aa_tr, aa_tr_cl = aa(y_tr_flattened[filter_items], y_pred_tr_flattened[filter_items])\n",
    "\n",
    "# val\n",
    "y_pred_val_flattened = np.asarray(y_pred_label_val.flatten()).astype('int')\n",
    "y_val_flattened = np.asarray(data_val.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_val_flattened != 0) & (y_val_flattened != class_to_remove)\n",
    "oa_val = oa(y_val_flattened[filter_items], y_pred_val_flattened[filter_items])\n",
    "aa_val, aa_val_cl = aa(y_val_flattened[filter_items], y_pred_val_flattened[filter_items])\n",
    "\n",
    "# test\n",
    "y_pred_te_flattened = np.asarray(y_pred_label_te.flatten()).astype('int')\n",
    "y_te_flattened = np.asarray(data_test.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_te_flattened != 0) & (y_te_flattened != class_to_remove)\n",
    "oa_te = oa(y_te_flattened[filter_items], y_pred_te_flattened[filter_items])\n",
    "aa_te, aa_te_cl = aa(y_te_flattened[filter_items], y_pred_te_flattened[filter_items])\n",
    "\n",
    "print(np.round(np.multiply([oa_tr, aa_tr], 100), 2))\n",
    "print(np.round(np.multiply([oa_val, aa_val], 100), 2))\n",
    "print(np.round(np.multiply([oa_te, aa_te], 100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metrics to CSV files\n",
    "df_metrics = pd.read_csv('models_out/metrics_ND.csv', index_col=0)\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]): [oa_tr, aa_tr, oa_val, aa_val, oa_te, aa_te]},\n",
    "                    index=['OA Train', 'AA Train', 'OA Val', 'AA Val', 'OA Test', 'AA Test']).T\n",
    "df_metrics = df_metrics.append(df2)\n",
    "df_metrics = df_metrics[~df_metrics.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_metrics.to_csv('models_out/metrics_ND.csv')\n",
    "# print((df_metrics*100).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Roads      0.806     0.955     0.874    794570\n",
      "         Trees      0.805     0.834     0.819    693092\n",
      "         Grass      0.941     0.737     0.827    689620\n",
      "     Bare Soil      0.677     0.767     0.719     88088\n",
      "         Water      0.991     0.912     0.950    284293\n",
      "      Railways      0.001     0.001     0.001     19190\n",
      "Swimming Pools      0.000     0.000     0.000     10457\n",
      "\n",
      "   avg / total      0.849     0.842     0.840   2579310\n",
      "\n",
      "84.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics\n",
    "y_pred_flattened = np.asarray(y_pred_label_te.flatten()).astype('int')\n",
    "y_test_flattened = np.asarray(data_test.gt_patches.flatten()).astype('int')\n",
    "\n",
    "# mask background and removed classes for evaluation metrics\n",
    "filter_items = (y_test_flattened != 0) & (y_test_flattened != class_to_remove)\n",
    "\n",
    "# Class accuracy, average accuracy\n",
    "print(metrics.classification_report(\n",
    "    y_test_flattened[filter_items],\n",
    "    y_pred_flattened[filter_items],\n",
    "    target_names=names_keep,\n",
    "    digits=3))\n",
    "\n",
    "\n",
    "# Overall accuracy\n",
    "print(np.round(oa_te * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of predictions in unseen class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of predicted label\n",
    "pred_labels, pred_counts = np.unique(y_pred_label_te[pred_f_te], return_counts=True)\n",
    "pred_counts = pred_counts / sum(pred_counts) * 100\n",
    "\n",
    "# visualization\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.bar(pred_labels, pred_counts)\n",
    "plt.xticks(np.arange(0, 10))\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Count [%]\")\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.title(\"Misclassified labels (mean MSR=%.2f)\" % np.mean(get_acc_net_msr(y_pred_te[pred_f_te])))\n",
    "plt.xticks(pred_labels_te, names, rotation=20)\n",
    "plt.savefig(\"../Figures/Zurich/Pred_count/ZH_pred-count_wo_cl\" + str(class_to_remove) + \".pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_msr = get_acc_net_msr(y_pred_te).flatten()\n",
    "probas_margin = get_acc_net_max_margin(y_pred_te).flatten()\n",
    "probas_entropy = get_acc_net_entropy(y_pred_te).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.65, PR AUC: 0.20\n",
      "AUROC: 0.66, PR AUC: 0.21\n",
      "AUROC: 0.65, PR AUC: 0.20\n"
     ]
    }
   ],
   "source": [
    "# precision-recall curves\n",
    "y_true = pred_f_te.flatten()\n",
    "\n",
    "# msr\n",
    "precision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, -probas_msr)\n",
    "pr_auc_msr = metrics.average_precision_score(y_true, -probas_msr)\n",
    "auroc_msr = metrics.roc_auc_score(y_true, -probas_msr)\n",
    "fpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, -probas_msr)\n",
    "\n",
    "# margin\n",
    "precision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, -probas_margin)\n",
    "pr_auc_margin = metrics.average_precision_score(y_true, -probas_margin)\n",
    "auroc_margin = metrics.roc_auc_score(y_true, -probas_margin)\n",
    "fpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, -probas_margin)\n",
    "\n",
    "# entropy\n",
    "precision_entropy, recall_entropy, _ = metrics.precision_recall_curve(y_true, -probas_entropy)\n",
    "pr_auc_entropy = metrics.average_precision_score(y_true, -probas_entropy)\n",
    "\n",
    "auroc_entropy = metrics.roc_auc_score(y_true, -probas_entropy)\n",
    "fpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, -probas_entropy)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_msr, pr_auc_msr))\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_margin, pr_auc_margin))\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_entropy, pr_auc_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "# MSR\n",
    "probas_patches_msr = np.reshape(probas_msr, np.shape(data_test.gt_patches))\n",
    "probas_patches_msr -= np.min(probas_patches_msr)\n",
    "probas_patches_msr /= np.max(probas_patches_msr)\n",
    "\n",
    "# margin\n",
    "probas_patches_margin = np.reshape(probas_margin, np.shape(data_test.gt_patches))\n",
    "probas_patches_margin -= np.min(probas_patches_margin)\n",
    "probas_patches_margin /= np.max(probas_patches_margin)\n",
    "\n",
    "# entropy\n",
    "probas_patches_entropy = np.reshape(probas_entropy, np.shape(data_test.gt_patches))\n",
    "probas_patches_entropy -= np.min(probas_patches_entropy)\n",
    "probas_patches_entropy /= np.max(probas_patches_entropy)\n",
    "\n",
    "base_folder = \"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_im_msr = convert_patches_to_image(data_test.imgs, probas_patches_msr[..., np.newaxis], 64, 64)\n",
    "acc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis], 64, 64)\n",
    "acc_im_entropy = convert_patches_to_image(data_test.imgs, probas_patches_entropy[..., np.newaxis], 64, 64)\n",
    "\n",
    "# export images\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    # msr\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_net_msr_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_msr[img_idx], f_name, dpi=my_dpi)\n",
    "    \n",
    "    # margin\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_net_margin_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_margin[img_idx], f_name, dpi=my_dpi)\n",
    "    \n",
    "    # entropy\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_net_entropy_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_entropy[img_idx], f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAABLCAYAAACr45hhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAfhJREFUeJzt1k2Om0AUhdFXkL1kydlClpJNUS8DGzemkZ0MrlpqnSMhXH82YvDJo7sLIGH56gcAvi+BAWIEBogRGCBGYIAYgQFiBAaIERggRmCAmB//s/n3+rOXpepxjcPni2uM8XL9+B1Vx/lRYx01lvu1ftyXp7nl077l4sxYlhrLqGV9XqvH/fYgYx23BzrM7/vqcKbuv3ve+7xn/77zi3r/eYyr+Tfnxv0ljuVjvF/n8dh/Z3297+Jcj6ruWbNndZ3uPWvWvFjf3qxfne+a+736efxp7Th/GteLte7aug732yvcumt2Pea27przNH6s92G+as7T+L6+ddc293u/Hj/m6rB2Gl+cn7OqZ39c3c/jq+vdnov1qqr+9Wf8SzP8gwFiBAaIERggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYgQGiBEYIEZggBiBAWIEBogRGCBGYIAYgQFiBAaIERggRmCAGIEBYkZ3f/UzAN+UfzBAjMAAMQIDxAgMECMwQIzAADECA8QIDBAjMECMwAAxfwFz5mOgoT6MYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x108 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export colorbar\n",
    "a = np.array([[0, 1]])\n",
    "plt.figure(figsize=(9, 1.5))\n",
    "img = plt.imshow(a, cmap=\"RdYlGn\")\n",
    "plt.gca().set_visible(False)\n",
    "cax = plt.axes([0.1, 0.1, 0.4, 0.5])\n",
    "cb = plt.colorbar(orientation=\"horizontal\", cax=cax)\n",
    "cb.outline.set_linewidth(0)\n",
    "plt.axis('off')\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "plt.savefig(\"../Figures/Zurich/Im_cert/colorbar.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:33<00:00,  9.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "y_preds = predict_with_dropout_imgs(model_unet, data_test_overlap, batch_size=500, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction and confidence\n",
    "prediction = np.mean(y_preds, 0)\n",
    "probas_dropout = get_acc_net_entropy(prediction)\n",
    "del y_preds  # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.65, PR AUC: 0.21\n"
     ]
    }
   ],
   "source": [
    "# dropout metrics\n",
    "y_scores = -probas_dropout.flatten()\n",
    "precision_dropout, recall_dropout, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_dropout = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_dropout = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_dropout, tpr_dropout, _ = metrics.roc_curve(y_true, y_scores)\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_dropout, pr_auc_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_dropout = np.reshape(probas_dropout, np.shape(data_test.gt_patches))\n",
    "probas_patches_dropout -= np.min(probas_patches_dropout)\n",
    "probas_patches_dropout /= np.max(probas_patches_dropout)\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "acc_im_dropout = convert_patches_to_image(data_test.imgs, probas_patches_dropout[..., np.newaxis], 64, 64)\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    # export\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_dropout_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_dropout[img_idx], f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Activations, PCA, t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:52<00:00, 14.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations for training Density Forest\n",
    "act_train_all = get_activations_batch(model_unet, -2, data_train_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_train_all = remove_overlap(data_train.imgs, act_train_all, patch_size=64, stride=32)\n",
    "act_train = act_train_all[pred_t_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:06<00:00, 42.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations\n",
    "act_val_all = get_activations_batch(model_unet, -2, data_val_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_val_all = remove_overlap(data_val.imgs, act_val_all, patch_size=64, stride=32)\n",
    "act_val = act_val_all[pred_t_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [00:08<00:00, 31.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations for testing Density Forest\n",
    "act_test = get_activations_batch(model_unet, -2, data_test_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# remove test activations overlap\n",
    "act_test = remove_overlap(data_test.imgs, act_test, patch_size=64, stride=32)\n",
    "act_test = np.concatenate(np.concatenate(act_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get balanced data subset to show in figure\n",
    "tsne_pts_per_class = 200\n",
    "dataset_subset_indices = get_balanced_subset_indices(data_test.gt_patches.flatten(), \n",
    "                                                     np.arange(1, 9), pts_per_class=tsne_pts_per_class)\n",
    "dataset_subset_indices = np.concatenate(dataset_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 1600 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1600 samples in 1.608s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1600\n",
      "[t-SNE] Computed conditional probabilities for sample 1600 / 1600\n",
      "[t-SNE] Mean sigma: 0.996462\n"
     ]
    }
   ],
   "source": [
    "# t-SNE visualization\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=500)\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])\n",
    "tsne_y = data_test.gt_patches.flatten()[dataset_subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.set_axis_off()\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, class_to_remove=class_to_remove)\n",
    "plt.savefig(\"../Figures/Zurich/tSNE/t-SNE_wo_cl\" + str(class_to_remove) + \"_before_PCA.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create density tree for activation weights of training data\n",
    "# PCA\n",
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(act_test)  # fit on training set without background pixels\n",
    "n_components = np.alen(pca.explained_variance_ratio_)\n",
    "print(\"Variance explained by first %i components: %.2f\" % (\n",
    "    n_components, sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "# transform training activations\n",
    "act_train_all = pca.transform(np.concatenate(np.concatenate(act_train_all)))\n",
    "act_train = pca.transform(act_train)\n",
    "\n",
    "act_val_all = pca.transform(np.concatenate(np.concatenate(act_val_all)))\n",
    "act_val = pca.transform(act_val)\n",
    "\n",
    "\n",
    "# transform test set activations\n",
    "act_test = pca.transform(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance\n",
    "fig = plt.figure()\n",
    "plt.scatter(np.arange(n_components), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative sum of explained variance\")\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.savefig(\"../Figures/Zurich/PCA/ZH_pca_components_wo_cl_\" + str(class_to_remove) + \".pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization after PCA\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])\n",
    "# tsne without unseen class\n",
    "tsne_train = tsne_all[tsne_y != class_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pts_2d(x_pts, y_labels, ax, classes_to_keep, colors,\n",
    "                names=None, class_to_remove=None, s_name=None, subsample_pct=1):\n",
    "    \"\"\"\n",
    "    Plot 2D data with class label\n",
    "    :param x_pts: 2D data to plot\n",
    "    :param y_labels: the corresponding y labels to the PCA data, needs to be in same classes as classes_to_keep\n",
    "    :param ax: axis on which to plot data (can be combined with other plot calls, such as to show ellipses)\n",
    "    :param class_to_remove: class number removed in classification\n",
    "    :param classes_to_keep: array of classes to keep\n",
    "    :param names: class names for legend (optional)\n",
    "    :param subsample_pct: percentage of all data to show\n",
    "    :param colors: colors corresponding to classes\n",
    "    :param s_name: name where to save figure\n",
    "    \"\"\"\n",
    "    # points corresponding to seen classes\n",
    "    for i, class_keep in enumerate(classes_to_keep):\n",
    "        data_plt = draw_subsamples(x_pts[y_labels == class_keep], subsample_pct, replace=False)\n",
    "        if class_to_remove is not None:\n",
    "            alpha = .3\n",
    "        else:\n",
    "            alpha = .7\n",
    "        ax.scatter(data_plt[:, 0], data_plt[:, 1], c=np.asarray(colors)[class_keep], s=30, marker='o', alpha=alpha)\n",
    "\n",
    "    # points corresponding to unseen class\n",
    "    if class_to_remove is not None:\n",
    "        data_plt = draw_subsamples(x_pts[y_labels == class_to_remove], subsample_pct, replace=False)\n",
    "        ax.scatter(data_plt[:, 0], data_plt[:, 1], c=np.asarray(colors)[class_to_remove], marker='x', s=90)\n",
    "\n",
    "    # add legend\n",
    "    if names is not None:\n",
    "        names_keep = np.asarray(names)[classes_to_keep]\n",
    "        names_keep = names_keep.tolist()\n",
    "        names_legend = names_keep.copy()\n",
    "        if class_to_remove is not None:\n",
    "            names_legend.append('unseen class (' + names[class_to_remove] + ')')\n",
    "        ax.legend(names_legend, framealpha=1)\n",
    "\n",
    "    if s_name is not None:\n",
    "        plt.savefig(s_name, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, class_to_remove=class_to_remove)\n",
    "ax.set_axis_off()\n",
    "plt.savefig(\"../Figures/Zurich/tSNE/t-SNE_wo_cl\" + str(class_to_remove) + \"_after_PCA.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 3 PCA components\n",
    "plot_pts_3d(act_test[:, :3], data_test.gt_patches.flatten(), classes_to_keep, colors,\n",
    "            class_to_remove=class_to_remove, subsample_pct=.0003,\n",
    "            s_name='../Figures/Zurich/PCA/pca_components_3d_' + str(names[class_to_remove]) + '.pdf')\n",
    "\n",
    "print(\"Variance explained by first 3 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 2 PCA components\n",
    "_, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_axis_off()\n",
    "plot_pts_2d(act_test[:, :2], data_test.gt_patches.flatten(), ax, classes_to_keep, colors,\n",
    "            class_to_remove=class_to_remove, subsample_pct=.0005,\n",
    "            s_name='../Figures/Zurich/PCA/pca_components_2d_' + str(names[class_to_remove]) + '.pdf')\n",
    "print(\"Variance explained by first 2 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search\n",
    "if paramsearch:\n",
    "    tuned_parameters = [{'n_components': np.arange(3, 10), 'max_iter': [10000]}]\n",
    "    # do parameter search\n",
    "    ps_gmm = ParameterSearch(GaussianMixture, tuned_parameters, act_train, act_train_all,\n",
    "                             pred_f_tr.flatten(), scorer_roc_probas_gmm, \n",
    "                             n_iter=3, verbosity=10, n_jobs=-1, subsample_train=.01, subsample_test=.01)\n",
    "    ps_gmm.fit()\n",
    "    best_params_gmm = ps_gmm.best_params\n",
    "else:\n",
    "    best_params_gmm = {'n_components': df_ps.loc[str(names[class_to_remove])]['gmm_n_components'], 'max_iter': 10000}\n",
    "\n",
    "print(best_params_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GMM\n",
    "gmm = GaussianMixture(**best_params_gmm)\n",
    "gmm.fit(draw_subsamples(act_train, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "probas_gmm = gmm.score_samples(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO divide y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original histogram\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "_ = plt.hist(probas_gmm, bins=1000)\n",
    "plt.xlim([-30, 0])\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title('Skewness: %.2f' % skew(probas_gmm))\n",
    "plt.savefig(\"../Figures/Zurich/Skew/Skew_GMM_wo_cl\" + str(class_to_remove) + \".pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare to histogram stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stretched histogram\n",
    "p2 = np.percentile(probas_gmm, 2)\n",
    "p98 = np.percentile(probas_gmm, 98)\n",
    "probas_gmm_s = exposure.rescale_intensity(probas_gmm, in_range=(p2, p98))  # stretch\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "_ = plt.hist(probas_gmm_s, bins=1000)\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title('Skewness: %.2f' % skew(probas_gmm_s))\n",
    "plt.savefig(\"../Figures/Zurich/Skew/Skew_GMM_wo_cl\" + str(class_to_remove) + \"_stretched.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalized histogram\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "_ = plt.hist(exposure.equalize_hist(probas_gmm), bins=100)\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title('Skewness: %.2f' % skew(exposure.equalize_hist(probas_gmm)))\n",
    "plt.savefig(\"../Figures/Zurich/Skew/Skew_GMM_wo_cl\" + str(class_to_remove) + \"_eq.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "_ = plt.hist(1.2 ** probas_gmm, bins=50)\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title('Skewness: %.2f' % skew(1.2 ** probas_gmm))\n",
    "plt.savefig(\"../Figures/Zurich/Skew/Skew_GMM_wo_cl\" + str(class_to_remove) + \"_corr.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "precision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, -probas_gmm)\n",
    "pr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\n",
    "\n",
    "# ROC\n",
    "fpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, -probas_gmm)\n",
    "auroc_gmm = metrics.roc_auc_score(y_true, -probas_gmm)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_gmm, pr_auc_gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_gmm = np.reshape(probas_gmm, np.shape(data_test.gt_patches))\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "acc_im_gmm = convert_patches_to_image(data_test.imgs, probas_patches_gmm[..., np.newaxis], 64, 64)\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    # original \n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_gmm_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_gmm[img_idx], f_name, dpi=my_dpi)\n",
    "    \n",
    "    # equalized\n",
    "    acc_im_gmm_ = exposure.equalize_hist(acc_im_gmm[img_idx])\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_gmm_im_\" + str(img_idx) + \"_eq.jpg\"\n",
    "    export_figure_matplotlib(acc_im_gmm_, f_name, dpi=my_dpi)\n",
    "    \n",
    "    # strethed\n",
    "    p2 = np.percentile(acc_im_gmm[img_idx], 2)\n",
    "    p98 = np.percentile(acc_im_gmm[img_idx], 98)\n",
    "    acc_im_gmm_stretched = exposure.rescale_intensity(acc_im_gmm[img_idx], (p2, p98))\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_gmm_im_\" + str(img_idx) + \"_stretched.jpg\"\n",
    "    export_figure_matplotlib(acc_im_gmm_stretched, f_name, dpi=my_dpi)\n",
    "    \n",
    "    # de-skewed\n",
    "    acc_im_gmm_ = np.exp(1.2 ** acc_im_gmm[img_idx])\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_gmm_im_\" + str(img_idx) + \"_deskew.jpg\"\n",
    "    export_figure_matplotlib(acc_im_gmm_, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train_svm = preprocessing.scale(act_train)\n",
    "act_train_all_svm = preprocessing.scale(act_train_all)\n",
    "act_val_all_svm = preprocessing.scale(act_val_all)\n",
    "act_test_svm = preprocessing.scale(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search\n",
    "if paramsearch:\n",
    "    tuned_parameters = [{'kernel': ['rbf'],\n",
    "                         'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1],\n",
    "                         'degree':[1]\n",
    "                         },\n",
    "                        {'kernel': ['poly'],\n",
    "                         'degree': np.arange(1, 4),\n",
    "                         'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1],\n",
    "                         'max_iter': [10000]}]\n",
    "\n",
    "    # do parameter search\n",
    "    ps_svm = ParameterSearch(svm.OneClassSVM, tuned_parameters, act_train_svm, act_val_all_svm,\n",
    "                             pred_f_val.flatten(), scorer_roc_probas_svm, n_iter=5,\n",
    "                             verbosity=11, n_jobs=-1, subsample_train=.001, subsample_test=.01)\n",
    "    ps_svm.fit()\n",
    "    best_params_svm = ps_svm.best_params\n",
    "else:\n",
    "    best_params_svm = {'kernel': df_ps.loc[str(names[class_to_remove])]['oc-svm_k'], \n",
    "                       'degree': df_ps.loc[str(names[class_to_remove])]['oc-svm_deg'], \n",
    "                       'nu': df_ps.loc[str(names[class_to_remove])]['oc_svm_nu'],\n",
    "                       'max_iter': 100}\n",
    "    \n",
    "print(best_params_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "clf_svm = svm.OneClassSVM(**best_params_svm, verbose=True)\n",
    "\n",
    "if best_params_svm['nu'] == 0.001:\n",
    "    clf_svm.fit(draw_subsamples(act_train_svm, .1))\n",
    "else:\n",
    "    clf_svm.fit(draw_subsamples(act_train_svm, .001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict confidence (distance from separating plane, positive for inliers, negative for outliers)\n",
    "probas_svm = clf_svm.decision_function(act_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "# PR\n",
    "precision_svm, recall_svm, _ = metrics.precision_recall_curve(y_true, -probas_svm)\n",
    "pr_auc_svm = metrics.auc(recall_svm, precision_svm)\n",
    "\n",
    "# ROC\n",
    "fpr_svm, tpr_svm, _ = metrics.roc_curve(y_true, -probas_svm)\n",
    "auroc_svm = metrics.roc_auc_score(y_true, -probas_svm)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_svm, pr_auc_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_svm = np.reshape(probas_svm, np.shape(data_test.gt_patches))\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "acc_im_svm = convert_patches_to_image(data_test.imgs, probas_patches_svm[..., np.newaxis], 64, 64)\n",
    "\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    # original\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_svm_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_svm[img_idx], f_name, dpi=my_dpi)\n",
    "    \n",
    "    # equalized\n",
    "    acc_im_svm_ = exposure.equalize_hist(acc_im_svm[img_idx])\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_svm_im_\" + str(img_idx) + \"_eq.jpg\"\n",
    "    export_figure_matplotlib(acc_im_svm_, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_ind = get_balanced_subset_indices(data_train.gt_patches.flatten(), classes_to_keep, pts_per_class=150)\n",
    "\n",
    "subsample = act_train_all_svm[np.concatenate(subset_ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF\n",
    "K = RBF()\n",
    "K_X = K.__call__(subsample)\n",
    "K_X = exposure.equalize_hist(K_X)\n",
    "f_name = \"../Figures/Zurich/Kernels/Kernel_RBF_wo_cl_\" + str(class_to_remove) + \".jpg\" \n",
    "export_figure_matplotlib(K_X, f_name, dpi=my_dpi)\n",
    "\n",
    "# polynomial\n",
    "for deg in [1, 2, 3]:\n",
    "    K_X = metrics.pairwise.polynomial_kernel(subsample, degree=deg)\n",
    "    # contrast stretching\n",
    "    p2, p98 = np.percentile(K_X, (2, 98))\n",
    "    K_X = exposure.rescale_intensity(K_X, in_range=(p2, p98))\n",
    "\n",
    "    f_name = \"../Figures/Zurich/Kernels/Kernel_poly_wo_cl_\" + str(class_to_remove) + \"_deg_\" + str(deg) + \".jpg\"\n",
    "    export_figure_matplotlib(K_X, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DensityForest instance\n",
    "clf_df = DensityForest(max_depth=2, min_subset=.1, n_trees=100,\n",
    "                       subsample_pct=.1, n_jobs=-1, verbose=10,\n",
    "                       ig_improvement=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to training data\n",
    "clf_df.fit(tsne_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ellipses on plot\n",
    "_, axes = plt.subplots(2, 2, figsize=(15, 15)) \n",
    "for i in range(4):\n",
    "    plot_pts_2d(tsne_all, tsne_y, axes[int(i/2)][np.mod(i, 2)], classes_to_keep, \n",
    "                colors, class_to_remove=class_to_remove)\n",
    "    axes[int(i/2)][np.mod(i, 2)].set_axis_off()\n",
    "    covs, means = get_clusters(clf_df.root_nodes[i], [], [])\n",
    "    plot_ellipses(axes[int(i / 2)][np.mod(i, 2)], means, covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export some ellipses for GIF\n",
    "for i in range(10):\n",
    "    _, ax = plt.subplots(1, 1, figsize=(8, 8)) \n",
    "    plt.xlim([-50, 50])\n",
    "    plt.ylim([-50, 50])\n",
    "    plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, \n",
    "                class_to_remove=class_to_remove, names=names)\n",
    "    covs, means = get_clusters(clf_df.root_nodes[i], [], [])\n",
    "    plot_ellipses(ax, means, covs)\n",
    "    plt.axis('off')\n",
    "    # plt.savefig(\"../Figures/Zurich/GIF/TSNE_act_wo_cl\" + str(class_to_remove) + \"_\"+str(i)+\".pdf\", \n",
    "    #              bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_roc_probas_df(clf_df, x, y=None):\n",
    "    \"\"\"\n",
    "    custom scorer for cross validation returning AUROC\n",
    "    :param clf_df: df classifier\n",
    "    :param x: validation data\n",
    "    :param y: optional gt data\n",
    "    \"\"\"\n",
    "    conf = clf_df.predict(x)\n",
    "    conf[conf == np.infty] = np.max(conf[conf != np.infty])\n",
    "    conf[conf == -np.infty] = np.min(conf[conf != -np.infty])\n",
    "    #conf[np.isnan(conf)] = 0\n",
    "    auroc = metrics.roc_auc_score(y, -conf)\n",
    "    print(auroc)\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search\n",
    "default_params = {'n_trees': 5, 'n_max_dim': 0, 'n_jobs': -1, \n",
    "                  'verbose': 0, 'subsample_pct': .0002, 'min_subset': 0}\n",
    "\n",
    "if paramsearch:\n",
    "    \"\"\"search for best hyperparameters\"\"\"\n",
    "    tuned_params = [{'max_depth': [1, 2, 3],\n",
    "                     'ig_improvement': [0, .4, .7]\n",
    "                    }]\n",
    "\n",
    "    # do parameter search\n",
    "    ps_df = ParameterSearch(DensityForest, tuned_params, act_train, act_val_all,\n",
    "                            pred_f_val.flatten(), scorer_roc_probas_df,\n",
    "                            n_iter=3, verbosity=11, n_jobs=1, subsample_train=1, \n",
    "                            subsample_test=.1, default_params=default_params)\n",
    "\n",
    "    print(\"Testing %i combinations %i times\" % (len(ps_df.combinations), ps_df.n_iter))\n",
    "    print(ps_df.combinations)\n",
    "    ps_df.fit()\n",
    "    print(ps_df.best_params)\n",
    "    \n",
    "    # Create DensityForest instance\n",
    "    best_params_df = ps_df.best_params\n",
    "    \n",
    "else:\n",
    "    \"\"\"use previously found hyperparameters\"\"\"\n",
    "    best_params_df = {'max_depth': df_ps.loc[str(names[class_to_remove])]['df_depth'],\n",
    "                      'ig_improvement': df_ps.loc[str(names[class_to_remove])]['df_min_ig']}\n",
    "    \n",
    "    \n",
    "print(best_params_df)\n",
    "default_params['verbose'] = 1\n",
    "default_params['n_trees'] = 10\n",
    "default_params['batch_size'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit DF with best found parameters\n",
    "clf_df = DensityForest(**best_params_df, **default_params)\n",
    "clf_df.fit(act_train)\n",
    "\n",
    "# get probabilities for all images\n",
    "probas_df = clf_df.predict(act_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "# PR\n",
    "precision_df, recall_df, _ = metrics.precision_recall_curve(y_true, -probas_df)\n",
    "pr_auc_df = metrics.auc(recall_df, precision_df)\n",
    "\n",
    "# ROC\n",
    "fpr_df, tpr_df, _ = metrics.roc_curve(y_true, -probas_df)\n",
    "auroc_df = metrics.roc_auc_score(y_true, -probas_df)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_df, pr_auc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_df -= np.min(probas_df)\n",
    "probas_df /= np.max(probas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_df = np.reshape(probas_df, np.shape(data_test.gt_patches))\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "acc_im_df = convert_patches_to_image(data_test.imgs, probas_patches_df[..., np.newaxis], 64, 64)\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    # original\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_df_im_\" + str(img_idx) + \".jpg\"\n",
    "    export_figure_matplotlib(acc_im_df[img_idx], f_name, dpi=my_dpi)\n",
    "    \n",
    "    # equalized\n",
    "    acc_im_df_= exposure.equalize_hist(acc_im_df[img_idx])\n",
    "    f_name = base_folder + \"/ZH_wo_cl_\" + str(class_to_remove) + \"_df_im_\" + str(img_idx) + \"_eq.jpg\"\n",
    "    export_figure_matplotlib(acc_im_df_, f_name, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "# order according to increasing score\n",
    "scores_pr = [pr_auc_msr, pr_auc_margin, pr_auc_entropy, pr_auc_dropout, pr_auc_gmm, pr_auc_svm, pr_auc_df]\n",
    "\n",
    "recalls = [recall_msr, recall_margin, recall_entropy, recall_dropout, recall_gmm, recall_svm, recall_df]\n",
    "precisions = [precision_msr, precision_margin, precision_entropy, precision_dropout, \n",
    "              precision_gmm, precision_svm, precision_df]\n",
    "\n",
    "names_methods = np.array(['MSR', 'Margin', 'Entropy', 'Dropout', 'GMM', 'OC SVM', 'DF'])\n",
    "scores_order = np.argsort(scores_pr)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_pr)))[:, :3]\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(recalls[i], precisions[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_pr[i]) for i in scores_order], title=\"PR AUC\")\n",
    "plt.savefig(\"../Figures/Zurich/Metrics/PR_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", \n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "# order according to increasing score\n",
    "scores_auc = [auroc_msr, auroc_margin, auroc_entropy, auroc_dropout, auroc_gmm, auroc_svm, auroc_df]\n",
    "fprs = [fpr_msr, fpr_margin, fpr_entropy, fpr_dropout, fpr_gmm, fpr_svm, fpr_df]\n",
    "tprs = [tpr_msr, tpr_margin, tpr_entropy, tpr_dropout, tpr_gmm, tpr_svm, tpr_df]\n",
    "scores_order = np.argsort(scores_auc)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_auc)))[:, :3]\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.plot(fprs[i], tprs[i], c=colors_lines[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', c='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.grid(alpha=.3)\n",
    "fig.axes[0].spines['right'].set_visible(False)\n",
    "fig.axes[0].spines['top'].set_visible(False)\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_auc[i]) for i in scores_order], title=\"AUROC\")\n",
    "plt.savefig(\"../Figures/Zurich/Metrics/ROC_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", \n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write best hyperparameters to CSV file\n",
    "best_params = {'gmm_n_components': best_params_gmm['n_components'], \n",
    "               'oc-svm_k': best_params_svm['kernel'], \n",
    "               'oc-svm_deg': best_params_svm['degree'], \n",
    "               'oc_svm_nu': best_params_svm['nu'], \n",
    "               'df_depth': best_params_df['max_depth'], \n",
    "               'df_min_ig': best_params_df['ig_improvement']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to CSV files\n",
    "# hyperparameters\n",
    "df2 = pd.DataFrame(best_params, index=[str(names[class_to_remove])])\n",
    "df_ps = df_ps.append(df2)\n",
    "df_ps = df_ps[~df_ps.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_ps.to_csv('models_out/hyperparams.csv')\n",
    "\n",
    "# AUROC\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]): scores_auc}, index=names_methods).T\n",
    "df_auroc = df_auroc.append(df2)\n",
    "df_auroc = df_auroc[~df_auroc.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_auroc.to_csv('models_out/auroc_all.csv')\n",
    "\n",
    "\n",
    "# PR AUC\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]): scores_pr}, index=names_methods).T\n",
    "df_aucpr = df_aucpr.append(df2)\n",
    "df_aucpr = df_aucpr[~df_aucpr.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_aucpr.to_csv('models_out/aucpr_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load auroc df with previously saved results\n",
    "df_auroc = pd.read_csv('models_out/auroc_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder by class names\n",
    "df_auroc = df_auroc.reindex(names[1:])\n",
    "df_auroc.to_csv('models_out/auroc_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show latex table of AUROC metrics for all methods\n",
    "print(df_auroc.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best method for each left-out class\n",
    "print(df_auroc.T.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show mean aourc for each method\n",
    "print(df_auroc.mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean aourc for each method\n",
    "print(df_ps.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting objects  with low confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dpi = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_particularity(dataset, img_idx, x, y, width, height, colors, confs_patches=None, names=None, dir_out=None,\n",
    "                         idx=0, dpi=255):\n",
    "    \"\"\"\n",
    "    export detail view of interesting image: image with blue rectangle, cropped region, cropped GT, cropped conf images\n",
    "    \"\"\"\n",
    "    # Image\n",
    "    class_to_remove = dataset.class_to_remove\n",
    "    im = dataset.imgs[img_idx][..., :3]\n",
    "    max_x = np.mod(im.shape[0], 32)\n",
    "    max_y = np.mod(im.shape[1], 32)\n",
    "    im = im[:-max_x, :-max_y]\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor='b', facecolor='b', alpha=.5)\n",
    "    f_name = dir_out + 'im_' + str(img_idx) + '_obj_' + str(idx) + '_im.jpg'\n",
    "    _ = export_figure_matplotlib(im, dpi=dpi, rect=rect, f_name=f_name)\n",
    "    plt.close()\n",
    "\n",
    "    # Cropped Image\n",
    "    im_crop = im[y:(y + height), x:(x + width)]\n",
    "    f_name = dir_out + 'im_' + str(img_idx) + '_obj_' + str(idx) + '_im_crop.jpg'\n",
    "    _ = export_figure_matplotlib(im_crop, dpi=dpi, f_name=f_name)\n",
    "    plt.close()\n",
    "\n",
    "    # GT\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=3, edgecolor='b', facecolor='None')\n",
    "    im_gt = gt_label_to_color(dataset.gt[img_idx], colors) * 255\n",
    "    max_x = np.mod(im_gt.shape[0], 32)\n",
    "    max_y = np.mod(im_gt.shape[1], 32)\n",
    "    im_gt = im_gt[:-max_x, :-max_y]\n",
    "    f_name = dir_out + 'im_' + str(img_idx) + '_obj_' + str(idx) + '_gt.jpg'\n",
    "    _ = export_figure_matplotlib(im_gt, dpi=dpi, rect=rect, f_name=f_name)\n",
    "    plt.close()\n",
    "\n",
    "    if confs_patches is not None:\n",
    "        for idx_conf, conf_patches in enumerate(confs_patches):\n",
    "            conf_imgs = convert_patches_to_image(dataset.imgs, conf_patches[..., np.newaxis], 64, 64)\n",
    "            rect = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor='b', facecolor='None')\n",
    "            f_name = dir_out + 'im_' + str(img_idx) + '_obj_' + str(idx) + '_' + names[idx_conf] + '_wo_cl_' + str(\n",
    "                class_to_remove) + '.jpg'\n",
    "            export_figure_matplotlib(conf_imgs[img_idx], dpi=dpi, rect=rect, f_name=f_name)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_confs_patches = ['msr', 'df']\n",
    "confs_patches = [probas_patches_msr, probas_patches_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = '../Figures/Zurich/Detail/im1/'\n",
    "export_particularity(data_test, 1, 270, 660, 200, 200, colors, dir_out=dir_out, confs_patches=confs_patches,\n",
    "                     names=names_confs_patches, idx=1, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = '../Figures/Zurich/Detail/im4/'\n",
    "export_particularity(data_test, 4, 670, 550, 450, 320, colors, dir_out=dir_out, confs_patches=confs_patches, \n",
    "                     names=names_confs_patches, idx=1, dpi=my_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confidence in t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_f_tsne = data_test.gt_patches == class_to_remove\n",
    "pred_t_tsne = (data_test.gt_patches != class_to_remove) & (data_test.gt_patches != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try without stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_tsne.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_tsne.flatten()[dataset_subset_indices]\n",
    "probas_methods = [probas_msr, probas_margin, probas_entropy, probas_dropout.flatten(), probas_gmm, \n",
    "                  np.squeeze(probas_svm), np.squeeze(probas_df)].copy()\n",
    "\n",
    "base_dir = \"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/\"\n",
    "\n",
    "names_methods_save = ['net_msr', 'net_margin', 'net_entropy', 'dropout', 'gmm', 'svm', 'df']\n",
    "for proba, name in zip(probas_methods, names_methods_save):\n",
    "    probas_tsne = proba[dataset_subset_indices]\n",
    "\n",
    "    # colors\n",
    "    probas_df_c = exposure.equalize_hist(probas_tsne)\n",
    "    probas_df_c -= np.min(probas_df_c)\n",
    "    probas_df_c /= np.max(probas_df_c)\n",
    "    colors_plt = plt.cm.RdYlGn(probas_df_c)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "    # indicators of least confident points    \n",
    "    # plot correctly predicted points (o marker)\n",
    "\n",
    "    ax.scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t], alpha=.1)\n",
    "\n",
    "    # plot incorrectly predicted points (x marker)\n",
    "    ax.scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], edgecolors='black',\n",
    "               linewidths=.5, s=90)\n",
    "    ax.set_axis_off()\n",
    "    extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "\n",
    "    f_name = base_dir + \"t-SNE_wo_cl_\" + str(class_to_remove) + \"_\" + str(name) + \".pdf\"\n",
    "    plt.savefig(f_name, bbox_inches=extent, pad_inches=0)\n",
    "    ax.legend(['Seen points', 'Novel points'])\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
