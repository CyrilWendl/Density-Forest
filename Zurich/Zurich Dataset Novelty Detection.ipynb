{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zurich Land Cover Classification\n",
    "\n",
    "This script presents a visualization of training a U-Net classifier on 7 out of 8 available land cover classes of the Zurich dataset, and detecting the unseen class using a Density Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 478257035317511962\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10905383732\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2407737816176272371\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraries\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import decomposition, svm, preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# custom libraries\n",
    "base_dir = '/Users/cyrilwendl/Documents/EPFL'\n",
    "#base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "sys.path.append(base_dir + '/SIE-Master/Code')  # Path to density Tree package\n",
    "sys.path.append(base_dir + '/SIE-Master')  # Path to density Tree package\n",
    "sys.path.append(base_dir + '/SIE-Master/Code/density_tree')  # Path to density Tree package\n",
    "from helpers.helpers import *\n",
    "from helpers.data_augment import *\n",
    "from helpers.data_loader import ZurichLoader\n",
    "from helpers.cv_scorers import *\n",
    "from helpers.cross_validator import ParameterSearch\n",
    "from baselines.helpers import predict_with_dropout_imgs\n",
    "from density_forest.density_forest import *\n",
    "from density_forest.plots import *\n",
    "from density_forest.helpers import *\n",
    "from keras_helpers.unet import *\n",
    "from keras_helpers.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_remove = 8  # int(sys.argv[1])\n",
    "paramsearch = False  # search for best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading data with overlap\n",
      "classes to keep: ['Roads' 'Buildings' 'Trees' 'Grass' 'Bare Soil' 'Water' 'Railways']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "# data without overlap\n",
    "print(\"loading data\")\n",
    "data_train = ZurichLoader(path, 'train')\n",
    "data_val = ZurichLoader(path, 'val')\n",
    "data_test = ZurichLoader(path, 'test')\n",
    "\n",
    "print(\"loading data with overlap\")\n",
    "# data with overlap, for prediction\n",
    "data_train_overlap = ZurichLoader(path, 'train', stride=32)\n",
    "data_val_overlap = ZurichLoader(path, 'val', stride=32)\n",
    "data_test_overlap = ZurichLoader(path, 'test', stride=32)\n",
    "\n",
    "# save RAM\n",
    "del data_train_overlap.imgs, data_train_overlap.gt\n",
    "del data_val_overlap.imgs, data_val_overlap.gt\n",
    "del data_test_overlap.imgs, data_test_overlap.gt\n",
    "\n",
    "# class names and colors\n",
    "names = data_train.names\n",
    "colors = data_train.colors\n",
    "n_classes = 9\n",
    "classes_to_keep = np.asarray([x for x in range(1, n_classes) if x != class_to_remove])\n",
    "names_keep = np.asarray(names)[classes_to_keep]\n",
    "print(\"classes to keep: \" + str(names_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_labels_tr, cnt_tr = np.unique(data_train.gt_patches, return_counts=True)\n",
    "pred_labels_val, cnt_val = np.unique(data_val.gt_patches, return_counts=True)\n",
    "pred_labels_te, cnt_te = np.unique(data_test.gt_patches, return_counts=True)\n",
    "\n",
    "cnt_tr = cnt_tr / np.sum(cnt_tr) * 100\n",
    "cnt_val = np.concatenate((cnt_val / np.sum(cnt_val) * 100, [0]))\n",
    "cnt_te = cnt_te / np.sum(cnt_te) * 100\n",
    "\n",
    "df = pd.DataFrame({'Train': cnt_tr, 'Val': cnt_val, 'Test': cnt_te}, index=names[pred_labels_tr])\n",
    "\n",
    "df[::-1].plot.barh(figsize=(7, 6), colormap='winter')\n",
    "plt.xlim([0, 100])\n",
    "plt.xlabel(\"Count [%]\")\n",
    "plt.grid(alpha=.3)\n",
    "plt.savefig(\"../Figures/Zurich/Pred_count/ZH_dist.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Data Split: \n",
    "- Training: 12 images\n",
    "- Validation: 4 images\n",
    "- Test: 4 images\n",
    "\n",
    "Tested Architectures: \n",
    "\n",
    "| Model | Patch Size | Data Augmentations | Number of Parameters | Testing Precision (avg) | Testing Recall (avg) | Testing f1 score (avg) | Validation / Test accuracy |\n",
    "| ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| U-Net | 64 | Rot 90°, Flipping  | 7,828,200 | 0.87 | 0.858 | 0.86 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.69 | 0.61 | 0.64 | t |\n",
    "| U-Net | 128 | Rot 90°, Flipping  | 7,828,200 | 0.90 | 0.89 | 0.89 | v |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create copies of original data\\ny_train_label = y_train.copy()\\ny_val_label = y_val.copy()\\ny_test_label = y_test.copy()\\n\\n# get class weights\\nlabels_unique = np.unique(y_train.flatten())\\nprint(labels_unique)\\nclass_weights = class_weight.compute_class_weight(\\'balanced\\', labels_unique, y_train.flatten())\\nclass_weights[0] = 0  # give less weight to background label class\\nclass_weights[5] = 7  # give less weight to bare soil class\\nclass_weights[8] = 7  # give less weight to swimming pool class\\n\\nprint(\"Class weights:\")\\nfor i, w in enumerate(class_weights):\\n    print(\"%15s: %3.3f\" % (names[i], w))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# create copies of original data\n",
    "y_train_label = y_train.copy()\n",
    "y_val_label = y_val.copy()\n",
    "y_test_label = y_test.copy()\n",
    "\n",
    "# get class weights\n",
    "labels_unique = np.unique(y_train.flatten())\n",
    "print(labels_unique)\n",
    "class_weights = class_weight.compute_class_weight('balanced', labels_unique, y_train.flatten())\n",
    "class_weights[0] = 0  # give less weight to background label class\n",
    "class_weights[5] = 7  # give less weight to bare soil class\n",
    "class_weights[8] = 7  # give less weight to swimming pool class\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(class_weights):\n",
    "    print(\"%15s: %3.3f\" % (names[i], w))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# convert to numpy arrays\\nx_train = np.asarray(x_train)\\nx_val = np.asarray(x_val)\\nx_test = np.asarray(x_test)\\n\\n# make y data categorical\\ny_train = to_categorical(y_train_label, n_classes)\\ny_val = to_categorical(y_val_label, n_classes)\\n\\ny_train = y_train[..., classes_to_keep]\\ny_val = y_val[..., classes_to_keep]\\nn_classes = len(classes_to_keep)\\nclass_weights = class_weights[classes_to_keep]\\n\\n# print shapes of variables\\nfor var in x_train, y_train, x_val, y_val:\\n    print(np.shape(var))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# convert to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "x_val = np.asarray(x_val)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "# make y data categorical\n",
    "y_train = to_categorical(y_train_label, n_classes)\n",
    "y_val = to_categorical(y_val_label, n_classes)\n",
    "\n",
    "y_train = y_train[..., classes_to_keep]\n",
    "y_val = y_val[..., classes_to_keep]\n",
    "n_classes = len(classes_to_keep)\n",
    "class_weights = class_weights[classes_to_keep]\n",
    "\n",
    "# print shapes of variables\n",
    "for var in x_train, y_train, x_val, y_val:\n",
    "    print(np.shape(var))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# callbacks (evaluated every epoch)\\n# show loss and accuracy figures after each epoch\\ncallback_plot = PlotLosses()\\n\\n# stop early if after several epochs the accuracy doesn\\'t improve\\ncallback_earlystop = EarlyStopping(monitor=\\'val_loss\\', min_delta=1e-4, patience=24, verbose=1, mode=\\'auto\\')\\n\\n# decrease learning rate when accuracy stops improving\\ncallback_lr = ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.5, patience=12, verbose=1, mode=\\'auto\\',\\n                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\\n\\n# checkpoint to save weights at every epoch (in case of interruption)\\nfile_path = \"weights-improvement.hdf5\"\\ncallback_checkpoint = ModelCheckpoint(file_path, monitor=\\'val_acc\\', verbose=0, save_best_only=True, mode=\\'max\\')\\n\\ncallback_tensorboard = TensorBoard(log_dir=\\'./tensorboard\\', histogram_freq=0, write_graph=True, write_images=True)\\n\\n# model setup\\nbatch_size = 20\\nepochs = 300\\n\\n\\ndef model_train(model, data_augmentation):\\n    # Fit the model on the batches generated by datagen.flow().\\n    model.fit_generator(batch_generator(x_train, y_train,\\n                                        batch_size=batch_size, data_augmentation=data_augmentation),\\n                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\\n                        epochs=epochs,\\n                        verbose=1,\\n                        class_weight=class_weights,  # weights for loss function\\n                        validation_data=(x_val, y_val),\\n                        callbacks=[callback_earlystop,\\n                                   callback_lr,\\n                                   # callback_checkpoint,\\n                                   callback_plot,\\n                                   callback_tensorboard],\\n                        workers=cpu_count(),\\n                        use_multiprocessing=True)\\n                        \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# callbacks (evaluated every epoch)\n",
    "# show loss and accuracy figures after each epoch\n",
    "callback_plot = PlotLosses()\n",
    "\n",
    "# stop early if after several epochs the accuracy doesn't improve\n",
    "callback_earlystop = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=24, verbose=1, mode='auto')\n",
    "\n",
    "# decrease learning rate when accuracy stops improving\n",
    "callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, verbose=1, mode='auto',\n",
    "                                epsilon=1e-4, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "# checkpoint to save weights at every epoch (in case of interruption)\n",
    "file_path = \"weights-improvement.hdf5\"\n",
    "callback_checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# model setup\n",
    "batch_size = 20\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "def model_train(model, data_augmentation):\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(batch_generator(x_train, y_train,\n",
    "                                        batch_size=batch_size, data_augmentation=data_augmentation),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        class_weight=class_weights,  # weights for loss function\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback_earlystop,\n",
    "                                   callback_lr,\n",
    "                                   # callback_checkpoint,\n",
    "                                   callback_plot,\n",
    "                                   callback_tensorboard],\n",
    "                        workers=cpu_count(),\n",
    "                        use_multiprocessing=True)\n",
    "                        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or load model\n",
    "# train the model\n",
    "# model_unet = get_unet(n_classes, x_train.shape[1:])\n",
    "# model_train(model_unet, data_augmentation=True)\n",
    "# model_unet.save('models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '_2.h5')  # save model, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "name_model = path + '/models_out/model_unet_64_flip_rot90_wo_cl_' + str(names[class_to_remove]).lower() + '.h5'    \n",
    "model_unet = load_model(name_model, custom_objects={'fn': ignore_background_class_accuracy(0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14520/14520 [==============================] - 10s 665us/step\n",
      "4688/4688 [==============================] - 3s 658us/step\n",
      "4786/4786 [==============================] - 4s 860us/step\n"
     ]
    }
   ],
   "source": [
    "# get all predictions in training and test set\n",
    "# training set\n",
    "y_pred_tr = model_unet.predict(data_train_overlap.im_patches, verbose=1)\n",
    "y_pred_tr = np.concatenate(remove_overlap(data_train.imgs, y_pred_tr, np.arange(10), 64, 32))\n",
    "y_pred_label_tr = get_y_pred_labels(y_pred_tr, class_to_remove=class_to_remove, background=True)\n",
    "\n",
    "# validation set\n",
    "y_pred_val = model_unet.predict(data_val_overlap.im_patches, verbose=1)\n",
    "y_pred_val = np.concatenate(remove_overlap(data_val.imgs, y_pred_val, np.arange(5), 64, 32))\n",
    "y_pred_label_val = get_y_pred_labels(y_pred_val, class_to_remove=class_to_remove, background=True)\n",
    "\n",
    "# test set\n",
    "y_pred_te = model_unet.predict(data_test_overlap.im_patches, batch_size=20, verbose=1)\n",
    "y_pred_te = np.concatenate(remove_overlap(data_test.imgs, y_pred_te, np.arange(5), 64, 32))\n",
    "y_pred_label_te = get_y_pred_labels(y_pred_te, class_to_remove=class_to_remove, background=True)\n",
    "\n",
    "# get indices of correctly / incorrectly predicted pixels\n",
    "# train\n",
    "pred_t_tr = (data_train.gt_patches != class_to_remove) & (data_train.gt_patches != 0)\n",
    "pred_f_tr = data_train.gt_patches == class_to_remove\n",
    "\n",
    "# val\n",
    "pred_t_val = (data_val.gt_patches != class_to_remove) & (data_val.gt_patches != 0)\n",
    "pred_f_val = data_val.gt_patches == class_to_remove\n",
    "\n",
    "# test\n",
    "pred_t_te = (data_test.gt_patches != class_to_remove) & (data_test.gt_patches != 0)\n",
    "pred_f_te = data_test.gt_patches == class_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oa(y_true, y_pred):\n",
    "        \"\"\"get overall accuracy\"\"\"\n",
    "        return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def aa(y_true, y_pred):\n",
    "    \"\"\"get average (macro) accuracy\"\"\"\n",
    "    acc_cl = []\n",
    "    for label in np.unique(y_pred):\n",
    "        acc_cl.append(np.sum(y_true[y_pred == label] == y_pred[y_pred == label]) / len(y_pred[y_pred == label]))\n",
    "    return np.nanmean(acc_cl), acc_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59.56 57.72]\n",
      "[80.55 70.5 ]\n",
      "[82.34 71.34]\n"
     ]
    }
   ],
   "source": [
    "# Get oa, aa for train, val, test\n",
    "# train\n",
    "y_pred_tr_flattened = np.asarray(y_pred_label_tr.flatten()).astype('int')\n",
    "y_tr_flattened = np.asarray(data_train.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_tr_flattened != 0) & (y_tr_flattened != class_to_remove)\n",
    "oa_tr = oa(y_tr_flattened[filter_items], y_pred_tr_flattened[filter_items])\n",
    "aa_tr, aa_tr_cl = aa(y_tr_flattened[filter_items], y_pred_tr_flattened[filter_items])\n",
    "\n",
    "# val\n",
    "y_pred_val_flattened = np.asarray(y_pred_label_val.flatten()).astype('int')\n",
    "y_val_flattened = np.asarray(data_val.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_val_flattened != 0) & (y_val_flattened != class_to_remove)\n",
    "oa_val = oa(y_val_flattened[filter_items], y_pred_val_flattened[filter_items])\n",
    "aa_val, aa_val_cl = aa(y_val_flattened[filter_items], y_pred_val_flattened[filter_items])\n",
    "\n",
    "# test\n",
    "y_pred_te_flattened = np.asarray(y_pred_label_te.flatten()).astype('int')\n",
    "y_te_flattened = np.asarray(data_test.gt_patches.flatten()).astype('int')\n",
    "filter_items = (y_te_flattened != 0) & (y_te_flattened != class_to_remove)\n",
    "oa_te = oa(y_te_flattened[filter_items], y_pred_te_flattened[filter_items])\n",
    "aa_te, aa_te_cl = aa(y_te_flattened[filter_items], y_pred_te_flattened[filter_items])\n",
    "\n",
    "print(np.round(np.multiply([oa_tr, aa_tr], 100), 2))\n",
    "print(np.round(np.multiply([oa_val, aa_val], 100), 2))\n",
    "print(np.round(np.multiply([oa_te, aa_te], 100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metrics to CSV files\n",
    "df_metrics = pd.read_csv('models_out/metrics_ND.csv', index_col=0)\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]):[oa_tr, aa_tr, oa_val, aa_val, oa_te, aa_te]},\n",
    "                    index = ['OA Train', 'AA Train', 'OA Val', 'AA Val', 'OA Test', 'AA Test']).T\n",
    "df_metrics = df_metrics.append(df2)\n",
    "df_metrics = df_metrics[~df_metrics.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_metrics.to_csv('models_out/metrics_ND.csv')\n",
    "# print((df_metrics*100).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Roads      0.784     0.860     0.820    726236\n",
      "  Buildings      0.773     0.805     0.789    698275\n",
      "      Trees      0.926     0.743     0.824    603174\n",
      "      Grass      0.842     0.901     0.871    616207\n",
      "  Bare Soil      0.691     0.733     0.711     67038\n",
      "      Water      0.977     0.859     0.914    234163\n",
      "   Railways      0.001     0.001     0.001     18526\n",
      "\n",
      "avg / total      0.831     0.823     0.824   2963619\n",
      "\n",
      "Overall accuracy: 82.341 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics\n",
    "y_pred_flattened = np.asarray(y_pred_label_te.flatten()).astype('int')\n",
    "y_test_flattened = np.asarray(data_test.gt_patches.flatten()).astype('int')\n",
    "\n",
    "# mask background and removed classes for evaluation metrics\n",
    "filter_items = (y_test_flattened != 0) & (y_test_flattened != class_to_remove)\n",
    "\n",
    "# Class accuracy, average accuracy\n",
    "print(metrics.classification_report(\n",
    "    y_test_flattened[filter_items],\n",
    "    y_pred_flattened[filter_items],\n",
    "    target_names=names_keep,\n",
    "    digits=3))\n",
    "\n",
    "\n",
    "# Overall accuracy\n",
    "print(\"Overall accuracy: %.3f %%\" % (oa_te * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of predictions in unseen class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of predicted label\n",
    "pred_labels, pred_counts = np.unique(y_pred_label_te[pred_f_te], return_counts=True)\n",
    "pred_counts = pred_counts  / sum(pred_counts) * 100\n",
    "\n",
    "# visualization\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(pred_labels, pred_counts)\n",
    "plt.xticks(np.arange(0, 10))\n",
    "plt.ylim([0,100])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Count [%]\")\n",
    "plt.grid(alpha=.3)\n",
    "plt.title(\"Misclassified labels (mean MSR=%.2f)\" % np.mean(get_acc_net_msr(y_pred_te[pred_f_te])))\n",
    "plt.xticks(pred_labels_te, names, rotation=20)\n",
    "plt.savefig(\"../Figures/Zurich/Pred_count/ZH_pred-count_wo_cl\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curves\n",
    "\n",
    "# msr\n",
    "y_scores = (-get_acc_net_msr(y_pred_te)).flatten()\n",
    "y_true = pred_f_te.flatten()\n",
    "precision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_msr = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_msr = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# margin\n",
    "y_scores = (-get_acc_net_max_margin(y_pred_te)).flatten()\n",
    "precision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_margin = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_margin = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, y_scores)\n",
    "\n",
    "# entropy\n",
    "y_scores = (-get_acc_net_entropy(y_pred_te)).flatten()\n",
    "precision_entropy, recall_entropy, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_entropy = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_entropy = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "# MSR\n",
    "probas_patches_msr = np.reshape((get_acc_net_msr(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_msr -= np.min(probas_patches_msr)\n",
    "probas_patches_msr /= np.max(probas_patches_msr)\n",
    "\n",
    "# margin\n",
    "probas_patches_margin = np.reshape((get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_margin -= np.min(probas_patches_margin)\n",
    "probas_patches_margin /= np.max(probas_patches_margin)\n",
    "\n",
    "# entropy\n",
    "probas_patches_entropy = np.reshape((get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\n",
    "probas_patches_entropy -= np.min(probas_patches_entropy)\n",
    "probas_patches_entropy /= np.max(probas_patches_entropy)\n",
    "\n",
    "# show images\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    acc_im_msr = convert_patches_to_image(data_test.imgs, probas_patches_msr[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_msr = imgs_stretch_eq([acc_im_msr])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_msr[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/net_msr_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    acc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis],\n",
    "                                             img_idx, 64, 64, 0)\n",
    "    acc_im_margin = imgs_stretch_eq([acc_im_margin])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_margin[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/net_margin_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    acc_im_entropy = convert_patches_to_image(data_test.imgs, probas_patches_entropy[..., np.newaxis],\n",
    "                                              img_idx, 64, 64, 0)\n",
    "    acc_im_entropy = imgs_stretch_eq([acc_im_entropy])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_entropy[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/net_entropy_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:03<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "y_preds = predict_with_dropout_imgs(model_unet, data_test_overlap.im_patches,\n",
    "                                    data_test.imgs, np.arange(len(data_test.imgs)), batch_size=500,\n",
    "                                    n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction and confidence\n",
    "prediction = np.mean(y_preds, 0)\n",
    "probas_dropout = -get_acc_net_entropy(prediction)\n",
    "del y_preds # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.28, PR AUC: 0.00\n"
     ]
    }
   ],
   "source": [
    "# dropout metrics\n",
    "y_scores = probas_dropout.flatten()\n",
    "precision_dropout, recall_dropout, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_dropout = metrics.average_precision_score(y_true, y_scores)\n",
    "auroc_dropout = metrics.roc_auc_score(y_true, y_scores)\n",
    "fpr_dropout, tpr_dropout, _ = metrics.roc_curve(y_true, y_scores)\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_dropout, pr_auc_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_dropout = np.reshape(probas_dropout, np.shape(data_test.gt_patches))\n",
    "probas_patches_dropout -= np.min(probas_patches_dropout)\n",
    "probas_patches_dropout /= np.max(probas_patches_dropout)\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    acc_im_dropout = convert_patches_to_image(data_test.imgs, probas_patches_dropout[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_dropout = imgs_stretch_eq([acc_im_dropout])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_dropout[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/dropout_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Activations, PCA, t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 726/726 [00:13<00:00, 52.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations for training Density Forest\n",
    "act_train_all = get_activations_batch(model_unet, -2, data_train_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_train_all = np.concatenate(remove_overlap(data_train.imgs, act_train_all, np.arange(len(data_train.imgs)), patch_size=64, stride=32))\n",
    "act_train = act_train_all[pred_t_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 79.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations\n",
    "act_val_all = get_activations_batch(model_unet, -2, data_val_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# retain only activation weights for which there is a ground truth\n",
    "act_val_all = np.concatenate(remove_overlap(data_val.imgs, act_val_all, np.arange(len(data_val.imgs)),\n",
    "                                            patch_size=64, stride=32))\n",
    "act_val = act_val_all[pred_t_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:02<00:00, 81.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# get activations for testing Density Forest\n",
    "act_test = get_activations_batch(model_unet, -2, data_test_overlap.im_patches, 20, verbose=True)\n",
    "\n",
    "# remove test activations overlap\n",
    "act_test = remove_overlap(data_test.imgs, act_test, np.arange(len(data_test.imgs)), patch_size=64, stride=32)\n",
    "act_test = np.concatenate(np.concatenate(np.concatenate(act_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get balanced data subset to show in figure\n",
    "tsne_pts_per_class = 200\n",
    "dataset_subset_indices = get_balanced_subset_indices(data_test.gt_patches.flatten(), \n",
    "                                                     np.arange(1, 9), pts_per_class=tsne_pts_per_class)\n",
    "dataset_subset_indices = np.concatenate(dataset_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 1600 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1600 samples in 0.196s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1600\n",
      "[t-SNE] Computed conditional probabilities for sample 1600 / 1600\n",
      "[t-SNE] Mean sigma: 1.527670\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 57.223873\n"
     ]
    }
   ],
   "source": [
    "# t-SNE visualization\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=500)\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])\n",
    "tsne_y = data_test.gt_patches.flatten()[dataset_subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.set_axis_off()\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, class_to_remove=class_to_remove)\n",
    "plt.savefig(\"../Figures/Zurich/tSNE/t-SNE_\" + str(names[class_to_remove]).lower() + \"_before_PCA.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create density tree for activation weights of training data\n",
    "# PCA\n",
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(act_test)  # fit on training set without background pixels\n",
    "n_components = np.alen(pca.explained_variance_ratio_)\n",
    "print(\"Variance explained by first %i components: %.2f\" % (\n",
    "    n_components, sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "# transform training activations\n",
    "act_train_all = pca.transform(np.concatenate(np.concatenate(act_train_all)))\n",
    "act_train = pca.transform(act_train)\n",
    "\n",
    "act_val_all = pca.transform(np.concatenate(np.concatenate(act_val_all)))\n",
    "act_val = pca.transform(act_val)\n",
    "\n",
    "\n",
    "# transform test set activations\n",
    "act_test = pca.transform(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance\n",
    "plt.scatter(np.arange(n_components), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative sum of explained variance\")\n",
    "plt.grid()\n",
    "plt.savefig(\"../Figures/Zurich/PCA/pca_components_wo_cl_\" + str(class_to_remove) + \".pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization after PCA\n",
    "tsne_all = tsne.fit_transform(act_test[dataset_subset_indices])\n",
    "# tsne without unseen class\n",
    "tsne_train = tsne_all[tsne_y != class_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, class_to_remove=class_to_remove)\n",
    "ax.set_axis_off()\n",
    "plt.savefig(\"../Figures/Zurich/tSNE/t-SNE_\" + str(names[class_to_remove]).lower() + \"_after_PCA.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 3 PCA components\n",
    "plot_pts_3d(act_test[:, :3], data_test.gt_patches.flatten(), classes_to_keep, colors,\n",
    "            class_to_remove=class_to_remove, subsample_pct=.0003,\n",
    "            s_name='../Figures/Zurich/PCA/pca_components_3d_' + str(names[class_to_remove]) + '.pdf')\n",
    "\n",
    "print(\"Variance explained by first 3 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 2 PCA components\n",
    "_, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plot_pts_2d(act_test[:, :2], data_test.gt_patches.flatten(), ax, classes_to_keep, colors,\n",
    "            class_to_remove=class_to_remove, subsample_pct=.0005,\n",
    "            s_name='../Figures/Zurich/PCA/pca_components_2d_' + str(names[class_to_remove]) + '.pdf')\n",
    "print(\"Variance explained by first 2 components: %.2f\" % np.sum(pca.explained_variance_ratio_[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_degrees = [6, 7, 6, 9, 5, 3, 4, 9]\n",
    "\n",
    "if paramsearch:\n",
    "    tuned_parameters = [{'n_components': np.arange(3, 12), 'max_iter': [10000]}]\n",
    "    # do parameter search\n",
    "    ps_gmm = ParameterSearch(GaussianMixture, tuned_parameters, act_train, act_train_all,\n",
    "                             pred_f_tr.flatten(), scorer_roc_probas_gmm, \n",
    "                             n_iter=3, verbosity=10, n_jobs=-1, subsample_train=.01, subsample_test=.001)\n",
    "    ps_gmm.fit()\n",
    "    best_params = ps_gmm.best_params\n",
    "else:\n",
    "    best_params = {'n_components': best_degrees[class_to_remove-1], 'max_iter': 10000}\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GMM\n",
    "gmm = GaussianMixture(**best_params)\n",
    "gmm.fit(draw_subsamples(act_train, .01))\n",
    "\n",
    "# Predict\n",
    "probas_gmm = gmm.predict_proba(act_test)\n",
    "probas_gmm = get_acc_net_entropy(probas_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# dataset_subset_indicesices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_gmm_c = imgs_stretch_eq([probas_gmm[..., np.newaxis]])[0, ..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_gmm_c)[:, :3][dataset_subset_indices]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] <\n",
    "                            np.sort(probas_gmm_c[dataset_subset_indices])[200])*255)[:, :3]\n",
    "c_thresh_f = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] > \n",
    "                            np.sort(probas_gmm_c[dataset_subset_indices])[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t], alpha=.6)\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "y_scores = -probas_gmm\n",
    "precision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\n",
    "fpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_gmm = metrics.roc_auc_score(y_true, y_scores)\n",
    "plt.step(recall_gmm, precision_gmm)\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_gmm, pr_auc_gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_gmm = np.reshape(probas_gmm, np.shape(data_test.gt_patches))\n",
    "probas_patches_gmm -= np.min(probas_patches_gmm)\n",
    "probas_patches_gmm /= np.max(probas_patches_gmm)\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    acc_im_gmm = convert_patches_to_image(data_test.imgs, probas_patches_gmm[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_gmm = imgs_stretch_eq([acc_im_gmm])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_gmm[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/GMM_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train_svm = preprocessing.scale(act_train)\n",
    "act_val_all_svm = preprocessing.scale(act_val_all)\n",
    "act_test_svm = preprocessing.scale(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [{'kernel':'poly', 'degree':5, 'nu':1e-4, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':1, 'nu':1e-3, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':1, 'nu':1e-1, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':3, 'nu':1e-1, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':3, 'nu':1e-4, 'max_iter':10000},\n",
    "               {'kernel':'rbf',  'degree':1, 'nu':1e-3, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':3, 'nu':1e-1, 'max_iter':10000},\n",
    "               {'kernel':'poly', 'degree':9, 'nu':1e-1, 'max_iter':10000},\n",
    "              ]\n",
    "\n",
    "if paramsearch:\n",
    "    tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1]\n",
    "                     },\n",
    "                    {'kernel': ['poly'],\n",
    "                     'degree': np.arange(1, 7),\n",
    "                     'nu': [1e-4, 1e-3, 1e-2, 1e-1, 5e-1],\n",
    "                     'max_iter': [10000]}]\n",
    "\n",
    "    # do parameter search\n",
    "    ps_svm = ParameterSearch(svm.OneClassSVM, tuned_parameters, act_train_svm, act_train_all,\n",
    "                             pred_f_tr.flatten(), scorer_roc_probas_svm, n_iter=5,\n",
    "                             verbosity=11, n_jobs=-1, subsample_train=.0001, subsample_test=.001)\n",
    "    ps_svm.fit()\n",
    "    best_params = ps_svm.best_params\n",
    "else:\n",
    "    best_params = best_params[class_to_remove-1]\n",
    "    \n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "clf_svm = svm.OneClassSVM(**best_params)\n",
    "clf_svm.fit(draw_subsamples(act_train_svm, .001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "probas_svm = clf_svm.decision_function(act_test_svm[dataset_subset_indices])\n",
    "probas_svm -= np.min(probas_svm)\n",
    "probas_svm /= np.max(probas_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_svm_c = probas_svm[..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_svm_c)[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_svm_c < np.sort(probas_svm_c)[200])*255)[:, :3]\n",
    "\n",
    "c_thresh_f = plt.cm.GnBu((probas_svm_c > np.sort(probas_svm_c)[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_svm = clf_svm.decision_function(act_test_svm)\n",
    "probas_svm -= np.min(probas_svm)\n",
    "probas_svm /= np.max(probas_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "y_scores = -probas_svm\n",
    "# PR\n",
    "precision_svm, recall_svm, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_svm = metrics.auc(recall_svm, precision_svm)\n",
    "\n",
    "# ROC\n",
    "fpr_svm, tpr_svm, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_svm = metrics.roc_auc_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auroc_svm, pr_auc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_svm = np.reshape(probas_svm, np.shape(data_test.gt_patches))\n",
    "probas_patches_svm -= np.min(probas_patches_svm)\n",
    "probas_patches_svm /= np.max(probas_patches_svm)\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    acc_im_svm = convert_patches_to_image(data_test.imgs, probas_patches_svm[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_svm = imgs_stretch_eq([acc_im_svm])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_svm[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/svm_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_train = data_train.gt_patches[(data_train.gt_patches != class_to_remove) & (data_train.gt_patches != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_ind = get_balanced_subset_indices(gts_train, classes_to_keep, pts_per_class=50)\n",
    "subsample = act_train_svm[np.concatenate(subset_ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF\n",
    "K = RBF()\n",
    "K_X = K.__call__(subsample)\n",
    "K_X = exposure.equalize_hist(K_X)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(K_X)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"../Figures/Zurich/Kernels/Kernel_RBF_wo_cl_\" + str(class_to_remove) + \".pdf\", \n",
    "            bbox_inches='tight', pad_inches=0)\n",
    "plt.title('RBF')\n",
    "\n",
    "# polynomial\n",
    "for deg in [1, 5, 10, best_params['degree']]:\n",
    "    K_X = polynomial_kernel(subsample, degree=deg)\n",
    "    # contrast stretching\n",
    "    p2, p98 = np.percentile(K_X, (2, 98))\n",
    "    K_X = exposure.rescale_intensity(K_X, in_range=(p2, p98))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(K_X)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"../Figures/Zurich/Kernels/Kernel_poly_wo_cl_\" + str(class_to_remove) + \"_deg_\" + str(deg) + \".pdf\", \n",
    "                        bbox_inches='tight', pad_inches=0)\n",
    "    plt.title('Poly')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DensityForest instance\n",
    "clf_df = DensityForest(max_depth=2, min_subset=.1, n_trees=100,\n",
    "                       subsample_pct=.1, n_jobs=-1, verbose=10,\n",
    "                       ig_improvement=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to training data\n",
    "clf_df.fit(tsne_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ellipses on plot\n",
    "_, axes = plt.subplots(2, 2, figsize=(15, 15)) \n",
    "for i in range(4):\n",
    "    plot_pts_2d(tsne_all, tsne_y, axes[int(i/2)][np.mod(i, 2)], classes_to_keep, \n",
    "                colors, class_to_remove=class_to_remove)\n",
    "    axes[int(i/2)][np.mod(i, 2)].set_axis_off()\n",
    "    covs, means = get_clusters(clf_df.root_nodes[i], [], [])\n",
    "    plot_ellipses(axes[int(i / 2)][np.mod(i, 2)], means, covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export some ellipses for GIF\n",
    "\n",
    "for i in range(10):\n",
    "    _, ax = plt.subplots(1, 1, figsize=(8, 8)) \n",
    "    plt.xlim([-50, 50])\n",
    "    plt.ylim([-50, 50])\n",
    "    plot_pts_2d(tsne_all, tsne_y, ax, classes_to_keep, colors, \n",
    "                class_to_remove=class_to_remove, names=names)\n",
    "    covs, means = get_clusters(clf_df.root_nodes[i], [], [])\n",
    "    plot_ellipses(ax, means, covs)\n",
    "    plt.axis('off')\n",
    "    #plt.savefig(\"../Figures/Zurich/GIF/TSNE_act_wo_cl\" + str(class_to_remove) + \"_\"+str(i)+\".pdf\", \n",
    "    #            bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "# get probabilities for all images\n",
    "probas_df = np.log(clf_df.predict(tsne_all))\n",
    "\n",
    "# indices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_df_c = imgs_stretch_eq(probas_df[np.newaxis, ..., np.newaxis])[0, ..., 0]\n",
    "colors_plt = plt.cm.YlOrRd(1 - probas_df_c)[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.GnBu((probas_df < np.sort(probas_df)[tsne_pts_per_class])*255)[:, :3]\n",
    "\n",
    "c_thresh_f = plt.cm.GnBu((probas_df > np.sort(probas_df)[tsne_pts_per_class])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "[axes[i].legend(['Seen points', 'Novel points']) for i in range(2)]\n",
    "[axes[i].set_axis_off() for i in range(2)]\n",
    "extent = axes[0].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.savefig(\"../Figures/Zurich/GIF/probas.pdf\", bbox_inches=extent, pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [{'max_depth': 3, 'ig_improvement': 0},\n",
    "               {'max_depth': 2, 'ig_improvement': .5},\n",
    "               {'max_depth': 4, 'ig_improvement': .5},\n",
    "               {'max_depth': 2, 'ig_improvement': .3},\n",
    "               {'max_depth': 2, 'ig_improvement': .3},\n",
    "               {'max_depth': 2, 'ig_improvement': 0},\n",
    "               {'max_depth': 2, 'ig_improvement': .3},\n",
    "               {'max_depth': 4, 'ig_improvement': 0}\n",
    "              ]\n",
    "\n",
    "\n",
    "default_params = {'n_trees': 10, 'n_max_dim': 0, 'n_jobs': -1, \n",
    "                  'verbose': 0, 'subsample_pct': .0002, 'min_subset': 1e-3}\n",
    "\n",
    "if paramsearch:\n",
    "    \"\"\"search for best hyperparameters\"\"\"\n",
    "    tuned_params = [{'max_depth': [1, 2, 3],\n",
    "                     'ig_improvement': [-np.infty, 0, .4, .7]\n",
    "                    }]\n",
    "\n",
    "    # do parameter search\n",
    "    ps_df = ParameterSearch(DensityForest, tuned_params, act_train, act_train_all,\n",
    "                            pred_f_tr.flatten(), scorer_roc_probas_df,\n",
    "                            n_iter=3, verbosity=11, n_jobs=1, subsample_train=1, \n",
    "                            subsample_test=.001, default_params=default_params)\n",
    "\n",
    "    print(\"Testing %i combinations %i times\" % (len(ps_df.combinations), ps_df.n_iter))\n",
    "    print(ps_df.combinations)\n",
    "    ps_df.fit()\n",
    "    print(ps_df.best_params)\n",
    "    \n",
    "    # Create DensityForest instance\n",
    "    best_params = ps_df.best_params\n",
    "    \n",
    "else:\n",
    "    \"\"\"use previously found hyperparameters\"\"\"\n",
    "    best_params = best_params[class_to_remove-1]\n",
    "    \n",
    "    \n",
    "print(best_params)\n",
    "default_params['verbose'] = 1\n",
    "default_params['batch_size'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit DF with best found parameters\n",
    "clf_df = DensityForest(**best_params, **default_params)\n",
    "clf_df.fit(act_train)\n",
    "\n",
    "# get probabilities for all images\n",
    "probas_df = clf_df.predict(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# indices of correctly / wrongly predicted points\n",
    "pred_f = pred_f_te.flatten()[dataset_subset_indices]\n",
    "pred_t = pred_t_te.flatten()[dataset_subset_indices]\n",
    "\n",
    "# plot colors\n",
    "probas_df_c = probas_df[dataset_subset_indices]\n",
    "colors_plt = plt.cm.YlOrRd(1-np.log(probas_df_c))[..., :3]\n",
    "\n",
    "# threshold for second plot\n",
    "c_thresh_t = plt.cm.YlOrRd((probas_df_c < np.sort(probas_df_c)[200])*255)[:, :3]\n",
    "c_thresh_f = plt.cm.YlOrRd((probas_df_c > np.sort(probas_df_c)[200])*255)[:, :3]\n",
    "\n",
    "# plot correctly predicted points (o marker)\n",
    "_, axes = plt.subplots(1, 2, figsize=(20, 10)) \n",
    "axes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=colors_plt[pred_t])\n",
    "axes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\n",
    "\n",
    "# plot incorrectly predicted points (x marker)\n",
    "axes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=colors_plt[pred_f], marker='x')\n",
    "axes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n",
    "# axes[0].savefig(\"../Figures/Zurich/GIF/probas.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape probas to (n_patches, patch_size, patch_size)\n",
    "probas_patches_df = np.reshape(probas_df, np.shape(data_test.gt_patches))\n",
    "\n",
    "# transformations\n",
    "probas_patches_df -= np.nanmin(probas_patches_df)\n",
    "probas_patches_df /= np.nanmax(probas_patches_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "y_scores = -probas_df\n",
    "\n",
    "# PR\n",
    "precision_df, recall_df, _ = metrics.precision_recall_curve(y_true, y_scores)\n",
    "pr_auc_df = metrics.auc(recall_df, precision_df)\n",
    "\n",
    "# ROC\n",
    "fpr_df, tpr_df, _ = metrics.roc_curve(y_true, y_scores)\n",
    "auroc_df = metrics.roc_auc_score(y_true, y_scores)\n",
    "\n",
    "print(\"AUROC: %.2f, PR AUC: %.2f\" % (auroc_df, pr_auc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "probas_patches_df = np.reshape(probas_df, np.shape(data_test.gt_patches))\n",
    "probas_patches_df -= np.min(probas_patches_df)\n",
    "probas_patches_df /= np.max(probas_patches_df)\n",
    "\n",
    "# show image of DF uncertainty vs. max margin uncertainty\n",
    "for img_idx in range(len(data_test.imgs)):\n",
    "    acc_im_df = convert_patches_to_image(data_test.imgs, probas_patches_df[..., np.newaxis], img_idx, 64, 64, 0)\n",
    "    acc_im_df = imgs_stretch_eq([acc_im_df])[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_im_df[..., 0], cmap='RdYlGn')\n",
    "    plt.savefig(\"../Figures/Zurich/Im_cert/cl_\" + str(class_to_remove) + \"/df_im_\" + str(img_idx) + \".pdf\", \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "# order according to increasing score\n",
    "scores_pr = [pr_auc_msr, pr_auc_margin, pr_auc_entropy, pr_auc_dropout, pr_auc_gmm, pr_auc_svm, pr_auc_df]\n",
    "\n",
    "recalls = [recall_msr, recall_margin, recall_entropy, recall_dropout, recall_gmm, recall_svm, recall_df]\n",
    "precisions = [precision_msr, precision_margin, precision_entropy, precision_dropout, \n",
    "              precision_gmm, precision_svm, precision_df]\n",
    "\n",
    "names_methods = np.array(['MSR', 'Margin', 'Entropy', 'Dropout', 'GMM', 'OC SVM', 'DF'])\n",
    "scores_order = np.argsort(scores_pr)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_pr)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(recalls[i], precisions[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_pr[i]) for i in scores_order], title=\"PR AUC\")\n",
    "plt.savefig(\"../Figures/Zurich/Metrics/PR_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "# order according to increasing score\n",
    "scores_auc = [auroc_msr, auroc_margin, auroc_entropy, auroc_dropout, auroc_gmm, auroc_svm, auroc_df]\n",
    "fprs = [fpr_msr, fpr_margin, fpr_entropy, fpr_dropout, fpr_gmm, fpr_svm, fpr_df]\n",
    "tprs = [tpr_msr, tpr_margin, tpr_entropy, tpr_dropout, tpr_gmm, tpr_svm, tpr_df]\n",
    "scores_order = np.argsort(scores_auc)\n",
    "colors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_auc)))[:, :3]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in scores_order:\n",
    "    plt.step(fprs[i], tprs[i], where='post', c=colors_lines[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', c='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend([str.format('%s: %.2f') % (names_methods[i], scores_auc[i]) for i in scores_order], title=\"AUROC\")\n",
    "plt.savefig(\"../Figures/Zurich/Metrics/ROC_pred_wo_cl_\" + str(class_to_remove) + \".pdf\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to CSV files\n",
    "\n",
    "# AUROC\n",
    "df_auroc = pd.read_csv('models_out/auroc_all.csv', index_col=0)\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]): scores_auc}, index = names_methods).T\n",
    "df_auroc = df_auroc.append(df2)\n",
    "df_auroc = df_auroc[~df_auroc.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_auroc.to_csv('models_out/auroc_all.csv')\n",
    "\n",
    "\n",
    "# PR AUC\n",
    "df_aucpr = pd.read_csv('models_out/aucpr_all.csv', index_col=0)\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]): scores_pr}, index = names_methods).T\n",
    "df_aucpr = df_aucpr.append(df2)\n",
    "df_aucpr = df_aucpr[~df_aucpr.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_aucpr.to_csv('models_out/aucpr_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_auroc.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
