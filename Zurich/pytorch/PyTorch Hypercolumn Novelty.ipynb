{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Hypercolumn CNN  for Zurich Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# custom libraries\n",
    "base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "sys.path.append(base_dir + '/SIE-Master/Code')  # Path to density Tree package\n",
    "from helpers.data_loader import ZurichLoader\n",
    "from helpers.helpers import *\n",
    "from hypercolumn import HyperColumn\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/raid/home/cwendl'  # for guanabana\n",
    "root_dir = base_dir + '/SIE-Master/Zurich'\n",
    "patch_size = 64\n",
    "class_to_remove = 4\n",
    "\n",
    "# load data\n",
    "dataset_train = ZurichLoader(root_dir, 'train', patch_size=patch_size, stride=patch_size, transform='augment', \n",
    "                             random_crop=True, class_to_remove=class_to_remove)\n",
    "\n",
    "dataset_val = ZurichLoader(root_dir, 'val', patch_size=patch_size, stride=patch_size, \n",
    "                           class_to_remove=class_to_remove)\n",
    "\n",
    "dataset_test = ZurichLoader(root_dir, 'test', patch_size=patch_size, stride=patch_size, \n",
    "                            class_to_remove=class_to_remove)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=100, shuffle=True, num_workers=20)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=100, shuffle=False, num_workers=20)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=100, shuffle=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_with_filt(y_true, y_pred, label_to_ignore):\n",
    "    \"\"\"\n",
    "    get accuracy ignoring a label in y_true\n",
    "    :param y_true: ground truth (tensor)\n",
    "    :param y_pred: predicted label (tensor)\n",
    "    :param label_to_ignore: label to ignore\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    y_true = y_true.numpy().flatten()\n",
    "    y_pred = y_pred.numpy().flatten()\n",
    "    filt = y_true != label_to_ignore\n",
    "    return np.sum(np.equal(y_pred[filt], y_true[filt]))/len(y_true[filt])\n",
    "\n",
    "\n",
    "def test(model, f_loss, dataloader, name, verbosity=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        acc = []  # average accuracy\n",
    "        for i_batch, (im, gt) in enumerate(dataloader):\n",
    "            im = im.cuda()\n",
    "            gt = gt.cuda()\n",
    "            output = model(im)\n",
    "            loss += f_loss(output, gt).cpu()\n",
    "            _, pred = output.cpu().max(1, keepdim=True)\n",
    "            acc.append(acc_with_filt(gt.cpu(), pred.cpu(), 0))\n",
    "\n",
    "        loss /= len(dataloader.dataset)\n",
    "        acc = np.mean(acc)\n",
    "        if verbosity>0:\n",
    "            print(name + ' set: Average loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(loss, acc * 100))\n",
    "        return acc, loss\n",
    "\n",
    "def predict(model, dataloader_pred):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_pred = torch.LongTensor()\n",
    "        for i_batch, (im, gt) in enumerate(dataloader_pred):\n",
    "            im = im.cuda()\n",
    "            gt = gt.cuda()\n",
    "            output = model(im)\n",
    "            _, pred = output.cpu().max(1, keepdim=False)\n",
    "            test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "    return test_pred.numpy()\n",
    "\n",
    "\n",
    "def train(model, dataloader_train, dataloader_val, epochs, verbosity=0, plot=False):\n",
    "    \"\"\"\n",
    "    Train a model for a given number of epochs\n",
    "    :param model: Model to train\n",
    "    :param dataloader_train: dataloader for training data\n",
    "    :param dataloader_val: dataloader for test data\n",
    "    :param epochs: number of epochs to train\n",
    "    :param verbosity: verbosity level of status messages\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "    #weights = torch.from_numpy(dataloader_train.dataset.weights).float().cuda()\n",
    "    f_loss = nn.CrossEntropyLoss(ignore_index=0)  # weight=weights,\n",
    "    model.train()\n",
    "    acc_tr_hist, acc_val_hist = [], []\n",
    "    loss_tr_hist, loss_val_hist = [], []\n",
    "    for epoch in range(epochs):\n",
    "        # validation\n",
    "        av_loss = 0\n",
    "\n",
    "        for i_batch, (im, gt) in (tqdm(enumerate(dataloader_train)) if verbosity>1 else enumerate(dataloader_train)):\n",
    "            im = im.cuda()\n",
    "            gt = gt.cuda()\n",
    "            opt.zero_grad()\n",
    "            output = model(im)\n",
    "            loss_out = f_loss(output, gt)\n",
    "            av_loss += loss_out.cpu().detach().numpy()\n",
    "            loss_out.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if not i_batch % 100 and verbosity > 1:\n",
    "                tqdm.write(\"Average loss: {:.2f}\".format(av_loss/(i_batch+1)))\n",
    "                \n",
    "        if verbosity>0:\n",
    "            print(\"Epoch %i:\" % epoch)\n",
    "        acc_tr, loss_tr = test(model, f_loss, dataloader_train, 'Train', verbosity=verbosity)\n",
    "        acc_val, loss_val = test(model, f_loss, dataloader_val, 'Val', verbosity=verbosity)\n",
    "        acc_tr_hist.append(acc_tr)\n",
    "        acc_val_hist.append(acc_val)\n",
    "        loss_tr_hist.append(loss_tr)\n",
    "        loss_val_hist.append(loss_val)\n",
    "        if plot:\n",
    "            # plot accuracy history\n",
    "            fig, ax = plt.subplots(1,1)\n",
    "            ax.plot(np.arange(epoch+1), acc_tr_hist)\n",
    "            ax.plot(np.arange(epoch+1), acc_val_hist)\n",
    "            ax.set_xlabel(\"Epochs\")\n",
    "            ax.set_ylabel(\"OA\")\n",
    "            ax.set_ylim([0,1])\n",
    "            ax.grid(alpha=.3)\n",
    "            fig.axes[0].spines['right'].set_visible(False)\n",
    "            fig.axes[0].spines['top'].set_visible(False)\n",
    "            ax.legend(['Training Set', 'Validation Set'])\n",
    "            plt.savefig('Figures/hist_train_all_acc.pdf')\n",
    "            plt.close()\n",
    "            \n",
    "            # plot loss history\n",
    "            fig, ax = plt.subplots(1,1)\n",
    "            ax.plot(np.arange(epoch+1), loss_tr_hist)\n",
    "            ax.plot(np.arange(epoch+1), loss_val_hist)\n",
    "            ax.set_xlabel(\"Epochs\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.grid(alpha=.3)\n",
    "            fig.axes[0].spines['right'].set_visible(False)\n",
    "            fig.axes[0].spines['top'].set_visible(False)\n",
    "            ax.legend(['Training Set','Validation Set'])\n",
    "            plt.savefig('Figures/hist_train_all_loss.pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train set: Average loss: 0.0176, Accuracy: 73.47%\n",
      "Val set: Average loss: 0.0181, Accuracy: 66.45%\n",
      "Epoch 1:\n",
      "Train set: Average loss: 0.0159, Accuracy: 83.22%\n",
      "Val set: Average loss: 0.0169, Accuracy: 73.57%\n"
     ]
    }
   ],
   "source": [
    "train_bool = True\n",
    "\n",
    "model = HyperColumn(in_dim=4, out_dim=9, n_filters=32, patch_size=patch_size).cuda()\n",
    "if train_bool:\n",
    "    # Train network from scratch\n",
    "    train(model, dataloader_train, dataloader_val, epochs=50, verbosity=1, plot=True)\n",
    "    \n",
    "    # save model\n",
    "    state = {'model': model.state_dict(), \n",
    "             'n_epochs': 50,\n",
    "             'loss_tr':0.\n",
    "            }\n",
    "    \n",
    "    torch.save(state, 'models/model_wo_cl_' + str(class_to_remove) + '.pytorch')\n",
    "\n",
    "else:  # load saved model\n",
    "    state = torch.load('models/model_wo_cl_' + str(class_to_remove) + '.pytorch')\n",
    "    model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_softmax(model, dataloader_pred):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred = torch.FloatTensor()  # softmax activations\n",
    "        for i_batch, (im, gt) in tqdm(enumerate(dataloader_pred)):\n",
    "            im = im.cuda()\n",
    "            gt = gt.cuda()\n",
    "            output = model(im)\n",
    "            pred = torch.cat((pred, output.cpu()), dim=0)\n",
    "            \n",
    "    pred = pred.numpy()\n",
    "    pred = np.transpose(pred, (0, 2, 3, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with overlap\n",
    "dataset_train_overlap = ZurichLoader(root_dir, 'train', patch_size=patch_size, stride=int(patch_size/2))\n",
    "dataset_val_overlap = ZurichLoader(root_dir, 'val', patch_size=patch_size, stride=int(patch_size/2))\n",
    "dataset_test_overlap = ZurichLoader(root_dir, 'test', patch_size=patch_size, stride=int(patch_size/2))\n",
    "\n",
    "dataloader_train_overlap = DataLoader(dataset_train_overlap, batch_size=100, shuffle=False, num_workers=40)\n",
    "dataloader_val_overlap = DataLoader(dataset_val_overlap, batch_size=100, shuffle=False, num_workers=40)\n",
    "dataloader_test_overlap = DataLoader(dataset_test_overlap, batch_size=100, shuffle=False, num_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "# train\n",
    "preds_tr = predict_softmax(model, dataloader_train_overlap)\n",
    "preds_tr = remove_overlap(dataset_train.imgs, preds_tr, np.arange(10), patch_size=patch_size, stride=int(patch_size/2))\n",
    "preds_tr = np.concatenate(preds_tr)\n",
    "\n",
    "# val\n",
    "preds_val = predict_softmax(model, dataloader_val_overlap)\n",
    "preds_val = remove_overlap(dataset_val.imgs, preds_val, np.arange(5), patch_size=patch_size, stride=int(patch_size/2))\n",
    "preds_val = np.concatenate(preds_val)\n",
    "\n",
    "# test\n",
    "preds_te = predict_softmax(model, dataloader_test_overlap)\n",
    "preds_te = remove_overlap(dataset_test.imgs, preds_te, np.arange(5), patch_size=patch_size, stride=int(patch_size/2))\n",
    "preds_te = np.concatenate(preds_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "pred_labels_tr = get_y_pred_labels(preds_tr, class_to_remove=class_to_remove, background=False)\n",
    "pred_labels_val = get_y_pred_labels(preds_val, class_to_remove=class_to_remove, background=False)\n",
    "pred_labels_te = get_y_pred_labels(preds_te, class_to_remove=class_to_remove, background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 2\n",
    "\n",
    "img = convert_patches_to_image(dataset_val.imgs, pred_labels_val[..., np.newaxis], img_idx, patch_size, patch_size, 0)\n",
    "\n",
    "# pred\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(gt_label_to_color(img[...,0], dataset_val.colors)*255)\n",
    "plt.show()\n",
    "\n",
    "# im\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,7))\n",
    "axes[0].imshow(dataset_val.imgs[img_idx][..., :3])\n",
    "axes[1].imshow(gt_label_to_color(dataset_val.gt[img_idx], dataset_val.colors)*255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get weights\n",
    "p = [p for p in model.parameters()]\n",
    "for p_ in p:\n",
    "    print(p_.cpu().detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(len(np.unique(dataset_train.gt_patches)))\n",
    "ones[0] = 0\n",
    "weight = torch.from_numpy(ones).float().cuda()\n",
    "f_loss = nn.CrossEntropyLoss(weight=weight)\n",
    "p = test(model, f_loss, dataloader_train, \"Train\", verbosity=1)\n",
    "p = test(model, f_loss, dataloader_val, \"Val\", verbosity=1)\n",
    "p = test(model, f_loss, dataloader_test, \"Test\", verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names and colors\n",
    "names = dataset_train.names\n",
    "colors = dataset_train.colors\n",
    "n_classes = 9\n",
    "classes_to_keep = np.asarray([x for x in range(1, n_classes) if x != class_to_remove])\n",
    "names_keep = np.asarray(names)[classes_to_keep]\n",
    "print(\"classes to keep: \" + str(names_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures for each class\n",
    "y_preds = [pred_labels_tr, pred_labels_val, pred_labels_te]\n",
    "datasets = [dataset_train, dataset_val, dataset_test]\n",
    "\n",
    "aa_sets, oa_sets = [], []\n",
    "for y_pred, y_true in zip(y_preds, datasets):\n",
    "    y_pred_flattened = np.asarray(y_pred.flatten()).astype('int') \n",
    "    y_true_flattened = np.asarray(y_true.gt_patches.flatten()).astype('int') \n",
    "\n",
    "    # mask background and removed classes for evaluation metrics\n",
    "    filter_items = (y_true_flattened != 0) & (y_true_flattened != class_to_remove)\n",
    "\n",
    "    # Class accuracy, average accuracy\n",
    "    #print(metrics.classification_report(y_true_flattened[filter_items], y_pred_flattened[filter_items],\n",
    "    #                                    target_names=names_keep, digits=3))\n",
    "    \n",
    "    aa_set, _ = aa(y_true_flattened[filter_items], y_pred_flattened[filter_items])\n",
    "    oa_set = oa(y_true_flattened[filter_items], y_pred_flattened[filter_items])\n",
    "    print(\"OA: %.3f, AA: %.3f\" % (oa_set, aa_set))  # slightly higher accuracy because of overlapping patches\n",
    "    oa_sets.append(oa_set)\n",
    "    aa_sets.append(aa_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO save CSV\n",
    "# write metrics to CSV files\n",
    "df_metrics = pd.read_csv('models/metrics_ND.csv', index_col=0)\n",
    "accs = np.concatenate([[oa_sets[i], aa_sets[i]] for i in range(3)])  # [oa, aa] for tr, val, te\n",
    "df2 = pd.DataFrame({str(names[class_to_remove]):accs},\n",
    "                    index = ['OA Train', 'AA Train', 'OA Val', 'AA Val', 'OA Test', 'AA Test']).T\n",
    "df_metrics = df_metrics.append(df2)\n",
    "df_metrics = df_metrics[~df_metrics.index.duplicated(keep='last')]  # avoid duplicates\n",
    "df_metrics.to_csv('models/metrics_ND.csv')\n",
    "print((df_metrics*100).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO retrieve activations, do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Activations, Novelty Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, dataloader_pred):\n",
    "    model.get_activations = True\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_pred = torch.FloatTensor()\n",
    "        for i_batch, (im, gt) in tqdm(enumerate(dataloader_pred)):\n",
    "            im = im.cuda()\n",
    "            gt = gt.cuda()\n",
    "            output = model(im)\n",
    "            test_pred = torch.cat((test_pred, output.cpu()), dim=0)\n",
    "    return test_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:02,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:03,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:06,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:10,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:15,  2.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:19,  2.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:23,  2.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:29,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:35,  3.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [00:39,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [00:48,  4.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [00:55,  4.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [01:01,  4.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [01:08,  4.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [01:15,  4.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [01:25,  5.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [01:35,  5.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [01:46,  5.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [01:57,  5.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [02:09,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [02:24,  6.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [02:38,  6.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [02:52,  7.20s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "a = get_activations(model, dataloader_val_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
